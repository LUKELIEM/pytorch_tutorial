{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "import time\n",
    "import platform\n",
    "import random\n",
    "import pickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor # the CPU datatype\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# This is a little utility that we'll use to reset the model\n",
    "# if we want to re-initialize all our parameters\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n",
    "        \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def generator():\n",
    "\n",
    "    # Model - 5 layer Conv Layers (WIDER)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=256, kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=256),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(16384,1024),  # 5408=128*16*16 input siz\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = generator().type(gpu_dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "0.weight\n",
      "864\n",
      "0.bias\n",
      "32\n",
      "2.weight\n",
      "32\n",
      "2.bias\n",
      "32\n",
      "3.weight\n",
      "18432\n",
      "3.bias\n",
      "64\n",
      "5.weight\n",
      "64\n",
      "5.bias\n",
      "64\n",
      "6.weight\n",
      "73728\n",
      "6.bias\n",
      "128\n",
      "8.weight\n",
      "128\n",
      "8.bias\n",
      "128\n",
      "10.weight\n",
      "147456\n",
      "10.bias\n",
      "128\n",
      "12.weight\n",
      "128\n",
      "12.bias\n",
      "128\n",
      "13.weight\n",
      "294912\n",
      "13.bias\n",
      "256\n",
      "15.weight\n",
      "256\n",
      "15.bias\n",
      "256\n",
      "18.weight\n",
      "16777216\n",
      "18.bias\n",
      "1024\n",
      "20.weight\n",
      "10240\n",
      "20.bias\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): ReLU(inplace)\n",
       "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (6): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (7): ReLU(inplace)\n",
       "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (10): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (13): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (14): ReLU(inplace)\n",
       "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (17): Flatten(\n",
       "  )\n",
       "  (18): Linear(in_features=16384, out_features=1024)\n",
       "  (19): ReLU(inplace)\n",
       "  (20): Linear(in_features=1024, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (type(model))\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print (name)\n",
    "    print (param.nelement())\n",
    "\n",
    " \n",
    "# custom weights initialization called on model\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -0.1550  0.1479  0.0342\n",
      " -0.1847 -0.0347  0.0402\n",
      "  0.0107  0.0169  0.0192\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -0.1241  0.1246  0.1225\n",
      "  0.0983  0.1047 -0.1189\n",
      " -0.0136  0.1202 -0.0534\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      " -0.0446  0.0721  0.1867\n",
      " -0.1421  0.0388  0.0117\n",
      "  0.0387 -0.1566  0.1905\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  0.1600 -0.0253 -0.0523\n",
      " -0.0409 -0.1209  0.0389\n",
      "  0.1416  0.1481 -0.0424\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      " -0.0815 -0.0534 -0.0957\n",
      "  0.1913 -0.1840  0.0141\n",
      " -0.0193  0.1353 -0.0545\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      " -0.0531 -0.0176  0.0214\n",
      "  0.1069 -0.0974  0.0407\n",
      " -0.0960  0.0704 -0.1548\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -0.0193 -0.1427  0.1284\n",
      "  0.1613  0.1592  0.1542\n",
      " -0.1388 -0.1617  0.0499\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      "  0.0234 -0.0264 -0.0608\n",
      " -0.1610  0.0848  0.0861\n",
      "  0.1852 -0.0193 -0.1332\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      " -0.1741 -0.0629 -0.0055\n",
      " -0.0248 -0.1169  0.1822\n",
      " -0.1061 -0.1501 -0.1644\n",
      "\n",
      "(3 ,0 ,.,.) = \n",
      "  0.0709  0.0077 -0.1818\n",
      " -0.0386 -0.1634 -0.1231\n",
      " -0.0880 -0.1129 -0.0794\n",
      "\n",
      "(3 ,1 ,.,.) = \n",
      " -0.0447  0.1500 -0.0415\n",
      " -0.0780 -0.0873 -0.0162\n",
      " -0.0374  0.0980 -0.1810\n",
      "\n",
      "(3 ,2 ,.,.) = \n",
      " -0.1681  0.1868  0.0311\n",
      " -0.1799  0.0739  0.0177\n",
      " -0.0730 -0.0702 -0.0634\n",
      "\n",
      "(4 ,0 ,.,.) = \n",
      "  0.1370 -0.0624 -0.0532\n",
      "  0.0608  0.0483  0.1697\n",
      " -0.1076  0.1074  0.1546\n",
      "\n",
      "(4 ,1 ,.,.) = \n",
      " -0.0595 -0.0252  0.1295\n",
      " -0.1887 -0.0313 -0.1630\n",
      " -0.1056 -0.0561  0.0710\n",
      "\n",
      "(4 ,2 ,.,.) = \n",
      "  0.0665  0.0766 -0.0893\n",
      " -0.0224 -0.1882 -0.0999\n",
      " -0.0707  0.1314  0.0823\n",
      "\n",
      "(5 ,0 ,.,.) = \n",
      " -0.1142 -0.1293 -0.0498\n",
      "  0.0559 -0.0725 -0.0967\n",
      "  0.0651 -0.1297 -0.0695\n",
      "\n",
      "(5 ,1 ,.,.) = \n",
      "  0.1787  0.0559  0.0153\n",
      " -0.1514 -0.1189  0.0641\n",
      " -0.0570  0.0657 -0.0913\n",
      "\n",
      "(5 ,2 ,.,.) = \n",
      " -0.1757  0.0867 -0.0130\n",
      " -0.1703  0.1628  0.1771\n",
      "  0.1868 -0.0188  0.0114\n",
      "\n",
      "(6 ,0 ,.,.) = \n",
      "  0.1774  0.1483 -0.0736\n",
      " -0.0616 -0.0475 -0.0783\n",
      "  0.1150  0.0327  0.1777\n",
      "\n",
      "(6 ,1 ,.,.) = \n",
      " -0.1553  0.0937 -0.0272\n",
      "  0.1527 -0.1887 -0.1601\n",
      " -0.0880  0.0091  0.1358\n",
      "\n",
      "(6 ,2 ,.,.) = \n",
      "  0.0868  0.1303 -0.0884\n",
      " -0.1878  0.0198  0.1899\n",
      " -0.1151  0.0850  0.1091\n",
      "\n",
      "(7 ,0 ,.,.) = \n",
      " -0.1130 -0.1425 -0.0711\n",
      " -0.1484 -0.1787 -0.0857\n",
      " -0.1512 -0.0850 -0.1096\n",
      "\n",
      "(7 ,1 ,.,.) = \n",
      "  0.1825 -0.1659 -0.1088\n",
      " -0.1452 -0.0926  0.0598\n",
      "  0.1631  0.1573  0.1325\n",
      "\n",
      "(7 ,2 ,.,.) = \n",
      " -0.1564 -0.1000  0.0208\n",
      "  0.0009 -0.1473 -0.0859\n",
      "  0.1034 -0.0033  0.1668\n",
      "\n",
      "(8 ,0 ,.,.) = \n",
      " -0.0045 -0.0778  0.0855\n",
      " -0.1219 -0.1176  0.0925\n",
      " -0.0092  0.1814 -0.1336\n",
      "\n",
      "(8 ,1 ,.,.) = \n",
      " -0.0785 -0.0361 -0.0688\n",
      "  0.0714  0.1905  0.1702\n",
      " -0.1819 -0.0249 -0.0647\n",
      "\n",
      "(8 ,2 ,.,.) = \n",
      "  0.0988  0.0220 -0.0019\n",
      "  0.1796  0.1628  0.0277\n",
      " -0.0061 -0.0889  0.0716\n",
      "\n",
      "(9 ,0 ,.,.) = \n",
      " -0.1885  0.1856  0.0181\n",
      "  0.0190  0.1505  0.1893\n",
      " -0.1906  0.0609 -0.0206\n",
      "\n",
      "(9 ,1 ,.,.) = \n",
      "  0.0845  0.1423  0.0245\n",
      " -0.0062  0.0442  0.1777\n",
      "  0.0381  0.1757  0.0784\n",
      "\n",
      "(9 ,2 ,.,.) = \n",
      " -0.1606  0.0723 -0.0522\n",
      " -0.1584 -0.0061  0.1122\n",
      "  0.1327  0.0934  0.0141\n",
      "\n",
      "(10,0 ,.,.) = \n",
      "  0.1871  0.1017 -0.1715\n",
      "  0.1664 -0.1769  0.0546\n",
      " -0.1037  0.0495 -0.1143\n",
      "\n",
      "(10,1 ,.,.) = \n",
      " -0.0685  0.1775  0.1644\n",
      " -0.0050  0.1469 -0.0519\n",
      "  0.0691 -0.1146 -0.1282\n",
      "\n",
      "(10,2 ,.,.) = \n",
      " -0.1325 -0.1830  0.0473\n",
      "  0.0356  0.1384 -0.0948\n",
      "  0.0990 -0.1012 -0.0740\n",
      "\n",
      "(11,0 ,.,.) = \n",
      "  0.0274  0.0709  0.0145\n",
      "  0.0064  0.0337 -0.0718\n",
      " -0.1667  0.1617 -0.0555\n",
      "\n",
      "(11,1 ,.,.) = \n",
      " -0.1563 -0.1312  0.1060\n",
      "  0.0778 -0.1697  0.1612\n",
      "  0.1349 -0.1093 -0.0913\n",
      "\n",
      "(11,2 ,.,.) = \n",
      "  0.0634 -0.0792  0.1748\n",
      " -0.1214 -0.0925 -0.0216\n",
      " -0.0334  0.1822 -0.1382\n",
      "\n",
      "(12,0 ,.,.) = \n",
      " -0.0873 -0.0256  0.1200\n",
      "  0.1329 -0.0072  0.0958\n",
      "  0.0135  0.1746 -0.0192\n",
      "\n",
      "(12,1 ,.,.) = \n",
      " -0.1237 -0.1306 -0.1593\n",
      " -0.1561 -0.1126 -0.0337\n",
      "  0.1149  0.0922  0.1010\n",
      "\n",
      "(12,2 ,.,.) = \n",
      " -0.1102 -0.0588  0.0989\n",
      "  0.0282  0.0113  0.1521\n",
      "  0.0011  0.1353  0.0080\n",
      "\n",
      "(13,0 ,.,.) = \n",
      " -0.0484  0.1116  0.0632\n",
      "  0.1612 -0.0622  0.0312\n",
      "  0.0963 -0.0885 -0.0323\n",
      "\n",
      "(13,1 ,.,.) = \n",
      "  0.0944  0.1804 -0.1759\n",
      " -0.0285  0.1522  0.1374\n",
      " -0.0973  0.1826  0.1353\n",
      "\n",
      "(13,2 ,.,.) = \n",
      "  0.0335  0.1005  0.0101\n",
      " -0.0723  0.0238  0.0147\n",
      "  0.0138 -0.0479 -0.0652\n",
      "\n",
      "(14,0 ,.,.) = \n",
      " -0.1244 -0.0336  0.0493\n",
      "  0.0373  0.1856  0.1463\n",
      "  0.0444 -0.1701 -0.1148\n",
      "\n",
      "(14,1 ,.,.) = \n",
      " -0.0487  0.1445  0.0783\n",
      " -0.0096  0.1862  0.0912\n",
      " -0.1391 -0.1317 -0.1887\n",
      "\n",
      "(14,2 ,.,.) = \n",
      " -0.1841  0.0357  0.1614\n",
      "  0.0708 -0.1498  0.1615\n",
      "  0.1371 -0.0713  0.0447\n",
      "\n",
      "(15,0 ,.,.) = \n",
      " -0.1844 -0.1654 -0.0098\n",
      " -0.0280  0.0840  0.0443\n",
      " -0.1096 -0.0866 -0.0877\n",
      "\n",
      "(15,1 ,.,.) = \n",
      "  0.0006  0.0899  0.1546\n",
      " -0.1430 -0.1141  0.0434\n",
      "  0.0360  0.0804 -0.1096\n",
      "\n",
      "(15,2 ,.,.) = \n",
      "  0.1812  0.1753  0.1559\n",
      " -0.0998 -0.0593  0.0861\n",
      "  0.1590  0.0884 -0.1569\n",
      "\n",
      "(16,0 ,.,.) = \n",
      " -0.1217 -0.1590  0.1791\n",
      " -0.0524  0.0667  0.1420\n",
      " -0.1835 -0.0940  0.1421\n",
      "\n",
      "(16,1 ,.,.) = \n",
      "  0.0427  0.0444 -0.1758\n",
      " -0.1005 -0.0138  0.0936\n",
      "  0.1202  0.0176  0.0770\n",
      "\n",
      "(16,2 ,.,.) = \n",
      " -0.1395  0.0626 -0.0685\n",
      " -0.0928  0.1284  0.1725\n",
      "  0.0183  0.0444 -0.0030\n",
      "\n",
      "(17,0 ,.,.) = \n",
      " -0.1908  0.1630 -0.1063\n",
      " -0.0856 -0.0539  0.0736\n",
      " -0.0323 -0.0769  0.0743\n",
      "\n",
      "(17,1 ,.,.) = \n",
      "  0.0374  0.0049  0.0701\n",
      "  0.0133 -0.0241 -0.0144\n",
      "  0.1197  0.0949 -0.0480\n",
      "\n",
      "(17,2 ,.,.) = \n",
      "  0.1630 -0.1538 -0.0086\n",
      " -0.0990  0.1659  0.0519\n",
      " -0.0913  0.1009 -0.0037\n",
      "\n",
      "(18,0 ,.,.) = \n",
      " -0.0764 -0.0027  0.1052\n",
      "  0.0083 -0.0012  0.1115\n",
      "  0.0321 -0.1866 -0.1262\n",
      "\n",
      "(18,1 ,.,.) = \n",
      " -0.1583  0.1515 -0.0701\n",
      " -0.0462  0.0995  0.0141\n",
      "  0.1707  0.0462  0.0398\n",
      "\n",
      "(18,2 ,.,.) = \n",
      "  0.0164  0.0742 -0.1071\n",
      "  0.1286  0.1005 -0.0141\n",
      "  0.1253  0.0368 -0.1227\n",
      "\n",
      "(19,0 ,.,.) = \n",
      " -0.0057  0.1728 -0.0581\n",
      "  0.1342  0.1401 -0.1166\n",
      "  0.0924  0.1580  0.0129\n",
      "\n",
      "(19,1 ,.,.) = \n",
      "  0.1791  0.0577  0.0526\n",
      "  0.0457 -0.1662  0.0184\n",
      " -0.1230  0.1664  0.0627\n",
      "\n",
      "(19,2 ,.,.) = \n",
      " -0.1399 -0.0246  0.0324\n",
      "  0.1601 -0.1778  0.0441\n",
      " -0.1452  0.1497  0.0803\n",
      "\n",
      "(20,0 ,.,.) = \n",
      "  0.0049 -0.0178  0.0595\n",
      "  0.1824  0.1511  0.1168\n",
      " -0.1425  0.0753 -0.1278\n",
      "\n",
      "(20,1 ,.,.) = \n",
      "  0.0996  0.0664  0.0202\n",
      "  0.0708 -0.0041 -0.0017\n",
      " -0.1239  0.0348 -0.0290\n",
      "\n",
      "(20,2 ,.,.) = \n",
      " -0.0599 -0.1469 -0.1853\n",
      " -0.1519  0.1659  0.0628\n",
      " -0.1068 -0.0322 -0.0561\n",
      "\n",
      "(21,0 ,.,.) = \n",
      "  0.0054 -0.1619  0.0967\n",
      "  0.0377 -0.0418  0.0709\n",
      " -0.0920  0.1756  0.1628\n",
      "\n",
      "(21,1 ,.,.) = \n",
      "  0.0811  0.0368 -0.1680\n",
      "  0.0991 -0.1055  0.1236\n",
      "  0.0516  0.1157 -0.1151\n",
      "\n",
      "(21,2 ,.,.) = \n",
      " -0.0301 -0.0951 -0.1817\n",
      " -0.0414  0.0319  0.0740\n",
      "  0.1670  0.1391 -0.1086\n",
      "\n",
      "(22,0 ,.,.) = \n",
      "  0.1067  0.1359 -0.1873\n",
      "  0.0634 -0.0625  0.0845\n",
      " -0.0035  0.0328 -0.1099\n",
      "\n",
      "(22,1 ,.,.) = \n",
      "  0.0150  0.1614  0.0893\n",
      "  0.0048  0.0970 -0.0809\n",
      " -0.1367  0.1456 -0.0270\n",
      "\n",
      "(22,2 ,.,.) = \n",
      "  0.1862  0.1357 -0.0912\n",
      "  0.0247 -0.1033  0.0475\n",
      "  0.0022  0.1072  0.1513\n",
      "\n",
      "(23,0 ,.,.) = \n",
      "  0.1482  0.0224 -0.0475\n",
      "  0.0892 -0.0094 -0.0969\n",
      " -0.0166  0.1552  0.1892\n",
      "\n",
      "(23,1 ,.,.) = \n",
      " -0.1340  0.0750  0.0054\n",
      " -0.1615  0.1580  0.0568\n",
      "  0.0683  0.0083  0.1450\n",
      "\n",
      "(23,2 ,.,.) = \n",
      "  0.0919  0.0103 -0.0005\n",
      "  0.0761 -0.1830 -0.0280\n",
      "  0.0694  0.0714 -0.0814\n",
      "\n",
      "(24,0 ,.,.) = \n",
      " -0.0761 -0.0622  0.1795\n",
      "  0.0453  0.1118 -0.1635\n",
      "  0.0591 -0.1137  0.1672\n",
      "\n",
      "(24,1 ,.,.) = \n",
      "  0.0504  0.1263  0.1721\n",
      " -0.0877  0.0663  0.0480\n",
      "  0.0524  0.0564 -0.0403\n",
      "\n",
      "(24,2 ,.,.) = \n",
      "  0.1782  0.1245 -0.0408\n",
      " -0.0490  0.1357 -0.1304\n",
      " -0.0593  0.1421 -0.1604\n",
      "\n",
      "(25,0 ,.,.) = \n",
      " -0.0391 -0.0654 -0.0611\n",
      " -0.0265  0.1230 -0.1346\n",
      " -0.1062  0.1719  0.1585\n",
      "\n",
      "(25,1 ,.,.) = \n",
      "  0.1787  0.0933 -0.1058\n",
      "  0.0603 -0.0635  0.0556\n",
      "  0.0574  0.1728  0.0589\n",
      "\n",
      "(25,2 ,.,.) = \n",
      " -0.0838 -0.1641  0.1633\n",
      "  0.0133  0.1163  0.1627\n",
      " -0.1885 -0.1773 -0.1200\n",
      "\n",
      "(26,0 ,.,.) = \n",
      " -0.1850 -0.0516  0.0493\n",
      " -0.0481 -0.1706  0.0641\n",
      "  0.0612 -0.1115 -0.0773\n",
      "\n",
      "(26,1 ,.,.) = \n",
      " -0.1133 -0.0728  0.0407\n",
      " -0.1441  0.0857 -0.1452\n",
      "  0.1878 -0.0622 -0.0429\n",
      "\n",
      "(26,2 ,.,.) = \n",
      " -0.1304 -0.0035 -0.0524\n",
      "  0.0983  0.1756  0.0151\n",
      " -0.0757  0.1126 -0.0074\n",
      "\n",
      "(27,0 ,.,.) = \n",
      "  0.0390 -0.0555 -0.1657\n",
      " -0.1533  0.0750  0.1408\n",
      "  0.1686  0.0174 -0.0613\n",
      "\n",
      "(27,1 ,.,.) = \n",
      "  0.0950  0.0284  0.1364\n",
      "  0.1556  0.1556 -0.0466\n",
      " -0.1053 -0.0177  0.0805\n",
      "\n",
      "(27,2 ,.,.) = \n",
      " -0.1606  0.0832  0.0329\n",
      " -0.1520  0.1275  0.1554\n",
      " -0.0194  0.0167  0.1302\n",
      "\n",
      "(28,0 ,.,.) = \n",
      " -0.0322  0.0572 -0.0974\n",
      "  0.1887  0.0008  0.1406\n",
      "  0.1153 -0.0245  0.0226\n",
      "\n",
      "(28,1 ,.,.) = \n",
      " -0.0821  0.0459 -0.0646\n",
      " -0.1845 -0.1539  0.1480\n",
      "  0.1678  0.0063 -0.0624\n",
      "\n",
      "(28,2 ,.,.) = \n",
      "  0.1412 -0.0985 -0.1479\n",
      "  0.1313 -0.1912 -0.1051\n",
      " -0.0558  0.0983 -0.0647\n",
      "\n",
      "(29,0 ,.,.) = \n",
      "  0.1213 -0.1292  0.0019\n",
      "  0.0602 -0.1454 -0.0090\n",
      " -0.1552 -0.1384 -0.1039\n",
      "\n",
      "(29,1 ,.,.) = \n",
      " -0.0141  0.0981 -0.0464\n",
      "  0.0482  0.1761 -0.0265\n",
      "  0.0347  0.1848  0.1123\n",
      "\n",
      "(29,2 ,.,.) = \n",
      "  0.1859 -0.0941 -0.0168\n",
      " -0.1416  0.0773  0.1238\n",
      " -0.0722  0.1160  0.0471\n",
      "\n",
      "(30,0 ,.,.) = \n",
      "  0.1165  0.1405 -0.0266\n",
      "  0.1478  0.1249 -0.0851\n",
      " -0.1492  0.0521  0.1921\n",
      "\n",
      "(30,1 ,.,.) = \n",
      "  0.1902  0.1161 -0.0478\n",
      " -0.1547 -0.0777  0.1564\n",
      " -0.0205 -0.0954  0.0063\n",
      "\n",
      "(30,2 ,.,.) = \n",
      "  0.0188  0.0854 -0.0506\n",
      "  0.0296 -0.0600  0.1596\n",
      "  0.0281  0.1286 -0.0854\n",
      "\n",
      "(31,0 ,.,.) = \n",
      " -0.0637 -0.1733  0.1788\n",
      "  0.1617  0.1490 -0.1322\n",
      "  0.0492  0.1464 -0.1169\n",
      "\n",
      "(31,1 ,.,.) = \n",
      " -0.0719  0.1486  0.0423\n",
      " -0.1892 -0.1484  0.0605\n",
      "  0.0437 -0.1256  0.1026\n",
      "\n",
      "(31,2 ,.,.) = \n",
      " -0.1325 -0.0718  0.1149\n",
      "  0.1599 -0.1610 -0.0868\n",
      "  0.1247  0.1101  0.1499\n",
      "[torch.cuda.FloatTensor of size 32x3x3x3 (GPU 0)]\n",
      ", Parameter containing:\n",
      "-0.1012\n",
      " 0.1494\n",
      "-0.0346\n",
      " 0.0806\n",
      " 0.0327\n",
      " 0.1564\n",
      "-0.1343\n",
      "-0.1391\n",
      " 0.1549\n",
      "-0.0196\n",
      " 0.1910\n",
      "-0.1778\n",
      "-0.1371\n",
      "-0.1697\n",
      " 0.1559\n",
      " 0.0003\n",
      " 0.0864\n",
      " 0.0784\n",
      " 0.1788\n",
      "-0.0912\n",
      "-0.1271\n",
      "-0.1368\n",
      " 0.1731\n",
      "-0.0029\n",
      " 0.0807\n",
      "-0.1075\n",
      " 0.1251\n",
      " 0.0597\n",
      "-0.0207\n",
      "-0.0348\n",
      "-0.1414\n",
      "-0.0695\n",
      "[torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0.7568\n",
      " 0.8933\n",
      " 0.2579\n",
      " 0.8500\n",
      " 0.3383\n",
      " 0.8065\n",
      " 0.6920\n",
      " 0.4664\n",
      " 0.1321\n",
      " 0.8463\n",
      " 0.0337\n",
      " 0.8377\n",
      " 0.2930\n",
      " 0.2848\n",
      " 0.8031\n",
      " 0.0406\n",
      " 0.1676\n",
      " 0.3773\n",
      " 0.6015\n",
      " 0.2426\n",
      " 0.0338\n",
      " 0.3808\n",
      " 0.7840\n",
      " 0.9173\n",
      " 0.3363\n",
      " 0.0757\n",
      " 0.6831\n",
      " 0.1018\n",
      " 0.7315\n",
      " 0.1305\n",
      " 0.8130\n",
      " 0.2159\n",
      "[torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      ", Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  5.9355e-03  1.1527e-02  1.9157e-02\n",
      " -2.2960e-02  3.2381e-02  4.0874e-02\n",
      "  5.2320e-03 -5.4436e-02  6.2134e-03\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  1.6827e-02 -4.5391e-02  2.1741e-02\n",
      "  5.5753e-02 -5.8172e-02 -3.7800e-03\n",
      " -2.7207e-02  5.2950e-02 -5.6881e-02\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      " -5.1924e-02 -4.4612e-03  2.0124e-02\n",
      "  2.5839e-02  4.5539e-02  2.7150e-02\n",
      "  3.9819e-02  1.7905e-03  1.5616e-02\n",
      "   ...\n",
      "\n",
      "(0 ,29,.,.) = \n",
      " -5.7981e-02  2.8887e-04 -3.9205e-02\n",
      " -2.6439e-02 -1.8685e-02 -4.7856e-02\n",
      "  4.1956e-03  5.5826e-02  5.3599e-02\n",
      "\n",
      "(0 ,30,.,.) = \n",
      " -3.2128e-02  4.4807e-02  5.3027e-02\n",
      "  2.2672e-02 -4.6414e-02 -5.3882e-02\n",
      "  4.0031e-02 -5.8293e-02 -2.8738e-02\n",
      "\n",
      "(0 ,31,.,.) = \n",
      " -3.8557e-02  5.6871e-02  3.6832e-02\n",
      " -3.0568e-03  4.3535e-02  4.7426e-03\n",
      "  1.9464e-02 -2.0486e-02 -2.8742e-02\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -3.5131e-02 -3.5580e-02 -2.2587e-02\n",
      " -2.7728e-03 -4.2906e-02  4.9457e-02\n",
      " -5.0027e-03 -4.2800e-02 -3.5260e-02\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      " -1.4979e-02  5.6344e-02 -2.6183e-02\n",
      " -1.8254e-02  1.8294e-02 -9.7366e-03\n",
      "  2.5501e-02 -2.6464e-02 -3.1814e-02\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      " -2.5232e-02 -7.5569e-03 -4.3603e-02\n",
      " -2.3755e-02 -1.2717e-02  2.6462e-02\n",
      "  1.5731e-02 -3.5962e-02 -3.8701e-02\n",
      "   ...\n",
      "\n",
      "(1 ,29,.,.) = \n",
      "  4.1170e-02 -1.9038e-04 -3.1515e-02\n",
      "  2.5405e-02  3.4815e-02 -3.4814e-02\n",
      " -2.1713e-02  5.5881e-02 -5.5784e-02\n",
      "\n",
      "(1 ,30,.,.) = \n",
      " -8.2070e-03 -4.3166e-02  9.5021e-03\n",
      "  3.5438e-02 -3.0357e-02  5.8280e-03\n",
      "  2.0042e-02  8.0355e-03  7.4108e-03\n",
      "\n",
      "(1 ,31,.,.) = \n",
      "  4.6554e-02  3.3735e-02 -1.4664e-02\n",
      "  4.5530e-03  4.4708e-03 -4.4081e-02\n",
      " -3.2325e-02  1.7546e-03  2.6394e-02\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -3.8268e-02 -1.1772e-02 -5.1993e-02\n",
      "  3.8276e-02  3.0465e-03  9.4186e-03\n",
      "  5.8817e-02  2.7595e-02 -2.7046e-02\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      " -1.4255e-02 -4.8479e-02 -2.7794e-02\n",
      "  3.3571e-02 -4.2433e-02 -6.1146e-03\n",
      "  5.8452e-02 -2.8180e-02  3.8538e-02\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "  5.0408e-02  3.6683e-02  1.0465e-03\n",
      "  4.7986e-02 -4.8922e-02  4.3800e-02\n",
      " -1.7878e-02 -5.2365e-03  1.6198e-02\n",
      "   ...\n",
      "\n",
      "(2 ,29,.,.) = \n",
      "  7.8543e-03 -4.7406e-02  4.4668e-02\n",
      "  3.1095e-02 -2.9197e-02  4.0950e-02\n",
      "  2.9544e-02 -3.4528e-02 -1.3704e-02\n",
      "\n",
      "(2 ,30,.,.) = \n",
      " -5.8756e-02  1.0729e-02  1.5741e-03\n",
      " -5.4684e-02  3.4028e-02  5.1425e-02\n",
      " -2.9644e-02 -1.2395e-02  4.4308e-02\n",
      "\n",
      "(2 ,31,.,.) = \n",
      "  4.5949e-02  4.3357e-02  4.1021e-02\n",
      " -3.7384e-02  5.5751e-02  3.0125e-02\n",
      "  4.0771e-02  3.2097e-02 -5.7201e-02\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(61,0 ,.,.) = \n",
      "  1.7396e-02  1.0963e-02  5.4685e-02\n",
      " -2.6308e-02 -2.5785e-02  2.1018e-02\n",
      "  3.3587e-03 -4.1560e-02 -8.5096e-03\n",
      "\n",
      "(61,1 ,.,.) = \n",
      "  2.8850e-02  8.4795e-03 -1.2195e-02\n",
      " -1.5948e-03 -2.4563e-02  4.1843e-02\n",
      " -1.1552e-03  2.3323e-02  1.9769e-02\n",
      "\n",
      "(61,2 ,.,.) = \n",
      "  2.0750e-02  5.5819e-02  1.1540e-02\n",
      " -4.1359e-02  8.0704e-03  5.1742e-03\n",
      "  2.3182e-02 -1.5767e-02  3.0670e-02\n",
      "   ...\n",
      "\n",
      "(61,29,.,.) = \n",
      " -2.9339e-02 -2.0574e-02  3.4415e-02\n",
      "  2.5906e-02  5.6397e-02 -3.0524e-02\n",
      "  3.2820e-03  3.0793e-02 -1.9293e-02\n",
      "\n",
      "(61,30,.,.) = \n",
      " -2.2080e-02 -1.0923e-02  2.4527e-02\n",
      "  2.6339e-02 -1.2572e-02 -4.1009e-02\n",
      " -7.9431e-04 -2.8681e-02  3.4215e-02\n",
      "\n",
      "(61,31,.,.) = \n",
      "  1.7503e-02 -3.9644e-02 -2.5159e-02\n",
      "  4.5480e-02 -1.7649e-02 -2.8496e-02\n",
      "  2.9360e-02 -1.3888e-02  6.6250e-03\n",
      "     ⋮ \n",
      "\n",
      "(62,0 ,.,.) = \n",
      "  5.4096e-02  3.7530e-02  4.3099e-02\n",
      " -5.3195e-02  9.4763e-03 -1.7197e-02\n",
      "  4.2759e-02 -2.5934e-02 -5.8394e-02\n",
      "\n",
      "(62,1 ,.,.) = \n",
      "  4.6575e-02  8.3154e-04  5.3607e-02\n",
      " -1.1657e-02 -5.5424e-02  5.4888e-02\n",
      " -2.8922e-02  3.9491e-02 -2.1767e-02\n",
      "\n",
      "(62,2 ,.,.) = \n",
      " -4.3861e-02 -2.5048e-02 -5.8220e-02\n",
      " -1.6006e-02  3.1303e-02 -2.2140e-02\n",
      " -5.2297e-02 -5.4308e-02 -4.3593e-02\n",
      "   ...\n",
      "\n",
      "(62,29,.,.) = \n",
      "  1.7923e-02  2.7437e-02 -2.1961e-03\n",
      " -4.1281e-02  4.3682e-02  5.4013e-02\n",
      " -4.5722e-02  4.9799e-02 -5.5018e-02\n",
      "\n",
      "(62,30,.,.) = \n",
      " -2.2566e-02  5.3712e-02 -2.9202e-02\n",
      "  1.8372e-02  2.6867e-02  5.5922e-02\n",
      "  1.3603e-02 -5.2445e-02 -2.7686e-02\n",
      "\n",
      "(62,31,.,.) = \n",
      " -4.5685e-02 -2.9450e-02 -1.3260e-02\n",
      "  1.0667e-02  1.6610e-02 -1.4907e-02\n",
      "  2.9681e-02 -4.1980e-02  3.7810e-02\n",
      "     ⋮ \n",
      "\n",
      "(63,0 ,.,.) = \n",
      " -4.1908e-02  5.5896e-02  1.2989e-02\n",
      "  4.2376e-02  1.5367e-02  4.4286e-02\n",
      "  2.5002e-02 -4.0032e-02  3.0583e-02\n",
      "\n",
      "(63,1 ,.,.) = \n",
      " -1.4572e-02 -1.3746e-02 -5.4766e-02\n",
      "  7.2137e-03 -1.9856e-02 -5.2461e-02\n",
      "  7.3193e-03 -2.5153e-02  5.2226e-02\n",
      "\n",
      "(63,2 ,.,.) = \n",
      " -1.9364e-02 -3.1072e-02  3.5787e-02\n",
      "  2.7118e-02  4.3499e-02  3.6146e-02\n",
      " -1.2550e-03  2.2847e-02 -3.5493e-02\n",
      "   ...\n",
      "\n",
      "(63,29,.,.) = \n",
      "  5.3836e-02  3.6504e-02 -4.6786e-02\n",
      " -2.7788e-02 -1.6616e-02 -3.3515e-02\n",
      " -4.5845e-02 -2.9305e-02  1.5270e-03\n",
      "\n",
      "(63,30,.,.) = \n",
      "  9.9545e-03 -3.2781e-02  2.8957e-02\n",
      " -8.7552e-04 -1.6641e-02  5.2492e-02\n",
      " -1.5005e-03 -3.7819e-02 -2.7771e-02\n",
      "\n",
      "(63,31,.,.) = \n",
      " -4.8280e-02 -1.4590e-02  2.0773e-02\n",
      "  5.2561e-03 -2.0024e-02  5.4499e-02\n",
      " -2.4482e-02  4.0713e-02 -4.2122e-02\n",
      "[torch.cuda.FloatTensor of size 64x32x3x3 (GPU 0)]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      "  3.2745\n",
      " -0.3844\n",
      " -4.3027\n",
      " -2.6406\n",
      "  4.4052\n",
      "  0.5517\n",
      "  3.8356\n",
      " -5.0478\n",
      " -3.0089\n",
      " -3.7328\n",
      "  1.5461\n",
      "  3.3824\n",
      " -2.6144\n",
      " -2.4712\n",
      "  5.1845\n",
      "  3.6361\n",
      " -0.9536\n",
      " -2.1026\n",
      " -5.6479\n",
      " -3.5513\n",
      " -5.2796\n",
      "  2.1894\n",
      " -5.3939\n",
      "  1.7586\n",
      " -5.2067\n",
      " -3.5643\n",
      "  2.0340\n",
      "  1.6746\n",
      "  3.6980\n",
      " -3.8593\n",
      "  5.0185\n",
      " -1.1624\n",
      "  3.9466\n",
      "  0.5668\n",
      "  1.5273\n",
      " -4.1245\n",
      "  2.3378\n",
      " -5.2724\n",
      "  1.0992\n",
      " -5.4913\n",
      " -3.4987\n",
      " -2.2032\n",
      "  5.4169\n",
      "  4.7344\n",
      "  0.2486\n",
      " -2.9233\n",
      " -3.8029\n",
      "  4.4930\n",
      " -1.4881\n",
      "  0.4976\n",
      " -2.7034\n",
      " -3.6023\n",
      " -3.8322\n",
      " -0.1677\n",
      "  1.4790\n",
      "  0.3027\n",
      "  1.6749\n",
      "  3.3477\n",
      " -3.1208\n",
      "  4.5109\n",
      "  4.6315\n",
      " -5.3541\n",
      " -1.1591\n",
      " -5.0947\n",
      "[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0.0122\n",
      " 0.6064\n",
      " 0.6137\n",
      " 0.0389\n",
      " 0.0115\n",
      " 0.9854\n",
      " 0.1135\n",
      " 0.4065\n",
      " 0.1559\n",
      " 0.8262\n",
      " 0.9380\n",
      " 0.1848\n",
      " 0.5106\n",
      " 0.4504\n",
      " 0.6542\n",
      " 0.3669\n",
      " 0.8138\n",
      " 0.0806\n",
      " 0.0134\n",
      " 0.0714\n",
      " 0.7339\n",
      " 0.7783\n",
      " 0.3598\n",
      " 0.2074\n",
      " 0.3166\n",
      " 0.0931\n",
      " 0.2338\n",
      " 0.3414\n",
      " 0.4228\n",
      " 0.0337\n",
      " 0.5840\n",
      " 0.7443\n",
      " 0.5239\n",
      " 0.7970\n",
      " 0.4336\n",
      " 0.1742\n",
      " 0.5848\n",
      " 0.5869\n",
      " 0.7715\n",
      " 0.8142\n",
      " 0.4813\n",
      " 0.4928\n",
      " 0.4795\n",
      " 0.1827\n",
      " 0.3483\n",
      " 0.5724\n",
      " 0.7225\n",
      " 0.3896\n",
      " 0.4639\n",
      " 0.6252\n",
      " 0.1286\n",
      " 0.9866\n",
      " 0.1590\n",
      " 0.7582\n",
      " 0.7480\n",
      " 0.9616\n",
      " 0.2345\n",
      " 0.2567\n",
      " 0.8102\n",
      " 0.8438\n",
      " 0.5721\n",
      " 0.1867\n",
      " 0.3875\n",
      " 0.0059\n",
      "[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      ", Parameter containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  1.9851e-02 -8.3309e-03 -3.1425e-02\n",
      " -2.0881e-02 -5.2602e-03 -6.3094e-03\n",
      "  3.8584e-02  1.5879e-02  2.3778e-02\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      " -5.9563e-03  1.7733e-03  3.6362e-02\n",
      "  1.9189e-03 -9.3246e-03 -7.6906e-03\n",
      " -2.2508e-02 -1.5171e-02  1.1374e-02\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  3.4865e-02  3.1166e-02  3.1158e-02\n",
      " -3.8880e-02 -1.2268e-02 -1.5520e-02\n",
      " -1.8506e-02  4.1234e-02  3.4654e-02\n",
      "    ... \n",
      "\n",
      "( 0 ,61 ,.,.) = \n",
      " -1.4447e-02  1.7114e-02 -9.6744e-03\n",
      " -6.2786e-03 -3.1583e-02  3.2566e-02\n",
      " -2.8490e-02 -3.5579e-02  3.8787e-03\n",
      "\n",
      "( 0 ,62 ,.,.) = \n",
      "  3.8890e-02 -1.6183e-03  3.1751e-02\n",
      " -1.1164e-03  2.8515e-03  5.7267e-03\n",
      "  8.4827e-03 -3.3537e-02 -2.8650e-02\n",
      "\n",
      "( 0 ,63 ,.,.) = \n",
      " -6.8778e-03  2.6601e-02 -1.4147e-02\n",
      "  2.5191e-02 -1.4925e-02 -7.8129e-04\n",
      "  1.8417e-02  2.5468e-02  2.5393e-03\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      " -2.3623e-02  2.5425e-02 -1.7051e-05\n",
      " -3.3098e-02 -9.2645e-03  1.3608e-02\n",
      "  1.3041e-02 -2.9058e-02  1.7565e-02\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      " -2.4944e-02  3.8572e-02 -3.1496e-02\n",
      " -3.1897e-02 -1.9555e-02  1.4570e-02\n",
      "  1.2677e-02 -8.0814e-03  2.6207e-02\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  2.4527e-02 -3.1945e-02 -3.7263e-02\n",
      " -1.9899e-02  2.0105e-02  1.7055e-02\n",
      "  2.2528e-02  3.9083e-02 -2.8166e-02\n",
      "    ... \n",
      "\n",
      "( 1 ,61 ,.,.) = \n",
      "  2.1143e-02  1.7598e-02 -1.1720e-03\n",
      " -3.8715e-02  2.8559e-02 -2.0913e-02\n",
      "  2.1140e-02  2.4423e-03  1.3382e-02\n",
      "\n",
      "( 1 ,62 ,.,.) = \n",
      " -2.8304e-02 -4.7261e-03  2.5622e-02\n",
      " -3.1543e-02  3.9711e-02  3.3937e-02\n",
      " -3.4608e-02  2.6331e-02 -3.7484e-02\n",
      "\n",
      "( 1 ,63 ,.,.) = \n",
      "  1.0778e-02 -2.2617e-02  1.7302e-02\n",
      "  2.1430e-02  2.3409e-02  1.8253e-03\n",
      "  2.8892e-02  1.8945e-02 -5.3384e-03\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      " -3.4803e-02  1.0311e-02 -5.2708e-03\n",
      " -2.7317e-02 -3.9392e-02 -1.8182e-03\n",
      "  1.1732e-02  2.9614e-03 -2.2899e-02\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      " -4.4956e-03 -2.4194e-02 -1.2593e-02\n",
      "  3.3543e-03 -1.7402e-02 -2.1887e-02\n",
      "  3.8126e-02  2.3036e-02  2.6571e-02\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  1.0073e-02 -2.5726e-03 -4.0643e-02\n",
      "  3.5002e-02  2.1826e-03  3.0637e-02\n",
      " -2.1101e-02  2.7350e-02  2.2846e-02\n",
      "    ... \n",
      "\n",
      "( 2 ,61 ,.,.) = \n",
      "  3.7273e-02 -3.4811e-02 -8.7246e-03\n",
      " -7.9621e-03 -1.7538e-02  1.8134e-02\n",
      "  1.9489e-02 -1.4976e-02 -1.1011e-02\n",
      "\n",
      "( 2 ,62 ,.,.) = \n",
      "  3.5037e-02 -3.3600e-02 -2.1882e-02\n",
      " -1.1996e-02  3.7321e-02  3.1611e-02\n",
      " -2.8933e-02 -3.0836e-02  3.3949e-02\n",
      "\n",
      "( 2 ,63 ,.,.) = \n",
      " -1.7879e-02  3.4922e-02 -1.9640e-02\n",
      " -3.7539e-02  2.4171e-02  5.5344e-03\n",
      " -2.8089e-02  1.4800e-02 -6.5259e-03\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(125, 0 ,.,.) = \n",
      "  6.7217e-03  2.0154e-02  2.5118e-02\n",
      " -6.9297e-03 -5.2445e-03  3.8339e-02\n",
      " -1.2152e-02  4.0140e-02  1.1730e-02\n",
      "\n",
      "(125, 1 ,.,.) = \n",
      " -1.6610e-02  1.4695e-02 -3.2913e-02\n",
      " -2.4445e-02 -3.3393e-02 -7.3113e-03\n",
      "  2.6439e-02 -1.2684e-02  1.5643e-02\n",
      "\n",
      "(125, 2 ,.,.) = \n",
      " -2.0375e-02  3.3231e-02 -2.9685e-02\n",
      " -3.5542e-02 -5.5063e-03 -1.8467e-02\n",
      " -1.6500e-02 -2.3630e-02  2.0378e-02\n",
      "    ... \n",
      "\n",
      "(125,61 ,.,.) = \n",
      "  3.3828e-02 -1.2437e-02  9.0151e-03\n",
      "  3.7846e-02  2.4961e-02 -3.8212e-02\n",
      " -3.1068e-02 -1.3972e-02  4.1129e-02\n",
      "\n",
      "(125,62 ,.,.) = \n",
      "  1.8514e-04 -2.4699e-02 -5.3075e-03\n",
      "  1.4903e-02  2.8036e-02  2.4158e-02\n",
      "  8.3417e-03  2.4913e-02  1.2400e-02\n",
      "\n",
      "(125,63 ,.,.) = \n",
      " -2.9568e-02 -6.5067e-04 -6.1539e-03\n",
      "  2.7616e-02 -1.0386e-02 -2.4995e-02\n",
      "  2.9954e-02 -1.1685e-03  2.7767e-02\n",
      "      ⋮  \n",
      "\n",
      "(126, 0 ,.,.) = \n",
      " -3.3888e-02 -3.6146e-02 -1.5502e-02\n",
      "  4.0394e-02  3.0355e-02  2.5588e-02\n",
      " -2.3587e-02  3.6402e-02  3.6949e-02\n",
      "\n",
      "(126, 1 ,.,.) = \n",
      "  2.9037e-02 -1.3153e-02  2.8006e-02\n",
      "  4.6852e-03  1.0733e-02 -2.2962e-03\n",
      " -1.8556e-02  1.0792e-03  1.1074e-02\n",
      "\n",
      "(126, 2 ,.,.) = \n",
      " -2.3023e-02  4.9389e-03  2.3751e-02\n",
      " -3.6065e-02  9.4422e-03  4.9141e-03\n",
      " -2.7128e-02  4.2324e-03 -3.5482e-02\n",
      "    ... \n",
      "\n",
      "(126,61 ,.,.) = \n",
      "  1.7880e-02  4.0224e-02 -1.1230e-02\n",
      " -2.3937e-02  1.4684e-02  4.4464e-03\n",
      "  2.8715e-02  2.9729e-02 -3.8798e-02\n",
      "\n",
      "(126,62 ,.,.) = \n",
      " -3.2338e-02  1.7656e-02 -4.0559e-02\n",
      "  2.4040e-04  1.3532e-02 -3.8088e-02\n",
      "  1.4787e-02 -1.6331e-02 -2.7486e-02\n",
      "\n",
      "(126,63 ,.,.) = \n",
      " -3.9562e-03  3.9559e-02 -4.8646e-03\n",
      " -4.2114e-03  6.8168e-03  2.1594e-02\n",
      "  8.1952e-03  2.5801e-03 -4.8590e-03\n",
      "      ⋮  \n",
      "\n",
      "(127, 0 ,.,.) = \n",
      " -1.1763e-02 -2.9278e-02 -1.3475e-02\n",
      " -3.5502e-02 -3.6866e-02 -1.0330e-02\n",
      "  1.1832e-02 -2.5148e-02  6.4809e-03\n",
      "\n",
      "(127, 1 ,.,.) = \n",
      " -3.1029e-02  1.5289e-02 -1.1572e-02\n",
      "  1.1579e-02  1.5766e-02 -3.3101e-02\n",
      "  1.2165e-02  2.1908e-02  1.9060e-02\n",
      "\n",
      "(127, 2 ,.,.) = \n",
      " -2.0684e-02  1.8027e-02 -3.5554e-02\n",
      " -3.3250e-02  2.4015e-03 -8.0650e-04\n",
      " -2.3521e-02 -1.2440e-02  3.4706e-02\n",
      "    ... \n",
      "\n",
      "(127,61 ,.,.) = \n",
      " -2.8841e-02 -3.6643e-02 -8.5799e-03\n",
      " -2.1753e-02  2.7721e-02  3.2964e-02\n",
      " -3.6181e-02 -1.7336e-02 -1.2525e-02\n",
      "\n",
      "(127,62 ,.,.) = \n",
      " -3.7465e-02  1.1741e-02  1.8317e-02\n",
      " -4.1598e-02 -6.0892e-03 -4.0422e-02\n",
      " -2.1946e-02 -2.6850e-02  3.9790e-02\n",
      "\n",
      "(127,63 ,.,.) = \n",
      "  3.1224e-02  5.3029e-04  2.9705e-02\n",
      " -3.4974e-02  1.2473e-02  3.1996e-02\n",
      " -3.8336e-02 -1.3469e-02 -1.7633e-02\n",
      "[torch.cuda.FloatTensor of size 128x64x3x3 (GPU 0)]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      "  0.7777\n",
      " -3.3708\n",
      " -2.5865\n",
      " -0.9634\n",
      " -0.8293\n",
      "  0.2089\n",
      "  1.4881\n",
      " -1.6455\n",
      " -0.9257\n",
      "  0.9819\n",
      " -2.5268\n",
      "  1.1990\n",
      " -1.5306\n",
      "  3.2409\n",
      "  3.2987\n",
      " -3.7922\n",
      "  2.5411\n",
      "  0.6565\n",
      " -0.6144\n",
      " -0.1541\n",
      " -3.0275\n",
      "  0.9892\n",
      " -1.2270\n",
      " -2.5687\n",
      "  0.7669\n",
      " -1.7053\n",
      " -0.7173\n",
      " -1.5707\n",
      " -2.3217\n",
      " -3.5638\n",
      " -2.4635\n",
      " -1.1045\n",
      "  0.1886\n",
      " -3.8577\n",
      " -2.0338\n",
      " -1.1239\n",
      "  3.8638\n",
      " -0.2038\n",
      " -3.6413\n",
      " -2.4159\n",
      "  3.0360\n",
      "  0.6403\n",
      "  1.0246\n",
      " -3.2819\n",
      "  1.8699\n",
      " -3.4799\n",
      "  3.3849\n",
      "  3.6674\n",
      " -2.4711\n",
      "  3.0183\n",
      " -2.9990\n",
      "  2.1115\n",
      "  3.7818\n",
      " -1.2119\n",
      "  2.9707\n",
      "  2.1832\n",
      "  3.9010\n",
      " -2.7618\n",
      " -1.4319\n",
      "  1.8579\n",
      " -1.3168\n",
      " -2.1178\n",
      "  0.5885\n",
      " -3.8297\n",
      " -3.8863\n",
      " -0.3725\n",
      "  1.9993\n",
      " -3.4798\n",
      " -0.1362\n",
      "  2.4618\n",
      "  0.0505\n",
      " -3.4741\n",
      "  1.9730\n",
      "  1.2524\n",
      "  3.5359\n",
      "  2.3012\n",
      " -1.3586\n",
      "  2.7166\n",
      "  0.7369\n",
      " -2.1158\n",
      " -3.3746\n",
      " -0.2696\n",
      "  1.5596\n",
      "  2.5047\n",
      "  1.7859\n",
      "  1.5038\n",
      "  1.6145\n",
      "  3.3140\n",
      " -0.1043\n",
      "  3.7466\n",
      " -2.3220\n",
      "  2.8623\n",
      " -0.3984\n",
      "  1.4973\n",
      "  3.6677\n",
      " -0.2055\n",
      " -1.2947\n",
      "  0.0334\n",
      " -2.2954\n",
      "  2.4266\n",
      "  2.1011\n",
      "  1.5076\n",
      " -0.8840\n",
      " -0.3651\n",
      "  2.2425\n",
      "  1.9192\n",
      "  3.7621\n",
      " -2.8408\n",
      "  2.4794\n",
      " -2.6844\n",
      " -1.7895\n",
      " -2.6444\n",
      " -2.1354\n",
      "  0.5269\n",
      "  4.0842\n",
      " -0.4635\n",
      " -4.0651\n",
      " -0.3037\n",
      " -0.0124\n",
      "  3.6250\n",
      "  0.1786\n",
      "  3.6516\n",
      "  1.3553\n",
      "  3.0460\n",
      "  1.2617\n",
      "  0.8975\n",
      " -3.8248\n",
      " -0.5145\n",
      "[torch.cuda.FloatTensor of size 128 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0.9491\n",
      " 0.5162\n",
      " 0.8521\n",
      " 0.1844\n",
      " 0.4999\n",
      " 0.5233\n",
      " 0.5530\n",
      " 0.5244\n",
      " 0.7579\n",
      " 0.6531\n",
      " 0.6713\n",
      " 0.2057\n",
      " 0.4475\n",
      " 0.0320\n",
      " 0.2759\n",
      " 0.0611\n",
      " 0.0716\n",
      " 0.8251\n",
      " 0.3535\n",
      " 0.9061\n",
      " 0.8848\n",
      " 0.8395\n",
      " 0.3462\n",
      " 0.6458\n",
      " 0.8186\n",
      " 0.4156\n",
      " 0.6963\n",
      " 0.6100\n",
      " 0.1172\n",
      " 0.8248\n",
      " 0.7345\n",
      " 0.6357\n",
      " 0.9531\n",
      " 0.5124\n",
      " 0.2930\n",
      " 0.3785\n",
      " 0.1426\n",
      " 0.3139\n",
      " 0.8409\n",
      " 0.8003\n",
      " 0.1985\n",
      " 0.3925\n",
      " 0.1877\n",
      " 0.4750\n",
      " 0.9021\n",
      " 0.2670\n",
      " 0.6331\n",
      " 0.2445\n",
      " 0.6283\n",
      " 0.0090\n",
      " 0.7928\n",
      " 0.8461\n",
      " 0.1485\n",
      " 0.8569\n",
      " 0.1532\n",
      " 0.7867\n",
      " 0.7817\n",
      " 0.8784\n",
      " 0.4170\n",
      " 0.8089\n",
      " 0.3002\n",
      " 0.5085\n",
      " 0.2289\n",
      " 0.8451\n",
      " 0.5766\n",
      " 0.9749\n",
      " 0.9884\n",
      " 0.0998\n",
      " 0.6132\n",
      " 0.2974\n",
      " 0.5536\n",
      " 0.6537\n",
      " 0.3563\n",
      " 0.7104\n",
      " 0.0928\n",
      " 0.1633\n",
      " 0.8146\n",
      " 0.5861\n",
      " 0.9765\n",
      " 0.2227\n",
      " 0.9009\n",
      " 0.5355\n",
      " 0.7141\n",
      " 0.1447\n",
      " 0.6563\n",
      " 0.4671\n",
      " 0.8820\n",
      " 0.8257\n",
      " 0.8415\n",
      " 0.2234\n",
      " 0.5693\n",
      " 0.7399\n",
      " 0.6380\n",
      " 0.0649\n",
      " 0.9754\n",
      " 0.6856\n",
      " 0.0644\n",
      " 0.5216\n",
      " 0.5304\n",
      " 0.7108\n",
      " 0.3424\n",
      " 0.1480\n",
      " 0.8740\n",
      " 0.9575\n",
      " 0.2909\n",
      " 0.4714\n",
      " 0.8001\n",
      " 0.0577\n",
      " 0.4541\n",
      " 0.3892\n",
      " 0.6154\n",
      " 0.9139\n",
      " 0.3740\n",
      " 0.2966\n",
      " 0.3782\n",
      " 0.2613\n",
      " 0.8517\n",
      " 0.8098\n",
      " 0.0535\n",
      " 0.6939\n",
      " 0.7595\n",
      " 0.4487\n",
      " 0.7208\n",
      " 0.6585\n",
      " 0.5275\n",
      " 0.3414\n",
      " 0.6816\n",
      " 0.5935\n",
      "[torch.cuda.FloatTensor of size 128 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.cuda.FloatTensor of size 128 (GPU 0)]\n",
      ", Parameter containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  2.3491e-02  1.1033e-02  3.8104e-03\n",
      " -6.0814e-03  1.1732e-03 -8.9948e-03\n",
      " -2.5261e-02 -1.1145e-02 -2.5419e-02\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  2.1551e-02  1.2800e-02  2.6465e-02\n",
      "  9.6015e-03  1.8015e-02  1.6626e-02\n",
      " -2.5503e-02 -1.9862e-02  8.7850e-03\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      " -1.6308e-02 -1.5352e-02 -1.8013e-02\n",
      "  8.4436e-03  2.0204e-02  2.4839e-02\n",
      "  8.8289e-03  1.0693e-02  2.6134e-02\n",
      "    ... \n",
      "\n",
      "( 0 ,125,.,.) = \n",
      " -9.6753e-03 -2.2851e-02 -2.3842e-02\n",
      " -2.7936e-02  1.3615e-02 -1.3380e-02\n",
      " -5.0077e-03 -2.0069e-02 -3.0191e-03\n",
      "\n",
      "( 0 ,126,.,.) = \n",
      "  1.8462e-02  3.9517e-03  7.3611e-03\n",
      "  2.0090e-02 -1.4642e-02 -8.2393e-03\n",
      "  8.6056e-03 -5.6208e-03  2.2844e-03\n",
      "\n",
      "( 0 ,127,.,.) = \n",
      "  5.2189e-03 -2.2016e-02 -2.1806e-02\n",
      "  2.5133e-02 -1.1435e-02  3.4907e-03\n",
      "  1.8649e-02  4.3652e-03  2.8304e-02\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  2.0715e-02 -1.3381e-02  5.1532e-03\n",
      "  2.6334e-02 -6.1453e-03 -2.2406e-02\n",
      " -4.0244e-03  1.0704e-03 -4.5498e-03\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      " -2.1622e-02 -1.0635e-02 -1.0368e-02\n",
      "  3.8680e-03 -5.3053e-03  2.6872e-03\n",
      " -1.9960e-02 -1.7190e-02 -1.2363e-02\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  5.4015e-03  9.6798e-03 -6.8905e-03\n",
      "  2.9288e-02 -1.4560e-02 -1.5825e-02\n",
      "  2.8062e-02 -2.9168e-02 -1.0819e-02\n",
      "    ... \n",
      "\n",
      "( 1 ,125,.,.) = \n",
      " -1.0602e-02  2.4701e-02 -4.8009e-03\n",
      " -1.0051e-02  2.2442e-02  1.0934e-02\n",
      " -2.2393e-02 -2.4664e-02  1.8083e-02\n",
      "\n",
      "( 1 ,126,.,.) = \n",
      "  7.9998e-03  2.4508e-02  9.4331e-03\n",
      " -1.2950e-02  1.9545e-03 -2.1718e-03\n",
      " -2.8154e-03 -3.9584e-03  1.4322e-03\n",
      "\n",
      "( 1 ,127,.,.) = \n",
      "  1.8483e-02  2.7789e-02 -1.2416e-02\n",
      " -1.0194e-02 -2.0122e-02 -1.1211e-02\n",
      " -2.0353e-03  7.5260e-03  2.5627e-03\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      " -9.2489e-03  2.9892e-03 -2.2723e-02\n",
      " -6.4008e-03  2.0352e-02  8.5408e-03\n",
      " -9.0665e-03  2.6538e-02 -4.7488e-03\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  4.1508e-03  1.0537e-02 -1.9994e-02\n",
      " -2.3306e-02 -6.5848e-03 -4.9744e-04\n",
      "  7.1335e-03 -1.8460e-02  1.1587e-03\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      " -2.3607e-02 -2.0950e-02  5.0260e-03\n",
      "  1.8269e-02  2.8198e-02 -1.7361e-02\n",
      " -1.9180e-02  1.4517e-02  2.5285e-02\n",
      "    ... \n",
      "\n",
      "( 2 ,125,.,.) = \n",
      " -2.1937e-02  2.3991e-02  1.0702e-02\n",
      " -1.7814e-02 -1.1781e-02  7.5373e-03\n",
      " -2.6544e-02 -2.0836e-03 -1.2498e-02\n",
      "\n",
      "( 2 ,126,.,.) = \n",
      " -2.9428e-02  2.6198e-02  1.8431e-02\n",
      " -3.4852e-03  2.7924e-02  1.0072e-02\n",
      "  2.0118e-02  1.5897e-02  9.6985e-03\n",
      "\n",
      "( 2 ,127,.,.) = \n",
      "  1.9756e-02 -2.5977e-02 -1.2462e-02\n",
      "  1.1136e-02  2.3062e-02  2.5217e-02\n",
      " -4.7289e-03 -1.1674e-02 -3.4515e-03\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(125, 0 ,.,.) = \n",
      "  7.6510e-03 -1.9914e-03  2.4125e-02\n",
      "  2.6537e-02 -2.0254e-02  2.7506e-02\n",
      " -1.0296e-02 -1.0750e-02  8.4319e-03\n",
      "\n",
      "(125, 1 ,.,.) = \n",
      " -2.3211e-02  3.5714e-03  2.5435e-02\n",
      " -1.1739e-02 -2.5688e-02  9.8120e-03\n",
      "  1.6620e-02 -1.7423e-02 -1.3192e-02\n",
      "\n",
      "(125, 2 ,.,.) = \n",
      "  6.8954e-03 -1.1439e-02 -6.0926e-03\n",
      "  2.8046e-02  6.2655e-04 -3.0820e-03\n",
      "  1.7359e-02  1.0213e-03 -1.0618e-02\n",
      "    ... \n",
      "\n",
      "(125,125,.,.) = \n",
      " -2.0163e-02 -2.3537e-02  1.4319e-02\n",
      "  1.5886e-03  6.8604e-03  1.1183e-03\n",
      " -2.2344e-02 -2.6640e-02  3.6885e-03\n",
      "\n",
      "(125,126,.,.) = \n",
      " -1.9281e-02  7.2398e-03  3.9179e-03\n",
      "  6.0482e-03 -1.4014e-02  1.1344e-02\n",
      " -1.6538e-02  1.0497e-03 -8.2413e-03\n",
      "\n",
      "(125,127,.,.) = \n",
      " -2.7146e-02  1.6351e-04  2.2395e-02\n",
      "  7.7795e-03  1.7900e-03 -1.2252e-02\n",
      "  1.8830e-02 -1.3983e-02 -3.0398e-03\n",
      "      ⋮  \n",
      "\n",
      "(126, 0 ,.,.) = \n",
      "  2.6350e-03 -2.1586e-02  1.0730e-02\n",
      "  1.8862e-02  2.8705e-02 -2.3935e-02\n",
      " -1.1271e-02 -8.3872e-03  1.8939e-02\n",
      "\n",
      "(126, 1 ,.,.) = \n",
      " -4.5399e-03  1.7274e-02 -2.9002e-02\n",
      " -2.7532e-02  2.4131e-02  1.7610e-02\n",
      "  3.9451e-03  2.0075e-02  1.1404e-02\n",
      "\n",
      "(126, 2 ,.,.) = \n",
      " -2.8214e-02  2.5692e-02  8.6098e-04\n",
      " -2.0261e-02 -2.6747e-02 -3.5022e-03\n",
      "  3.8394e-03 -7.6079e-03 -1.1734e-02\n",
      "    ... \n",
      "\n",
      "(126,125,.,.) = \n",
      " -2.7912e-02 -2.7154e-02 -2.4235e-02\n",
      "  2.6416e-02  1.3383e-02 -1.8252e-02\n",
      "  2.7813e-02  1.8415e-02  1.5748e-02\n",
      "\n",
      "(126,126,.,.) = \n",
      " -2.2597e-02 -2.2471e-02  2.8053e-02\n",
      "  2.1176e-02  1.1843e-02  1.0115e-02\n",
      "  1.6872e-02  4.7771e-03 -2.3238e-02\n",
      "\n",
      "(126,127,.,.) = \n",
      "  2.9457e-02 -1.8316e-02 -6.5109e-03\n",
      "  3.6532e-03 -1.3079e-02 -2.7906e-03\n",
      " -2.6943e-02  1.8299e-02 -1.7060e-02\n",
      "      ⋮  \n",
      "\n",
      "(127, 0 ,.,.) = \n",
      " -1.0323e-02 -5.1200e-03 -1.2289e-02\n",
      " -1.4674e-02 -1.3507e-02 -1.4333e-02\n",
      " -2.3116e-02  1.0874e-03 -2.7048e-02\n",
      "\n",
      "(127, 1 ,.,.) = \n",
      "  2.4991e-02  1.8120e-02 -7.3337e-04\n",
      " -9.2142e-03 -3.9974e-03 -1.4398e-02\n",
      "  2.3362e-02 -1.2500e-02 -2.3924e-02\n",
      "\n",
      "(127, 2 ,.,.) = \n",
      "  9.1793e-04  2.5969e-02  2.4797e-02\n",
      " -2.7031e-03  1.4911e-02 -3.5655e-03\n",
      "  1.4556e-02 -1.7610e-02 -1.5507e-02\n",
      "    ... \n",
      "\n",
      "(127,125,.,.) = \n",
      " -1.7293e-02  2.7180e-02 -9.4928e-03\n",
      "  2.5161e-02  1.8281e-02 -5.7704e-03\n",
      " -1.8208e-02  1.9575e-04  2.3748e-02\n",
      "\n",
      "(127,126,.,.) = \n",
      " -2.1987e-02 -3.4027e-03  2.3482e-02\n",
      "  9.2005e-03 -5.4570e-03 -6.7166e-03\n",
      " -2.1675e-02 -3.8482e-03  2.5040e-02\n",
      "\n",
      "(127,127,.,.) = \n",
      " -2.2734e-02  1.9483e-04  9.9896e-03\n",
      " -2.1190e-02 -1.2730e-02  1.9718e-02\n",
      " -4.8339e-03 -2.5623e-04  8.7949e-03\n",
      "[torch.cuda.FloatTensor of size 128x128x3x3 (GPU 0)]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      " -0.9581\n",
      " -2.5001\n",
      "  1.4469\n",
      " -1.0779\n",
      "  0.6806\n",
      "  1.9628\n",
      " -0.3501\n",
      "  1.5195\n",
      "  2.0270\n",
      " -2.8402\n",
      " -0.8620\n",
      " -1.8291\n",
      " -2.7805\n",
      " -2.0211\n",
      " -0.5616\n",
      "  1.3309\n",
      " -1.1272\n",
      " -2.6436\n",
      " -0.6125\n",
      " -2.5573\n",
      "  0.9483\n",
      "  1.8854\n",
      "  1.2436\n",
      " -1.8739\n",
      "  1.2493\n",
      " -1.0271\n",
      " -2.6755\n",
      "  0.2187\n",
      " -1.0534\n",
      "  0.0029\n",
      "  1.2330\n",
      "  0.1382\n",
      " -0.5573\n",
      " -2.1696\n",
      " -1.1112\n",
      " -0.2310\n",
      " -0.9468\n",
      " -0.5450\n",
      "  1.0699\n",
      "  2.8879\n",
      "  0.5660\n",
      " -1.4040\n",
      " -2.5211\n",
      "  2.5608\n",
      " -2.0678\n",
      " -0.2259\n",
      "  0.7210\n",
      "  0.7013\n",
      "  2.8156\n",
      "  2.8444\n",
      " -0.6890\n",
      "  2.0725\n",
      " -0.7137\n",
      "  1.8480\n",
      "  2.5014\n",
      "  2.2296\n",
      "  0.2993\n",
      " -1.5744\n",
      "  1.6309\n",
      "  2.3635\n",
      " -2.6880\n",
      "  2.4187\n",
      "  1.1947\n",
      " -2.5076\n",
      "  1.7335\n",
      " -0.3177\n",
      "  2.8099\n",
      "  1.7984\n",
      "  2.7220\n",
      "  1.2136\n",
      " -1.2616\n",
      " -1.4779\n",
      "  0.5427\n",
      "  0.4362\n",
      " -2.7552\n",
      " -1.8388\n",
      "  1.5204\n",
      "  2.7453\n",
      "  0.4053\n",
      " -2.6452\n",
      " -0.3339\n",
      " -1.7561\n",
      " -0.3206\n",
      "  0.0163\n",
      " -1.3419\n",
      "  0.4265\n",
      "  0.1415\n",
      " -0.9744\n",
      " -1.6995\n",
      "  2.1279\n",
      " -2.3452\n",
      " -0.9448\n",
      "  0.6451\n",
      "  2.7613\n",
      " -1.1101\n",
      " -0.8354\n",
      " -2.5804\n",
      "  1.5963\n",
      "  2.3141\n",
      "  0.2573\n",
      "  2.6411\n",
      "  1.7285\n",
      "  0.1518\n",
      "  1.1798\n",
      " -1.7165\n",
      " -2.4445\n",
      " -0.5728\n",
      "  2.8264\n",
      " -0.9050\n",
      "  1.8321\n",
      " -2.7012\n",
      " -0.9413\n",
      " -1.7783\n",
      " -1.6088\n",
      "  1.9291\n",
      "  1.1975\n",
      " -2.0705\n",
      "  1.1398\n",
      "  0.8180\n",
      " -0.0960\n",
      " -0.5781\n",
      " -1.9776\n",
      "  0.3367\n",
      " -1.3855\n",
      " -1.4687\n",
      " -2.9078\n",
      " -1.5039\n",
      " -0.7416\n",
      "[torch.cuda.FloatTensor of size 128 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0.0195\n",
      " 0.7013\n",
      " 0.4737\n",
      " 0.3795\n",
      " 0.5055\n",
      " 0.8793\n",
      " 0.6463\n",
      " 0.2348\n",
      " 0.4604\n",
      " 0.8909\n",
      " 0.9039\n",
      " 0.4057\n",
      " 0.1994\n",
      " 0.5907\n",
      " 0.3232\n",
      " 0.7695\n",
      " 0.4861\n",
      " 0.0307\n",
      " 0.5708\n",
      " 0.0327\n",
      " 0.7180\n",
      " 0.4726\n",
      " 0.9923\n",
      " 0.7654\n",
      " 0.3400\n",
      " 0.8368\n",
      " 0.8347\n",
      " 0.2038\n",
      " 0.8506\n",
      " 0.2910\n",
      " 0.3292\n",
      " 0.3547\n",
      " 0.4937\n",
      " 0.0136\n",
      " 0.3796\n",
      " 0.9612\n",
      " 0.1516\n",
      " 0.0904\n",
      " 0.4699\n",
      " 0.1685\n",
      " 0.9906\n",
      " 0.7430\n",
      " 0.2038\n",
      " 0.0380\n",
      " 0.8549\n",
      " 0.9839\n",
      " 0.0010\n",
      " 0.3229\n",
      " 0.4127\n",
      " 0.3208\n",
      " 0.2431\n",
      " 0.4312\n",
      " 0.7202\n",
      " 0.3350\n",
      " 0.1334\n",
      " 0.5627\n",
      " 0.0513\n",
      " 0.8253\n",
      " 0.1197\n",
      " 0.7019\n",
      " 0.1615\n",
      " 0.2983\n",
      " 0.1058\n",
      " 0.2332\n",
      " 0.0917\n",
      " 0.4373\n",
      " 0.6042\n",
      " 0.0846\n",
      " 0.0258\n",
      " 0.3265\n",
      " 0.2583\n",
      " 0.4686\n",
      " 0.1023\n",
      " 0.5439\n",
      " 0.9654\n",
      " 0.3992\n",
      " 0.2988\n",
      " 0.6457\n",
      " 0.4336\n",
      " 0.5301\n",
      " 0.1831\n",
      " 0.7767\n",
      " 0.6724\n",
      " 0.9631\n",
      " 0.7924\n",
      " 0.9185\n",
      " 0.6566\n",
      " 0.3527\n",
      " 0.9381\n",
      " 0.4759\n",
      " 0.3817\n",
      " 0.2020\n",
      " 0.5101\n",
      " 0.9351\n",
      " 0.1438\n",
      " 0.7153\n",
      " 0.8327\n",
      " 0.3119\n",
      " 0.1921\n",
      " 0.2867\n",
      " 0.7344\n",
      " 0.1655\n",
      " 0.5706\n",
      " 0.3094\n",
      " 0.7250\n",
      " 0.9297\n",
      " 0.9152\n",
      " 0.4428\n",
      " 0.4860\n",
      " 0.6249\n",
      " 0.0916\n",
      " 0.7502\n",
      " 0.0496\n",
      " 0.0909\n",
      " 0.1564\n",
      " 0.2364\n",
      " 0.9443\n",
      " 0.9705\n",
      " 0.5768\n",
      " 0.7555\n",
      " 0.3978\n",
      " 0.1047\n",
      " 0.8643\n",
      " 0.2355\n",
      " 0.6777\n",
      " 0.3571\n",
      " 0.5000\n",
      " 0.7905\n",
      "[torch.cuda.FloatTensor of size 128 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.cuda.FloatTensor of size 128 (GPU 0)]\n",
      ", Parameter containing:\n",
      "( 0 , 0 ,.,.) = \n",
      " -1.5387e-02 -2.1314e-02 -5.3611e-03\n",
      " -2.5633e-02  4.9565e-06 -1.4212e-02\n",
      "  1.6052e-02  8.0388e-03  7.3656e-03\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  1.2486e-02 -8.3795e-03  6.6196e-03\n",
      " -3.6096e-03  1.9863e-02 -1.1172e-02\n",
      "  6.1769e-03 -1.1876e-02  2.2150e-02\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      " -8.1311e-03 -1.8284e-02  2.7969e-02\n",
      "  2.3631e-03 -6.2183e-03 -1.6211e-02\n",
      "  1.8091e-02 -2.6765e-02 -2.0016e-03\n",
      "    ... \n",
      "\n",
      "( 0 ,125,.,.) = \n",
      " -2.1165e-02 -1.3226e-02  1.6575e-02\n",
      "  2.2733e-02 -4.4312e-03 -1.8643e-02\n",
      "  2.8952e-02 -1.4668e-02  8.7945e-03\n",
      "\n",
      "( 0 ,126,.,.) = \n",
      "  1.8387e-02 -2.5311e-02 -2.5561e-02\n",
      " -1.0882e-02 -1.4853e-02  2.0692e-02\n",
      "  2.0867e-02  4.3895e-03  2.1188e-02\n",
      "\n",
      "( 0 ,127,.,.) = \n",
      "  1.8424e-02  7.8998e-03 -2.3393e-02\n",
      "  2.1956e-02  1.3308e-02 -2.7837e-02\n",
      " -2.4016e-02 -1.7172e-02  1.3009e-02\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  7.5735e-03 -1.3811e-02 -3.9786e-03\n",
      "  1.3233e-02  5.7323e-03 -2.4959e-02\n",
      " -2.5373e-02 -1.4174e-02  2.6900e-02\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  1.5554e-02 -5.3862e-03 -2.3634e-02\n",
      " -2.3713e-02 -2.8277e-02  2.3866e-02\n",
      "  2.0726e-02  2.3759e-02 -1.6146e-03\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      "  2.1304e-02 -2.3076e-04 -1.1134e-02\n",
      "  1.1148e-02  2.4468e-02 -9.4262e-03\n",
      " -1.2264e-02  5.1491e-03 -1.7055e-02\n",
      "    ... \n",
      "\n",
      "( 1 ,125,.,.) = \n",
      "  7.6582e-03  1.8072e-02  2.0887e-03\n",
      "  7.5216e-03 -1.5417e-02 -2.2615e-02\n",
      " -1.7739e-02  2.5176e-02  2.0803e-02\n",
      "\n",
      "( 1 ,126,.,.) = \n",
      "  2.4443e-02 -7.4867e-03 -2.8836e-02\n",
      " -9.0089e-03  1.3498e-02 -1.2005e-02\n",
      " -1.8227e-02  2.8186e-02  1.5485e-02\n",
      "\n",
      "( 1 ,127,.,.) = \n",
      " -1.6551e-02  1.5839e-02  7.1133e-03\n",
      " -2.1168e-02 -2.8574e-02 -9.7871e-03\n",
      " -1.7148e-02  3.5131e-03  2.7031e-02\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  2.0511e-02  2.4130e-02  1.8049e-02\n",
      " -9.8272e-03 -8.9367e-03 -2.2712e-02\n",
      "  4.6162e-03  2.3431e-02 -2.9133e-02\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  7.9718e-03  1.1135e-02 -2.2284e-02\n",
      "  5.3615e-03 -2.0541e-02 -1.6353e-02\n",
      " -4.1706e-03  1.5066e-02  1.6903e-02\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  2.3990e-02 -2.6484e-02 -8.7536e-03\n",
      "  7.0255e-03  1.7002e-02  1.1064e-02\n",
      " -2.7520e-02  4.1832e-03 -9.4296e-03\n",
      "    ... \n",
      "\n",
      "( 2 ,125,.,.) = \n",
      " -1.9174e-02 -3.9837e-03 -2.6277e-02\n",
      "  1.9055e-02  1.6268e-04  2.0385e-02\n",
      "  1.7947e-02 -2.8369e-02  2.8899e-02\n",
      "\n",
      "( 2 ,126,.,.) = \n",
      "  1.2822e-02 -1.5100e-03  3.4736e-03\n",
      " -2.9263e-02 -1.1979e-02  2.1881e-02\n",
      " -3.5841e-03  2.6770e-02  2.2358e-02\n",
      "\n",
      "( 2 ,127,.,.) = \n",
      " -1.6546e-02  1.7913e-03 -1.5761e-03\n",
      " -3.2224e-03 -7.5105e-03 -1.4248e-02\n",
      "  1.4784e-02  8.0521e-03  5.8192e-03\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(253, 0 ,.,.) = \n",
      "  1.2832e-02  2.4802e-03  1.6450e-02\n",
      " -2.9391e-02 -2.6997e-02 -2.6762e-02\n",
      " -3.1039e-03  7.1991e-03  8.4564e-03\n",
      "\n",
      "(253, 1 ,.,.) = \n",
      "  6.8159e-03 -1.9457e-02  4.9945e-03\n",
      "  2.5995e-02  2.5453e-02 -1.5472e-02\n",
      "  1.7219e-02 -3.8654e-04  1.3154e-02\n",
      "\n",
      "(253, 2 ,.,.) = \n",
      " -1.3947e-02 -2.8136e-02 -2.7636e-02\n",
      " -1.0127e-02  1.4817e-02  2.3909e-02\n",
      " -1.6054e-02 -2.4201e-02 -4.4990e-03\n",
      "    ... \n",
      "\n",
      "(253,125,.,.) = \n",
      " -1.6747e-02 -1.7288e-02  2.1742e-02\n",
      " -1.3389e-03 -1.2436e-02  2.2232e-02\n",
      "  2.4206e-02 -3.6452e-03  2.6694e-02\n",
      "\n",
      "(253,126,.,.) = \n",
      "  4.1701e-03 -5.8502e-03 -1.1108e-02\n",
      "  1.1988e-02  1.0919e-02 -2.3105e-02\n",
      " -4.2782e-03 -1.3384e-02 -1.2777e-02\n",
      "\n",
      "(253,127,.,.) = \n",
      "  6.4009e-03  1.7650e-02 -2.7938e-02\n",
      "  7.5827e-03  1.8622e-02 -2.5840e-02\n",
      "  2.0570e-02  1.6856e-02  2.4298e-02\n",
      "      ⋮  \n",
      "\n",
      "(254, 0 ,.,.) = \n",
      " -1.9277e-02 -8.1783e-03  7.7168e-03\n",
      " -2.3365e-03  3.1107e-03  2.3214e-02\n",
      "  1.6852e-02  2.7457e-02  1.7558e-02\n",
      "\n",
      "(254, 1 ,.,.) = \n",
      " -1.4463e-02  1.4217e-02  1.8135e-03\n",
      "  2.0888e-02  3.0866e-03  2.7813e-02\n",
      " -1.4733e-02  4.3459e-03 -1.0188e-02\n",
      "\n",
      "(254, 2 ,.,.) = \n",
      "  1.1188e-02 -1.9237e-02  2.8136e-02\n",
      "  2.8985e-02  1.7382e-02 -1.6448e-02\n",
      " -1.1874e-02 -2.7434e-02  2.6770e-02\n",
      "    ... \n",
      "\n",
      "(254,125,.,.) = \n",
      "  2.4586e-02 -2.3270e-02  1.9068e-02\n",
      " -2.4135e-02 -2.8651e-02  2.4859e-02\n",
      "  7.2305e-03  2.5463e-03  2.1285e-02\n",
      "\n",
      "(254,126,.,.) = \n",
      "  9.9844e-03  5.6138e-04  8.7809e-03\n",
      "  1.1535e-02  2.7122e-02  2.2691e-02\n",
      " -2.0372e-02 -2.5175e-02 -7.5537e-03\n",
      "\n",
      "(254,127,.,.) = \n",
      " -1.4637e-02 -1.3677e-02  1.6508e-02\n",
      "  2.3729e-02  3.8283e-03  2.4031e-02\n",
      "  1.4750e-02 -7.3808e-03 -2.1846e-02\n",
      "      ⋮  \n",
      "\n",
      "(255, 0 ,.,.) = \n",
      " -2.6511e-02 -8.7343e-03  5.6901e-03\n",
      "  1.7295e-02  2.3684e-02  3.9088e-03\n",
      " -2.6214e-02  2.2810e-03  1.5703e-02\n",
      "\n",
      "(255, 1 ,.,.) = \n",
      "  1.3985e-02  7.6729e-04  2.0731e-02\n",
      "  8.0969e-03 -8.5191e-03  1.9839e-02\n",
      "  1.9410e-02  6.4363e-03 -2.3650e-02\n",
      "\n",
      "(255, 2 ,.,.) = \n",
      "  4.9235e-03  6.6108e-03  1.6585e-02\n",
      " -1.1202e-02  2.7428e-02  9.7415e-03\n",
      " -5.6214e-03 -6.7572e-03 -2.7392e-03\n",
      "    ... \n",
      "\n",
      "(255,125,.,.) = \n",
      "  2.5946e-03  1.9814e-02  2.6654e-02\n",
      " -2.4151e-02 -1.9869e-02 -2.5635e-02\n",
      " -4.1810e-03 -2.9289e-02  2.5591e-03\n",
      "\n",
      "(255,126,.,.) = \n",
      " -2.3500e-02 -1.9035e-02  2.1216e-02\n",
      "  1.0810e-02 -1.7349e-02 -2.4841e-02\n",
      " -1.1933e-02  2.0042e-02 -1.1128e-02\n",
      "\n",
      "(255,127,.,.) = \n",
      " -1.2288e-02 -1.1992e-02 -1.9390e-03\n",
      "  2.8231e-02  1.7664e-02  1.1812e-02\n",
      "  2.3892e-02  4.1514e-03  1.2797e-02\n",
      "[torch.cuda.FloatTensor of size 256x128x3x3 (GPU 0)]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      " -0.5719\n",
      "  0.2753\n",
      "  1.7698\n",
      "  1.2940\n",
      "  2.3145\n",
      " -1.4961\n",
      "  0.9433\n",
      "  2.0328\n",
      "  0.0412\n",
      " -0.3043\n",
      " -0.2935\n",
      "  2.2638\n",
      " -1.1336\n",
      " -1.0182\n",
      "  1.0992\n",
      "  2.6527\n",
      " -1.2919\n",
      " -0.5982\n",
      "  2.5476\n",
      "  1.9670\n",
      " -2.6162\n",
      "  2.4163\n",
      " -1.7462\n",
      " -0.2930\n",
      " -0.8767\n",
      "  2.7929\n",
      "  2.4130\n",
      " -0.9595\n",
      " -1.4025\n",
      " -1.5961\n",
      " -1.1685\n",
      "  1.3502\n",
      " -0.5136\n",
      " -0.1612\n",
      " -1.5539\n",
      "  2.3053\n",
      " -0.6421\n",
      "  1.3336\n",
      " -2.2871\n",
      "  0.1244\n",
      "  0.1853\n",
      " -0.2514\n",
      "  0.5615\n",
      "  0.2452\n",
      " -1.3933\n",
      " -0.7035\n",
      " -2.7399\n",
      " -0.6345\n",
      " -0.6471\n",
      "  2.7931\n",
      " -0.7431\n",
      " -1.5205\n",
      "  2.1649\n",
      " -2.5682\n",
      " -2.4397\n",
      " -1.6782\n",
      "  1.9875\n",
      "  2.6873\n",
      "  2.8053\n",
      " -1.7901\n",
      " -2.3117\n",
      " -2.4414\n",
      "  2.8824\n",
      " -1.5927\n",
      "  0.0842\n",
      " -1.9601\n",
      " -2.6897\n",
      " -1.0971\n",
      "  0.4015\n",
      " -1.5047\n",
      "  0.8664\n",
      "  2.7889\n",
      " -2.7177\n",
      "  0.8721\n",
      "  1.3188\n",
      "  1.6162\n",
      " -1.8879\n",
      " -0.7742\n",
      "  2.7181\n",
      " -0.9235\n",
      "  0.1823\n",
      "  0.0571\n",
      "  1.2625\n",
      " -1.3433\n",
      "  2.8558\n",
      " -1.7622\n",
      " -0.4225\n",
      " -0.8339\n",
      "  2.8031\n",
      "  2.2988\n",
      " -0.3948\n",
      " -2.8772\n",
      "  0.1185\n",
      " -0.5855\n",
      "  2.8999\n",
      " -2.2291\n",
      "  1.6633\n",
      " -1.9475\n",
      "  0.1032\n",
      "  2.0914\n",
      " -2.7611\n",
      "  0.6840\n",
      "  1.9483\n",
      "  0.7005\n",
      " -1.4376\n",
      " -2.3842\n",
      "  0.7698\n",
      " -0.0604\n",
      "  1.3502\n",
      " -1.4687\n",
      "  1.0202\n",
      "  0.3908\n",
      "  2.8657\n",
      "  0.8361\n",
      " -1.0493\n",
      "  2.4638\n",
      " -1.7333\n",
      " -0.2809\n",
      "  1.5462\n",
      "  2.6235\n",
      "  0.5014\n",
      "  0.0259\n",
      "  0.6937\n",
      " -1.2167\n",
      " -2.3162\n",
      " -0.7863\n",
      " -0.5084\n",
      "  1.2787\n",
      " -2.3011\n",
      " -0.8606\n",
      "  2.2215\n",
      " -0.0975\n",
      "  1.3154\n",
      "  0.9994\n",
      " -0.6111\n",
      " -2.8600\n",
      "  1.5462\n",
      " -2.4441\n",
      "  1.9722\n",
      "  0.7481\n",
      "  2.4251\n",
      "  2.4562\n",
      " -0.4231\n",
      "  1.3296\n",
      "  1.0819\n",
      "  0.1768\n",
      "  2.6871\n",
      " -0.3819\n",
      " -0.4894\n",
      " -1.5216\n",
      " -0.5949\n",
      "  2.1216\n",
      "  2.6698\n",
      " -1.2779\n",
      "  0.7956\n",
      "  0.7769\n",
      "  1.1863\n",
      "  1.2594\n",
      "  2.7703\n",
      " -1.9177\n",
      " -2.2569\n",
      "  0.2042\n",
      "  2.1806\n",
      "  2.8455\n",
      "  0.9283\n",
      " -2.1398\n",
      "  2.6106\n",
      " -0.8307\n",
      "  1.5767\n",
      "  2.8036\n",
      " -2.3186\n",
      " -0.4246\n",
      " -2.3854\n",
      "  0.6753\n",
      "  2.1263\n",
      " -0.9590\n",
      "  0.8506\n",
      " -2.1250\n",
      "  2.4567\n",
      "  2.9068\n",
      "  0.6089\n",
      "  2.9279\n",
      " -1.1529\n",
      " -2.1815\n",
      "  1.3756\n",
      "  0.8919\n",
      " -1.9802\n",
      "  2.7356\n",
      " -1.1594\n",
      " -1.5448\n",
      "  0.9997\n",
      " -0.6715\n",
      "  1.2624\n",
      "  1.2455\n",
      "  1.3832\n",
      " -1.6920\n",
      " -2.7715\n",
      "  1.9624\n",
      " -2.8065\n",
      " -1.4859\n",
      "  2.6538\n",
      " -1.5642\n",
      "  0.6897\n",
      " -0.0618\n",
      "  1.1628\n",
      " -2.7220\n",
      " -1.0195\n",
      "  1.3562\n",
      "  1.2646\n",
      " -1.1354\n",
      " -2.9034\n",
      "  1.3201\n",
      "  2.7586\n",
      " -2.2415\n",
      " -2.7681\n",
      "  1.2758\n",
      "  1.2258\n",
      " -0.7516\n",
      "  1.6100\n",
      "  1.8914\n",
      "  0.4628\n",
      "  2.8904\n",
      "  0.6735\n",
      "  0.0918\n",
      " -2.1207\n",
      "  1.2586\n",
      " -0.9253\n",
      " -2.2131\n",
      "  0.7225\n",
      " -2.5900\n",
      "  0.0957\n",
      " -0.2226\n",
      "  1.0920\n",
      "  0.5331\n",
      " -0.5582\n",
      " -2.6213\n",
      "  0.8418\n",
      " -0.9198\n",
      " -1.8052\n",
      "  1.1742\n",
      " -0.4865\n",
      " -1.7972\n",
      "  1.4935\n",
      " -1.9595\n",
      " -1.1680\n",
      "  0.7801\n",
      " -2.1866\n",
      "  0.7812\n",
      " -1.8324\n",
      " -1.1134\n",
      " -2.7952\n",
      " -1.0084\n",
      " -1.0513\n",
      " -2.7633\n",
      "  0.9704\n",
      " -0.2355\n",
      "[torch.cuda.FloatTensor of size 256 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0.4565\n",
      " 0.2742\n",
      " 0.2463\n",
      " 0.5028\n",
      " 0.7841\n",
      " 0.0789\n",
      " 0.6734\n",
      " 0.8867\n",
      " 0.7895\n",
      " 0.9111\n",
      " 0.2344\n",
      " 0.1253\n",
      " 0.3749\n",
      " 0.1601\n",
      " 0.3158\n",
      " 0.7094\n",
      " 0.5789\n",
      " 0.0262\n",
      " 0.8205\n",
      " 0.7091\n",
      " 0.2402\n",
      " 0.8271\n",
      " 0.8803\n",
      " 0.3539\n",
      " 0.2346\n",
      " 0.1402\n",
      " 0.3794\n",
      " 0.9846\n",
      " 0.5820\n",
      " 0.7746\n",
      " 0.6913\n",
      " 0.9838\n",
      " 0.0078\n",
      " 0.4877\n",
      " 0.6232\n",
      " 0.4298\n",
      " 0.4153\n",
      " 0.4527\n",
      " 0.6950\n",
      " 0.5850\n",
      " 0.8740\n",
      " 0.9818\n",
      " 0.0156\n",
      " 0.4302\n",
      " 0.3000\n",
      " 0.0510\n",
      " 0.5772\n",
      " 0.2138\n",
      " 0.8993\n",
      " 0.4432\n",
      " 0.3312\n",
      " 0.6949\n",
      " 0.3878\n",
      " 0.2956\n",
      " 0.7430\n",
      " 0.6236\n",
      " 0.1526\n",
      " 0.6842\n",
      " 0.4902\n",
      " 0.9884\n",
      " 0.7529\n",
      " 0.5533\n",
      " 0.6329\n",
      " 0.3222\n",
      " 0.0149\n",
      " 0.5586\n",
      " 0.8805\n",
      " 0.3038\n",
      " 0.2268\n",
      " 0.8998\n",
      " 0.5704\n",
      " 0.9181\n",
      " 0.4317\n",
      " 0.4706\n",
      " 0.8744\n",
      " 0.5013\n",
      " 0.5605\n",
      " 0.6643\n",
      " 0.2552\n",
      " 0.5940\n",
      " 0.7353\n",
      " 0.6087\n",
      " 0.0988\n",
      " 0.7950\n",
      " 0.9539\n",
      " 0.3773\n",
      " 0.7744\n",
      " 0.4185\n",
      " 0.8225\n",
      " 0.0623\n",
      " 0.5933\n",
      " 0.3984\n",
      " 0.0197\n",
      " 0.2208\n",
      " 0.2772\n",
      " 0.8776\n",
      " 0.6417\n",
      " 0.5774\n",
      " 0.5141\n",
      " 0.6751\n",
      " 0.8707\n",
      " 0.4972\n",
      " 0.0406\n",
      " 0.3457\n",
      " 0.7876\n",
      " 0.3282\n",
      " 0.5050\n",
      " 0.2461\n",
      " 0.1250\n",
      " 0.6409\n",
      " 0.2095\n",
      " 0.7097\n",
      " 0.9409\n",
      " 0.7890\n",
      " 0.1519\n",
      " 0.9604\n",
      " 0.5828\n",
      " 0.5182\n",
      " 0.3486\n",
      " 0.4307\n",
      " 0.1022\n",
      " 0.0461\n",
      " 0.3842\n",
      " 0.5988\n",
      " 0.6536\n",
      " 0.2903\n",
      " 0.2708\n",
      " 0.6567\n",
      " 0.7279\n",
      " 0.5976\n",
      " 0.2381\n",
      " 0.4614\n",
      " 0.4267\n",
      " 0.6267\n",
      " 0.6462\n",
      " 0.0725\n",
      " 0.5851\n",
      " 0.3576\n",
      " 0.9116\n",
      " 0.9155\n",
      " 0.8136\n",
      " 0.8776\n",
      " 0.0113\n",
      " 0.3428\n",
      " 0.0570\n",
      " 0.9496\n",
      " 0.6869\n",
      " 0.4029\n",
      " 0.3712\n",
      " 0.1138\n",
      " 0.0988\n",
      " 0.3293\n",
      " 0.2542\n",
      " 0.0615\n",
      " 0.4434\n",
      " 0.5547\n",
      " 0.2139\n",
      " 0.1151\n",
      " 0.9243\n",
      " 0.2213\n",
      " 0.8547\n",
      " 0.7679\n",
      " 0.0880\n",
      " 0.5450\n",
      " 0.5048\n",
      " 0.1725\n",
      " 0.8347\n",
      " 0.1065\n",
      " 0.3576\n",
      " 0.7790\n",
      " 0.1302\n",
      " 0.9016\n",
      " 0.6673\n",
      " 0.6843\n",
      " 0.3603\n",
      " 0.1436\n",
      " 0.2378\n",
      " 0.1208\n",
      " 0.7971\n",
      " 0.8436\n",
      " 0.8985\n",
      " 0.2460\n",
      " 0.8585\n",
      " 0.3607\n",
      " 0.7698\n",
      " 0.2823\n",
      " 0.9797\n",
      " 0.7472\n",
      " 0.0100\n",
      " 0.6599\n",
      " 0.2968\n",
      " 0.6272\n",
      " 0.5706\n",
      " 0.1782\n",
      " 0.1552\n",
      " 0.6982\n",
      " 0.0903\n",
      " 0.6067\n",
      " 0.2548\n",
      " 0.2152\n",
      " 0.7957\n",
      " 0.9624\n",
      " 0.5014\n",
      " 0.4057\n",
      " 0.7268\n",
      " 0.0351\n",
      " 0.3208\n",
      " 0.3160\n",
      " 0.3614\n",
      " 0.7887\n",
      " 0.2296\n",
      " 0.8834\n",
      " 0.1164\n",
      " 0.3158\n",
      " 0.2923\n",
      " 0.9921\n",
      " 0.2695\n",
      " 0.1071\n",
      " 0.5234\n",
      " 0.6709\n",
      " 0.1084\n",
      " 0.6861\n",
      " 0.9133\n",
      " 0.8904\n",
      " 0.3381\n",
      " 0.5374\n",
      " 0.6306\n",
      " 0.2869\n",
      " 0.9538\n",
      " 0.3437\n",
      " 0.6346\n",
      " 0.3616\n",
      " 0.7642\n",
      " 0.1827\n",
      " 0.5934\n",
      " 0.1695\n",
      " 0.0604\n",
      " 0.6538\n",
      " 0.1651\n",
      " 0.8709\n",
      " 0.1853\n",
      " 0.9341\n",
      " 0.6616\n",
      " 0.4239\n",
      " 0.6308\n",
      " 0.0596\n",
      " 0.1562\n",
      " 0.7599\n",
      " 0.2288\n",
      " 0.0897\n",
      " 0.3426\n",
      " 0.4215\n",
      " 0.5876\n",
      " 0.4438\n",
      " 0.8830\n",
      " 0.0761\n",
      "[torch.cuda.FloatTensor of size 256 (GPU 0)]\n",
      ", Parameter containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.cuda.FloatTensor of size 256 (GPU 0)]\n",
      ", Parameter containing:\n",
      "1.00000e-03 *\n",
      "-1.7067 -7.3858 -4.7405  ...  -1.6370  2.6084 -6.3883\n",
      "-7.6865  2.2383  7.4329  ...   3.0219 -0.6639  3.1576\n",
      " 3.0871  6.5381 -2.1544  ...  -2.5082  2.9675 -0.6128\n",
      "          ...             ⋱             ...          \n",
      " 0.2376 -5.3728  4.1019  ...   4.2408  1.3931  7.3552\n",
      "-2.4413  4.5068 -1.2026  ...  -4.5976  5.4645  5.5848\n",
      " 1.0813  0.2421  2.4712  ...   6.4661 -2.9400 -0.8806\n",
      "[torch.cuda.FloatTensor of size 1024x16384 (GPU 0)]\n",
      ", Parameter containing:\n",
      "1.00000e-03 *\n",
      " -1.8549\n",
      " -3.9748\n",
      " -3.7632\n",
      "    ⋮   \n",
      "  2.2666\n",
      "  0.3182\n",
      " -6.5288\n",
      "[torch.cuda.FloatTensor of size 1024 (GPU 0)]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      " 1.0357  0.1014 -2.6454  ...   0.2499  0.2891 -1.9387\n",
      "-2.6700 -1.0766 -2.1486  ...   2.1151 -0.5115  0.7061\n",
      "-2.5528  2.0144 -1.5101  ...  -2.5296  2.8471  1.1018\n",
      "          ...             ⋱             ...          \n",
      " 0.6052 -1.3250  0.8013  ...  -1.0541 -2.0387  0.6817\n",
      " 1.4834 -0.5680 -1.8850  ...   1.3127  1.1180 -1.1449\n",
      " 1.9096  3.1115 -2.3746  ...   2.3239  2.6635 -1.6891\n",
      "[torch.cuda.FloatTensor of size 10x1024 (GPU 0)]\n",
      ", Parameter containing:\n",
      "1.00000e-02 *\n",
      " -0.1062\n",
      " -0.4735\n",
      "  2.8719\n",
      "  2.6074\n",
      "  2.9608\n",
      "  1.2554\n",
      "  0.5900\n",
      "  0.1269\n",
      "  0.8957\n",
      "  1.4962\n",
      "[torch.cuda.FloatTensor of size 10 (GPU 0)]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "\n",
    "print (params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
