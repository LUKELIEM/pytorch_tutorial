{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE253 PA3 - Design a CNN \n",
    "\n",
    "First a bit of setup!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Python version:  3.6.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "import time\n",
    "import platform\n",
    "import random\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "\n",
    "We load the CIFAR-10 dataset. This might take a couple minutes the first time you do it, but the files should stay cached after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True,\n",
    "                          transform=T.ToTensor())\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our image data (and more relevantly, our intermediate feature maps) are initially N x C x H x W, where:\n",
    "\n",
    "* N is the number of datapoints  \n",
    "* C is the number of channels  \n",
    "* H is the height of the intermediate feature map in pixels  \n",
    "* W is the height of the intermediate feature map in pixels  \n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, that needs spatial understanding of where the intermediate features are relative to each other. When we input data into fully connected affine layers, however, we want each datapoint to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data. So, we use a \"Flatten\" operation to collapse the C x H x W values per representation into a single long vector. The Flatten function below first reads in the N, C, H, and W values from a given batch of data, and then returns a \"view\" of that data. \"View\" is analogous to numpy's \"reshape\" method: it reshapes x's dimensions to be N x ??, where ?? is allowed to be anything (in this case, it will be C x H x W, but we don't need to specify that explicitly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor # the CPU datatype\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "# This is a little utility that we'll use to reset the model\n",
    "# if we want to re-initialize all our parameters\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n",
    "        \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, num_epochs = 1, verbose=False):\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.9)    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "            \n",
    "        scheduler.step()    \n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var = Variable(x.type(gpu_dtype))\n",
    "            y_var = Variable(y.type(gpu_dtype).long())\n",
    "\n",
    "            scores = model(x_var)\n",
    "            \n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % print_every == 0 and verbose:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def check_accuracy(model, loader, verbose=False):\n",
    "    if verbose:\n",
    "        if loader.dataset.train:\n",
    "            print('Checking accuracy on validation set')\n",
    "        else:\n",
    "            print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in loader:\n",
    "        x_var = Variable(x.type(gpu_dtype), volatile=True)\n",
    "\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    if verbose:\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def generator():\n",
    "    \n",
    "    # Model - 4 layer Conv Layers\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(8192,1024),  # 5408=128*16*16 input size\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator():\n",
    "\n",
    "    # Model - 5 layer Conv Layers\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(8192,1024),  # 5408=128*16*16 input size\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model\n",
    "\n",
    "def generator():\n",
    "\n",
    "    Model - 6 layer Conv Layers\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=256),        \n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(16384,1024),  # 5408=128*16*16 input size\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator():\n",
    "\n",
    "    # Model - 5 layer Conv Layers (WIDER)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=256, kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=256),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(16384,1024),  # 5408=128*16*16 input siz\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model\n",
    "\"\"\"\n",
    "\n",
    "def generator():\n",
    "\n",
    "    # Model - 5 layer Conv Layers (WIDER)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=256, kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=256),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(16384,1024),  # 5408=128*16*16 input siz\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generator().type(gpu_dtype)\n",
    "\n",
    "x_gpu = torch.randn(64, 3, 32, 32).type(gpu_dtype)\n",
    "x_var_gpu = Variable(x_gpu.type(gpu_dtype)) # Construct a PyTorch Variable out of your input data\n",
    "ans = model(x_var_gpu)        # Feed it through the model! \n",
    "\n",
    "print (ans.shape)\n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(ans.size()), np.array([64, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy is 0.745. Training time for 1 epoch: 13.12 sec\n"
     ]
    }
   ],
   "source": [
    "model = generator().type(gpu_dtype)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00035, weight_decay=1e-10)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=1)\n",
    "val_acc = check_accuracy(model, loader_val)\n",
    "\n",
    "end = time.time()\n",
    "    \n",
    "print('validation accuracy is {0}. Training time for 1 epoch: {1:.2f} sec'.format(val_acc, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 5.882224702688513e-05, reg = 1e-10, validation accuracy is 0.671\n",
      "lr = 3.207152865895378e-05, reg = 1e-10, validation accuracy is 0.649\n",
      "lr = 9.798006024854252e-05, reg = 1e-10, validation accuracy is 0.696\n",
      "lr = 0.0015500672638029886, reg = 1e-10, validation accuracy is 0.7\n",
      "lr = 0.000233322407480608, reg = 1e-10, validation accuracy is 0.741\n",
      "lr = 0.001034725486107847, reg = 1e-10, validation accuracy is 0.732\n",
      "lr = 1.814455515451092e-05, reg = 1e-10, validation accuracy is 0.602\n",
      "lr = 0.0023977281239786394, reg = 1e-10, validation accuracy is 0.679\n",
      "lr = 0.00018592683890558467, reg = 1e-10, validation accuracy is 0.73\n",
      "lr = 0.00015828243833438324, reg = 1e-10, validation accuracy is 0.724\n",
      "lr = 1.703728984147158e-05, reg = 1e-10, validation accuracy is 0.609\n",
      "lr = 0.005171713154479716, reg = 1e-10, validation accuracy is 0.56\n",
      "lr = 0.00022262840711706407, reg = 1e-10, validation accuracy is 0.739\n",
      "lr = 0.0005543540968943043, reg = 1e-10, validation accuracy is 0.737\n",
      "lr = 0.0020646154334316882, reg = 1e-10, validation accuracy is 0.673\n",
      "lr = 0.000631269222563926, reg = 1e-10, validation accuracy is 0.733\n",
      "lr = 3.126458677944705e-05, reg = 1e-10, validation accuracy is 0.613\n",
      "lr = 3.0101779002806457e-05, reg = 1e-10, validation accuracy is 0.642\n",
      "lr = 0.0021052067759118327, reg = 1e-10, validation accuracy is 0.666\n",
      "lr = 0.00010797508629631022, reg = 1e-10, validation accuracy is 0.714\n",
      "Training time for 10 epochs: 176.47 sec\n",
      "In descending order of learning rate:\n",
      "lr = 0.005171713154479716, reg = 1e-10, validation accuracy is 0.56\n",
      "lr = 0.0023977281239786394, reg = 1e-10, validation accuracy is 0.679\n",
      "lr = 0.0021052067759118327, reg = 1e-10, validation accuracy is 0.666\n",
      "lr = 0.0020646154334316882, reg = 1e-10, validation accuracy is 0.673\n",
      "lr = 0.0015500672638029886, reg = 1e-10, validation accuracy is 0.7\n",
      "lr = 0.001034725486107847, reg = 1e-10, validation accuracy is 0.732\n",
      "lr = 0.000631269222563926, reg = 1e-10, validation accuracy is 0.733\n",
      "lr = 0.0005543540968943043, reg = 1e-10, validation accuracy is 0.737\n",
      "lr = 0.000233322407480608, reg = 1e-10, validation accuracy is 0.741\n",
      "lr = 0.00022262840711706407, reg = 1e-10, validation accuracy is 0.739\n",
      "lr = 0.00018592683890558467, reg = 1e-10, validation accuracy is 0.73\n",
      "lr = 0.00015828243833438324, reg = 1e-10, validation accuracy is 0.724\n",
      "lr = 0.00010797508629631022, reg = 1e-10, validation accuracy is 0.714\n",
      "lr = 9.798006024854252e-05, reg = 1e-10, validation accuracy is 0.696\n",
      "lr = 5.882224702688513e-05, reg = 1e-10, validation accuracy is 0.671\n",
      "lr = 3.207152865895378e-05, reg = 1e-10, validation accuracy is 0.649\n",
      "lr = 3.126458677944705e-05, reg = 1e-10, validation accuracy is 0.613\n",
      "lr = 3.0101779002806457e-05, reg = 1e-10, validation accuracy is 0.642\n",
      "lr = 1.814455515451092e-05, reg = 1e-10, validation accuracy is 0.602\n",
      "lr = 1.703728984147158e-05, reg = 1e-10, validation accuracy is 0.609\n"
     ]
    }
   ],
   "source": [
    "stat = []\n",
    "\n",
    "start = time.time()\n",
    "max_count = 20\n",
    "for count in range(max_count):\n",
    "    reg = 1e-10\n",
    "    lr = 10**random.uniform(-5,-2)\n",
    "    \n",
    "    model = generator().type(gpu_dtype)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    train(model, loss_fn, optimizer, num_epochs=1)\n",
    "    val_acc = check_accuracy(model, loader_val)\n",
    "    \n",
    "    print('lr = {}, reg = {}, validation accuracy is {}  '.format(lr, reg, val_acc))\n",
    "    stat.append([lr, reg, val_acc])\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "print('Training time for 10 epochs: {1:.2f} sec'.format(val_acc, end-start))\n",
    "\n",
    "sorted_stat = sorted(stat, key=lambda x: x[0], reverse=True)\n",
    "print (\"In descending order of learning rate:\")\n",
    "for lr, reg, val_acc in sorted_stat:\n",
    "    print('lr = {}, reg = {}, validation accuracy is {}  '.format(lr, reg, val_acc))    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust Learning Rate \n",
    "\n",
    "We turn down regularization (reg=1e-10), and do a coarse learning rate search over several multi-layer CNN with maxpooling.\n",
    "\n",
    "## Increase Depth\n",
    "\n",
    "####  Model 4-Conv Layers, 2 MaxPool Blocks\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (1): ReLU(inplace)\n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (4): ReLU(inplace)\n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (6): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (7): ReLU(inplace)\n",
    "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (10): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (11): ReLU(inplace)\n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (14): Flatten(\n",
    "  )\n",
    "  (15): Linear(in_features=8192, out_features=1024)\n",
    "  (16): ReLU(inplace)\n",
    "  (17): Linear(in_features=1024, out_features=10)\n",
    "\n",
    "* Training time for 1 epoch: 8.68 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "lr = 0.2839542464941698, reg = 1e-10, validation accuracy is 0.083  \n",
    "lr = 0.21651954228087467, reg = 1e-10, validation accuracy is 0.079   \n",
    "lr = 0.18749522641775604, reg = 1e-10, validation accuracy is 0.079   \n",
    "lr = 0.04615531370572979, reg = 1e-10, validation accuracy is 0.087   \n",
    "lr = 0.01949218798321564, reg = 1e-10, validation accuracy is 0.113   \n",
    "** lr = 0.0006625559311464299, reg = 1e-10, validation accuracy is 0.727 **   \n",
    "** r = 0.000144482779361209, reg = 1e-10, validation accuracy is 0.701 **  \n",
    "lr = 8.516588480512839e-05, reg = 1e-10, validation accuracy is 0.664  \n",
    "lr = 1.557003750655694e-05, reg = 1e-10, validation accuracy is 0.593  \n",
    "lr = 1.0379299460698738e-05, reg = 1e-10, validation accuracy is 0.559 \n",
    "\n",
    "####  Model 5-Conv Layers, 2 MaxPool Blocks\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (1): ReLU(inplace)\n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (4): ReLU(inplace)\n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (6): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (7): ReLU(inplace)\n",
    "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (10): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (11): ReLU(inplace)\n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (13): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (14): ReLU(inplace)\n",
    "  (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (17): Flatten(\n",
    "  )\n",
    "  (18): Linear(in_features=8192, out_features=1024)\n",
    "  (19): ReLU(inplace)\n",
    "  (20): Linear(in_features=1024, out_features=10)\n",
    ")\n",
    "\n",
    "* Training time for 1 epoch: 7.57 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "In descending order of learning rate:\n",
    "lr = 0.005171713154479716, reg = 1e-10, validation accuracy is 0.56  \n",
    "lr = 0.0023977281239786394, reg = 1e-10, validation accuracy is 0.679  \n",
    "lr = 0.0021052067759118327, reg = 1e-10, validation accuracy is 0.666  \n",
    "lr = 0.0020646154334316882, reg = 1e-10, validation accuracy is 0.673  \n",
    "lr = 0.0015500672638029886, reg = 1e-10, validation accuracy is 0.7  \n",
    "** lr = 0.001034725486107847, reg = 1e-10, validation accuracy is 0.732 **  \n",
    "** lr = 0.000631269222563926, reg = 1e-10, validation accuracy is 0.733 **  \n",
    "** lr = 0.0005543540968943043, reg = 1e-10, validation accuracy is 0.737 **  \n",
    "** lr = 0.000233322407480608, reg = 1e-10, validation accuracy is 0.741 **  \n",
    "** lr = 0.00022262840711706407, reg = 1e-10, validation accuracy is 0.739 **  \n",
    "** lr = 0.00018592683890558467, reg = 1e-10, validation accuracy is 0.73 **  \n",
    "** lr = 0.00015828243833438324, reg = 1e-10, validation accuracy is 0.724 **  \n",
    "lr = 0.00010797508629631022, reg = 1e-10, validation accuracy is 0.714  \n",
    "lr = 9.798006024854252e-05, reg = 1e-10, validation accuracy is 0.696  \n",
    "lr = 5.882224702688513e-05, reg = 1e-10, validation accuracy is 0.671  \n",
    "lr = 3.207152865895378e-05, reg = 1e-10, validation accuracy is 0.649  \n",
    "lr = 3.126458677944705e-05, reg = 1e-10, validation accuracy is 0.613  \n",
    "lr = 3.0101779002806457e-05, reg = 1e-10, validation accuracy is 0.642  \n",
    "lr = 1.814455515451092e-05, reg = 1e-10, validation accuracy is 0.602  \n",
    "lr = 1.703728984147158e-05, reg = 1e-10, validation accuracy is 0.609  \n",
    "\n",
    "####  Model 6-Conv Layers, 2 MaxPool Blocks\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (1): ReLU(inplace)\n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (4): ReLU(inplace)\n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (6): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (7): ReLU(inplace)\n",
    "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (10): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (11): ReLU(inplace)\n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (13): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (14): ReLU(inplace)\n",
    "  (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (16): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (17): ReLU(inplace)\n",
    "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (19): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (20): Flatten(\n",
    "  )\n",
    "  (21): Linear(in_features=16384, out_features=1024)\n",
    "  (22): ReLU(inplace)\n",
    "  (23): Linear(in_features=1024, out_features=10)\n",
    ")\n",
    "\n",
    "* Training time for 1 epoch: 12.99 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "lr = 0.007809235059540799, reg = 1e-10, validation accuracy is 0.397  \n",
    "lr = 0.005884487793553565, reg = 1e-10, validation accuracy is 0.468  \n",
    "lr = 0.005690937983509037, reg = 1e-10, validation accuracy is 0.486  \n",
    "** lr = 0.0005143479683944543, reg = 1e-10, validation accuracy is 0.708 **  \n",
    "** lr = 0.0004542994337330826, reg = 1e-10, validation accuracy is 0.728 **  \n",
    "** lr = 0.00023305794669548055, reg = 1e-10, validation accuracy is 0.735 **  \n",
    "** lr = 0.00014776247999586726, reg = 1e-10, validation accuracy is 0.703 **  \n",
    "** lr = 5.85992713405686e-05, reg = 1e-10, validation accuracy is 0.668 **   \n",
    "** lr = 2.108502413295989e-05, reg = 1e-10, validation accuracy is 0.629 **  \n",
    "lr = 1.8574849492178006e-05, reg = 1e-10, validation accuracy is 0.612  \n",
    "lr = 1.3270632405294917e-05, reg = 1e-10, validation accuracy is 0.586  \n",
    "lr = 8.865347011292369e-06, reg = 1e-10, validation accuracy is 0.597  \n",
    "lr = 8.470683213744055e-06, reg = 1e-10, validation accuracy is 0.575  \n",
    "\n",
    "\n",
    "## Increase Width\n",
    "\n",
    "####  Model 5-Conv Layers, 2 MaxPool Blocks (WIDER)\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (1): ReLU(inplace)\n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (4): ReLU(inplace)\n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (6): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (7): ReLU(inplace)\n",
    "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (10): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (11): ReLU(inplace)\n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (13): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (14): ReLU(inplace)\n",
    "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (17): Flatten(\n",
    "  )\n",
    "  (18): Linear(in_features=16384, out_features=1024)\n",
    "  (19): ReLU(inplace)\n",
    "  (20): Linear(in_features=1024, out_features=10)\n",
    ")\n",
    "\n",
    "* Training time for 1 epoch: 13.18 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "lr = 0.006511131263854212, reg = 1e-10, validation accuracy is 0.447  \n",
    "lr = 0.005311015630015579, reg = 1e-10, validation accuracy is 0.5  \n",
    "lr = 0.0050095585969268655, reg = 1e-10, validation accuracy is 0.468  \n",
    "lr = 0.0019763392774939607, reg = 1e-10, validation accuracy is 0.607  \n",
    "lr = 0.0016212594827078903, reg = 1e-10, validation accuracy is 0.67  \n",
    "lr = 0.0012378413601148973, reg = 1e-10, validation accuracy is 0.673  \n",
    "** lr = 0.0006205094279250759, reg = 1e-10, validation accuracy is 0.737 **  \n",
    "** lr = 0.0006055617870144327, reg = 1e-10, validation accuracy is 0.726 **  \n",
    "** lr = 0.0002567453541515327, reg = 1e-10, validation accuracy is 0.757 **  \n",
    "** lr = 0.00010598921967978786, reg = 1e-10, validation accuracy is 0.717 **  \n",
    "** lr = 7.918018060365135e-05, reg = 1e-10, validation accuracy is 0.728 **  \n",
    "lr = 5.3923032925417105e-05, reg = 1e-10, validation accuracy is 0.67  \n",
    "lr = 2.5770930840799296e-05, reg = 1e-10, validation accuracy is 0.664  \n",
    "lr = 1.0070525736216065e-05, reg = 1e-10, validation accuracy is 0.598  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 1.834628949407268e-05, reg = 4.781387738199418e-09, validation accuracy is 0.63  \n",
      "lr = 4.007498928855568e-05, reg = 1.0462145053481942e-05, validation accuracy is 0.66  \n",
      "lr = 6.5440784050296394e-06, reg = 1.460840922329886e-10, validation accuracy is 0.584  \n",
      "lr = 2.2601995271654264e-06, reg = 0.4816039172648769, validation accuracy is 0.43  \n",
      "lr = 0.0059948302614509005, reg = 0.010011618127031887, validation accuracy is 0.566  \n",
      "lr = 1.0608505969109444e-06, reg = 9.36159934357995e-08, validation accuracy is 0.429  \n",
      "lr = 0.008419751428795624, reg = 0.0035646738516316866, validation accuracy is 0.478  \n",
      "lr = 0.002831501424336825, reg = 2.1814028362557628e-05, validation accuracy is 0.594  \n",
      "lr = 0.0004420536106205546, reg = 2.0186822341150736e-06, validation accuracy is 0.768  \n",
      "lr = 0.00014157475047081133, reg = 3.515875715049107e-05, validation accuracy is 0.723  \n",
      "lr = 0.0017469433543108419, reg = 0.005407562156582751, validation accuracy is 0.588  \n",
      "lr = 0.0018436283136011092, reg = 1.20855073494988e-07, validation accuracy is 0.602  \n",
      "lr = 1.103067655335038e-06, reg = 1.3969242782012285e-06, validation accuracy is 0.433  \n",
      "lr = 0.00016799852379122324, reg = 15.613566194573618, validation accuracy is 0.098  \n",
      "lr = 3.312216301167796e-06, reg = 1.3208096729461642, validation accuracy is 0.394  \n",
      "lr = 7.049317699161044e-06, reg = 0.019993230642586797, validation accuracy is 0.59  \n",
      "lr = 5.494435066444071e-06, reg = 1.6931594998242051e-09, validation accuracy is 0.571  \n",
      "lr = 0.0006996954263941067, reg = 1.9038337189684477e-06, validation accuracy is 0.708  \n",
      "lr = 0.00037206712670449505, reg = 0.09927454316034201, validation accuracy is 0.614  \n",
      "lr = 5.268044462970665e-05, reg = 0.0948523510014383, validation accuracy is 0.668  \n",
      "lr = 1.0112212652872966e-05, reg = 0.020453604351085584, validation accuracy is 0.616  \n",
      "lr = 0.00011805442164972787, reg = 3.818327291174253e-10, validation accuracy is 0.716  \n",
      "lr = 4.1131199258244805e-06, reg = 0.009183569193389245, validation accuracy is 0.553  \n",
      "lr = 0.0019448764802993351, reg = 0.0014559406583695056, validation accuracy is 0.64  \n",
      "lr = 0.0001638932273529234, reg = 3.0703157061644324e-05, validation accuracy is 0.73  \n",
      "lr = 5.987749489253305e-06, reg = 3.193174800162297e-09, validation accuracy is 0.575  \n",
      "lr = 2.980838513237049e-05, reg = 3.9724783982491223, validation accuracy is 0.387  \n",
      "lr = 6.914399074312584e-05, reg = 0.030651772897969106, validation accuracy is 0.686  \n",
      "lr = 2.8276700188882648e-05, reg = 0.05565412975199819, validation accuracy is 0.618  \n",
      "lr = 0.0005251670566001226, reg = 0.0018050589295523598, validation accuracy is 0.699  \n",
      "lr = 4.625603296907752e-05, reg = 6.0699709968522045e-09, validation accuracy is 0.666  \n",
      "lr = 2.8013165961810122e-05, reg = 0.6740105236591744, validation accuracy is 0.543  \n",
      "lr = 1.4865817289651003e-05, reg = 28.45191209788082, validation accuracy is 0.321  \n",
      "lr = 0.005996111065727766, reg = 4.813600671695348e-06, validation accuracy is 0.428  \n",
      "lr = 0.00016151175929450816, reg = 0.001461378511321383, validation accuracy is 0.73  \n",
      "lr = 0.00011532989154129476, reg = 3.889665794272065, validation accuracy is 0.226  \n",
      "lr = 0.0002938522880460647, reg = 3.1116344006152496e-09, validation accuracy is 0.731  \n",
      "lr = 2.3012233654655408e-06, reg = 1.0587801567612161e-09, validation accuracy is 0.519  \n",
      "lr = 3.2066990160856126e-05, reg = 73.0011473426906, validation accuracy is 0.263  \n",
      "lr = 0.0006055829256460011, reg = 9.58996938648248e-07, validation accuracy is 0.722  \n",
      "lr = 0.002556305569075787, reg = 6.201957204054882e-06, validation accuracy is 0.57  \n",
      "lr = 0.0021901124260892647, reg = 0.0003707486641797913, validation accuracy is 0.606  \n",
      "lr = 1.3116142483651602e-06, reg = 0.02321093986222916, validation accuracy is 0.479  \n",
      "lr = 0.00015862184981477027, reg = 3.311901217036856e-07, validation accuracy is 0.72  \n",
      "lr = 0.002985900214736691, reg = 0.010453452867674394, validation accuracy is 0.529  \n",
      "lr = 2.019140109564537e-06, reg = 0.00023777504385718968, validation accuracy is 0.493  \n",
      "lr = 1.4115769829339359e-06, reg = 7.626434172108425, validation accuracy is 0.189  \n",
      "lr = 1.4783779752657483e-05, reg = 55.130951067603085, validation accuracy is 0.195  \n",
      "lr = 0.0002885154495256621, reg = 2.771973322549355e-09, validation accuracy is 0.75  \n",
      "lr = 0.0008867992873069955, reg = 1.4372398781436804, validation accuracy is 0.199  \n",
      "lr = 5.178320084401512e-06, reg = 3.125014916588725e-07, validation accuracy is 0.579  \n",
      "lr = 1.30366135150047e-06, reg = 24.68131034640062, validation accuracy is 0.117  \n",
      "lr = 3.13625482992454e-05, reg = 0.006702166937063668, validation accuracy is 0.67  \n",
      "lr = 1.0267141502637463e-05, reg = 2.2423114552249097e-05, validation accuracy is 0.624  \n",
      "lr = 0.0013869356779387546, reg = 5.94062005313746e-05, validation accuracy is 0.653  \n",
      "lr = 3.8290175559735334e-06, reg = 2.5761485147151517e-08, validation accuracy is 0.539  \n",
      "lr = 0.0005443722591657279, reg = 0.00017920546701173702, validation accuracy is 0.719  \n",
      "lr = 9.609980503912395e-05, reg = 0.005374903040295943, validation accuracy is 0.677  \n",
      "lr = 0.0003961550140640271, reg = 0.8105443384587647, validation accuracy is 0.37  \n",
      "lr = 1.8528189621301718e-06, reg = 4.746231249856485e-09, validation accuracy is 0.482  \n",
      "lr = 0.00822361091242141, reg = 7.4467018607870274, validation accuracy is 0.113  \n",
      "lr = 0.000348507497041526, reg = 1.4605422936453535e-05, validation accuracy is 0.725  \n",
      "lr = 1.5807948954963685e-06, reg = 4.214524828334788e-07, validation accuracy is 0.485  \n",
      "lr = 0.003373215466596708, reg = 1.0008602410294153e-09, validation accuracy is 0.586  \n",
      "lr = 1.056164027555874e-06, reg = 6.01442570862751e-09, validation accuracy is 0.434  \n",
      "lr = 0.00030976635881782815, reg = 1.9752562992451137e-05, validation accuracy is 0.737  \n",
      "lr = 3.348878693686202e-05, reg = 3.7300717080778774e-05, validation accuracy is 0.656  \n",
      "lr = 0.0003159819304478141, reg = 28.656846959736583, validation accuracy is 0.113  \n",
      "lr = 0.0002719530062001166, reg = 8.181890417359118e-05, validation accuracy is 0.714  \n",
      "lr = 1.647117910036382e-05, reg = 1.5768845674707156e-06, validation accuracy is 0.631  \n",
      "lr = 0.003732182285007303, reg = 2.7238935119576925e-05, validation accuracy is 0.563  \n",
      "lr = 0.005509688622390361, reg = 4.910230537193647e-10, validation accuracy is 0.506  \n",
      "lr = 0.0012393288000769702, reg = 5.12602146030666, validation accuracy is 0.113  \n",
      "lr = 7.764263308560473e-05, reg = 3.9283309473615766, validation accuracy is 0.203  \n",
      "lr = 0.0004122334077427315, reg = 6.4451833938235595e-09, validation accuracy is 0.747  \n",
      "lr = 2.8694436259300402e-06, reg = 30.457268745591442, validation accuracy is 0.171  \n",
      "lr = 2.497192285643466e-06, reg = 3.3166095775739293, validation accuracy is 0.328  \n",
      "lr = 8.454629846380738e-06, reg = 1.7079373718090442e-10, validation accuracy is 0.587  \n",
      "lr = 0.00048459438835051166, reg = 0.05983089061009524, validation accuracy is 0.621  \n",
      "lr = 1.6534760084963464e-06, reg = 3.3220756649313485e-07, validation accuracy is 0.5  \n",
      "lr = 1.0002048634484103e-05, reg = 1.0670019552932154e-10, validation accuracy is 0.611  \n",
      "lr = 0.008294070444654194, reg = 3.236490933113967e-10, validation accuracy is 0.476  \n",
      "lr = 2.188164811777817e-05, reg = 1.5925851372560153e-05, validation accuracy is 0.639  \n",
      "lr = 6.498649825474194e-06, reg = 0.10716034029437083, validation accuracy is 0.562  \n",
      "lr = 0.0042242132048472296, reg = 0.00192059789186161, validation accuracy is 0.608  \n",
      "lr = 0.00030255947398111444, reg = 1.1887805824295586e-07, validation accuracy is 0.732  \n",
      "lr = 7.734499090723071e-05, reg = 2.6875164976126248e-09, validation accuracy is 0.681  \n",
      "lr = 1.397889179081114e-05, reg = 0.013529082259143236, validation accuracy is 0.631  \n",
      "lr = 2.2995384859025576e-06, reg = 9.676504532814295e-09, validation accuracy is 0.522  \n",
      "lr = 4.971515443042102e-05, reg = 2.6175795871087453e-09, validation accuracy is 0.687  \n",
      "lr = 0.00025635190472579454, reg = 26.22154832223876, validation accuracy is 0.087  \n",
      "lr = 2.5404395271978616e-06, reg = 0.00010934657208394575, validation accuracy is 0.532  \n",
      "lr = 3.830276933583746e-06, reg = 4.100863399513804e-09, validation accuracy is 0.523  \n",
      "lr = 0.007708653113076822, reg = 0.09250638253620837, validation accuracy is 0.151  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 5.341281559305708e-05, reg = 0.17541836465002894, validation accuracy is 0.632  \n",
      "lr = 0.009098637986016157, reg = 6.696844600665914e-06, validation accuracy is 0.258  \n",
      "lr = 9.957375080232577e-06, reg = 0.0003074218017755357, validation accuracy is 0.615  \n",
      "lr = 0.006985326861929126, reg = 0.002004101256505656, validation accuracy is 0.522  \n",
      "lr = 9.30062019336857e-06, reg = 0.1593363262333967, validation accuracy is 0.572  \n",
      "lr = 0.006126752859952109, reg = 4.4516479043029783e-07, validation accuracy is 0.402  \n",
      "Training time for 10 epochs: 1316.03 sec\n",
      "In descending order of learning rate:\n",
      "lr = 0.009098637986016157, reg = 6.696844600665914e-06, validation accuracy is 0.258  \n",
      "lr = 0.008419751428795624, reg = 0.0035646738516316866, validation accuracy is 0.478  \n",
      "lr = 0.008294070444654194, reg = 3.236490933113967e-10, validation accuracy is 0.476  \n",
      "lr = 0.00822361091242141, reg = 7.4467018607870274, validation accuracy is 0.113  \n",
      "lr = 0.007708653113076822, reg = 0.09250638253620837, validation accuracy is 0.151  \n",
      "lr = 0.006985326861929126, reg = 0.002004101256505656, validation accuracy is 0.522  \n",
      "lr = 0.006126752859952109, reg = 4.4516479043029783e-07, validation accuracy is 0.402  \n",
      "lr = 0.005996111065727766, reg = 4.813600671695348e-06, validation accuracy is 0.428  \n",
      "lr = 0.0059948302614509005, reg = 0.010011618127031887, validation accuracy is 0.566  \n",
      "lr = 0.005509688622390361, reg = 4.910230537193647e-10, validation accuracy is 0.506  \n",
      "lr = 0.0042242132048472296, reg = 0.00192059789186161, validation accuracy is 0.608  \n",
      "lr = 0.003732182285007303, reg = 2.7238935119576925e-05, validation accuracy is 0.563  \n",
      "lr = 0.003373215466596708, reg = 1.0008602410294153e-09, validation accuracy is 0.586  \n",
      "lr = 0.002985900214736691, reg = 0.010453452867674394, validation accuracy is 0.529  \n",
      "lr = 0.002831501424336825, reg = 2.1814028362557628e-05, validation accuracy is 0.594  \n",
      "lr = 0.002556305569075787, reg = 6.201957204054882e-06, validation accuracy is 0.57  \n",
      "lr = 0.0021901124260892647, reg = 0.0003707486641797913, validation accuracy is 0.606  \n",
      "lr = 0.0019448764802993351, reg = 0.0014559406583695056, validation accuracy is 0.64  \n",
      "lr = 0.0018436283136011092, reg = 1.20855073494988e-07, validation accuracy is 0.602  \n",
      "lr = 0.0017469433543108419, reg = 0.005407562156582751, validation accuracy is 0.588  \n",
      "lr = 0.0013869356779387546, reg = 5.94062005313746e-05, validation accuracy is 0.653  \n",
      "lr = 0.0012393288000769702, reg = 5.12602146030666, validation accuracy is 0.113  \n",
      "lr = 0.0008867992873069955, reg = 1.4372398781436804, validation accuracy is 0.199  \n",
      "lr = 0.0006996954263941067, reg = 1.9038337189684477e-06, validation accuracy is 0.708  \n",
      "lr = 0.0006055829256460011, reg = 9.58996938648248e-07, validation accuracy is 0.722  \n",
      "lr = 0.0005443722591657279, reg = 0.00017920546701173702, validation accuracy is 0.719  \n",
      "lr = 0.0005251670566001226, reg = 0.0018050589295523598, validation accuracy is 0.699  \n",
      "lr = 0.00048459438835051166, reg = 0.05983089061009524, validation accuracy is 0.621  \n",
      "lr = 0.0004420536106205546, reg = 2.0186822341150736e-06, validation accuracy is 0.768  \n",
      "lr = 0.0004122334077427315, reg = 6.4451833938235595e-09, validation accuracy is 0.747  \n",
      "lr = 0.0003961550140640271, reg = 0.8105443384587647, validation accuracy is 0.37  \n",
      "lr = 0.00037206712670449505, reg = 0.09927454316034201, validation accuracy is 0.614  \n",
      "lr = 0.000348507497041526, reg = 1.4605422936453535e-05, validation accuracy is 0.725  \n",
      "lr = 0.0003159819304478141, reg = 28.656846959736583, validation accuracy is 0.113  \n",
      "lr = 0.00030976635881782815, reg = 1.9752562992451137e-05, validation accuracy is 0.737  \n",
      "lr = 0.00030255947398111444, reg = 1.1887805824295586e-07, validation accuracy is 0.732  \n",
      "lr = 0.0002938522880460647, reg = 3.1116344006152496e-09, validation accuracy is 0.731  \n",
      "lr = 0.0002885154495256621, reg = 2.771973322549355e-09, validation accuracy is 0.75  \n",
      "lr = 0.0002719530062001166, reg = 8.181890417359118e-05, validation accuracy is 0.714  \n",
      "lr = 0.00025635190472579454, reg = 26.22154832223876, validation accuracy is 0.087  \n",
      "lr = 0.00016799852379122324, reg = 15.613566194573618, validation accuracy is 0.098  \n",
      "lr = 0.0001638932273529234, reg = 3.0703157061644324e-05, validation accuracy is 0.73  \n",
      "lr = 0.00016151175929450816, reg = 0.001461378511321383, validation accuracy is 0.73  \n",
      "lr = 0.00015862184981477027, reg = 3.311901217036856e-07, validation accuracy is 0.72  \n",
      "lr = 0.00014157475047081133, reg = 3.515875715049107e-05, validation accuracy is 0.723  \n",
      "lr = 0.00011805442164972787, reg = 3.818327291174253e-10, validation accuracy is 0.716  \n",
      "lr = 0.00011532989154129476, reg = 3.889665794272065, validation accuracy is 0.226  \n",
      "lr = 9.609980503912395e-05, reg = 0.005374903040295943, validation accuracy is 0.677  \n",
      "lr = 7.764263308560473e-05, reg = 3.9283309473615766, validation accuracy is 0.203  \n",
      "lr = 7.734499090723071e-05, reg = 2.6875164976126248e-09, validation accuracy is 0.681  \n",
      "lr = 6.914399074312584e-05, reg = 0.030651772897969106, validation accuracy is 0.686  \n",
      "lr = 5.341281559305708e-05, reg = 0.17541836465002894, validation accuracy is 0.632  \n",
      "lr = 5.268044462970665e-05, reg = 0.0948523510014383, validation accuracy is 0.668  \n",
      "lr = 4.971515443042102e-05, reg = 2.6175795871087453e-09, validation accuracy is 0.687  \n",
      "lr = 4.625603296907752e-05, reg = 6.0699709968522045e-09, validation accuracy is 0.666  \n",
      "lr = 4.007498928855568e-05, reg = 1.0462145053481942e-05, validation accuracy is 0.66  \n",
      "lr = 3.348878693686202e-05, reg = 3.7300717080778774e-05, validation accuracy is 0.656  \n",
      "lr = 3.2066990160856126e-05, reg = 73.0011473426906, validation accuracy is 0.263  \n",
      "lr = 3.13625482992454e-05, reg = 0.006702166937063668, validation accuracy is 0.67  \n",
      "lr = 2.980838513237049e-05, reg = 3.9724783982491223, validation accuracy is 0.387  \n",
      "lr = 2.8276700188882648e-05, reg = 0.05565412975199819, validation accuracy is 0.618  \n",
      "lr = 2.8013165961810122e-05, reg = 0.6740105236591744, validation accuracy is 0.543  \n",
      "lr = 2.188164811777817e-05, reg = 1.5925851372560153e-05, validation accuracy is 0.639  \n",
      "lr = 1.834628949407268e-05, reg = 4.781387738199418e-09, validation accuracy is 0.63  \n",
      "lr = 1.647117910036382e-05, reg = 1.5768845674707156e-06, validation accuracy is 0.631  \n",
      "lr = 1.4865817289651003e-05, reg = 28.45191209788082, validation accuracy is 0.321  \n",
      "lr = 1.4783779752657483e-05, reg = 55.130951067603085, validation accuracy is 0.195  \n",
      "lr = 1.397889179081114e-05, reg = 0.013529082259143236, validation accuracy is 0.631  \n",
      "lr = 1.0267141502637463e-05, reg = 2.2423114552249097e-05, validation accuracy is 0.624  \n",
      "lr = 1.0112212652872966e-05, reg = 0.020453604351085584, validation accuracy is 0.616  \n",
      "lr = 1.0002048634484103e-05, reg = 1.0670019552932154e-10, validation accuracy is 0.611  \n",
      "lr = 9.957375080232577e-06, reg = 0.0003074218017755357, validation accuracy is 0.615  \n",
      "lr = 9.30062019336857e-06, reg = 0.1593363262333967, validation accuracy is 0.572  \n",
      "lr = 8.454629846380738e-06, reg = 1.7079373718090442e-10, validation accuracy is 0.587  \n",
      "lr = 7.049317699161044e-06, reg = 0.019993230642586797, validation accuracy is 0.59  \n",
      "lr = 6.5440784050296394e-06, reg = 1.460840922329886e-10, validation accuracy is 0.584  \n",
      "lr = 6.498649825474194e-06, reg = 0.10716034029437083, validation accuracy is 0.562  \n",
      "lr = 5.987749489253305e-06, reg = 3.193174800162297e-09, validation accuracy is 0.575  \n",
      "lr = 5.494435066444071e-06, reg = 1.6931594998242051e-09, validation accuracy is 0.571  \n",
      "lr = 5.178320084401512e-06, reg = 3.125014916588725e-07, validation accuracy is 0.579  \n",
      "lr = 4.1131199258244805e-06, reg = 0.009183569193389245, validation accuracy is 0.553  \n",
      "lr = 3.830276933583746e-06, reg = 4.100863399513804e-09, validation accuracy is 0.523  \n",
      "lr = 3.8290175559735334e-06, reg = 2.5761485147151517e-08, validation accuracy is 0.539  \n",
      "lr = 3.312216301167796e-06, reg = 1.3208096729461642, validation accuracy is 0.394  \n",
      "lr = 2.8694436259300402e-06, reg = 30.457268745591442, validation accuracy is 0.171  \n",
      "lr = 2.5404395271978616e-06, reg = 0.00010934657208394575, validation accuracy is 0.532  \n",
      "lr = 2.497192285643466e-06, reg = 3.3166095775739293, validation accuracy is 0.328  \n",
      "lr = 2.3012233654655408e-06, reg = 1.0587801567612161e-09, validation accuracy is 0.519  \n",
      "lr = 2.2995384859025576e-06, reg = 9.676504532814295e-09, validation accuracy is 0.522  \n",
      "lr = 2.2601995271654264e-06, reg = 0.4816039172648769, validation accuracy is 0.43  \n",
      "lr = 2.019140109564537e-06, reg = 0.00023777504385718968, validation accuracy is 0.493  \n",
      "lr = 1.8528189621301718e-06, reg = 4.746231249856485e-09, validation accuracy is 0.482  \n",
      "lr = 1.6534760084963464e-06, reg = 3.3220756649313485e-07, validation accuracy is 0.5  \n",
      "lr = 1.5807948954963685e-06, reg = 4.214524828334788e-07, validation accuracy is 0.485  \n",
      "lr = 1.4115769829339359e-06, reg = 7.626434172108425, validation accuracy is 0.189  \n",
      "lr = 1.3116142483651602e-06, reg = 0.02321093986222916, validation accuracy is 0.479  \n",
      "lr = 1.30366135150047e-06, reg = 24.68131034640062, validation accuracy is 0.117  \n",
      "lr = 1.103067655335038e-06, reg = 1.3969242782012285e-06, validation accuracy is 0.433  \n",
      "lr = 1.0608505969109444e-06, reg = 9.36159934357995e-08, validation accuracy is 0.429  \n",
      "lr = 1.056164027555874e-06, reg = 6.01442570862751e-09, validation accuracy is 0.434  \n"
     ]
    }
   ],
   "source": [
    "stat = []\n",
    "\n",
    "start = time.time()\n",
    "max_count = 100\n",
    "for count in range(max_count):\n",
    "    reg = 10**random.uniform(-10,2)\n",
    "    lr = 10**random.uniform(-6,-2)\n",
    "    \n",
    "    model = generator().type(gpu_dtype)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    train(model, loss_fn, optimizer, num_epochs=1)\n",
    "    val_acc = check_accuracy(model, loader_val)\n",
    "    \n",
    "    print('lr = {}, reg = {}, validation accuracy is {}  '.format(lr, reg, val_acc))\n",
    "    stat.append([lr, reg, val_acc])\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "print('Training time for 10 epochs: {1:.2f} sec'.format(val_acc, end-start))\n",
    "\n",
    "sorted_stat = sorted(stat, key=lambda x: x[0], reverse=True)\n",
    "print (\"In descending order of learning rate:\")\n",
    "for lr, reg, val_acc in sorted_stat:\n",
    "    print('lr = {}, reg = {}, validation accuracy is {}  '.format(lr, reg, val_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune Learning Rate + Regularization\n",
    "\n",
    "####  Model 5-Conv Layers, 2 MaxPool Blocks (WIDER)\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (1): ReLU(inplace)\n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (4): ReLU(inplace)\n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (6): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (7): ReLU(inplace)\n",
    "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (10): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (11): ReLU(inplace)\n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (13): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (14): ReLU(inplace)\n",
    "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (17): Flatten(\n",
    "  )\n",
    "  (18): Linear(in_features=16384, out_features=1024)\n",
    "  (19): ReLU(inplace)\n",
    "  (20): Linear(in_features=1024, out_features=10)\n",
    ")\n",
    "\n",
    "* Training time for 1 epoch: 13.18 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "lr = 0.0019448764802993351, reg = 0.0014559406583695056, validation accuracy is 0.64  \n",
    "lr = 0.0018436283136011092, reg = 1.20855073494988e-07, validation accuracy is 0.602  \n",
    "lr = 0.0017469433543108419, reg = 0.005407562156582751, validation accuracy is 0.588  \n",
    "lr = 0.0013869356779387546, reg = 5.94062005313746e-05, validation accuracy is 0.653  \n",
    "lr = 0.0012393288000769702, reg = 5.12602146030666, validation accuracy is 0.113  \n",
    "lr = 0.0008867992873069955, reg = 1.4372398781436804, validation accuracy is 0.199  \n",
    "lr = 0.0006996954263941067, reg = 1.9038337189684477e-06, validation accuracy is 0.708  \n",
    "** lr = 0.0006055829256460011, reg = 9.58996938648248e-07, validation accuracy is 0.722 **  \n",
    "** lr = 0.0005443722591657279, reg = 0.00017920546701173702, validation accuracy is 0.719 **  \n",
    "lr = 0.0005251670566001226, reg = 0.0018050589295523598, validation accuracy is 0.699  \n",
    "lr = 0.00048459438835051166, reg = 0.05983089061009524, validation accuracy is 0.621  \n",
    "lr = 0.0004420536106205546, reg = 2.0186822341150736e-06, validation accuracy is 0.768  \n",
    "** lr = 0.0004122334077427315, reg = 6.4451833938235595e-09, validation accuracy is 0.747 **  \n",
    "lr = 0.0003961550140640271, reg = 0.8105443384587647, validation accuracy is 0.37  \n",
    "lr = 0.00037206712670449505, reg = 0.09927454316034201, validation accuracy is 0.614  \n",
    "** lr = 0.000348507497041526, reg = 1.4605422936453535e-05, validation accuracy is 0.725 **  \n",
    "lr = 0.0003159819304478141, reg = 28.656846959736583, validation accuracy is 0.113  \n",
    "** lr = 0.00030976635881782815, reg = 1.9752562992451137e-05, validation accuracy is 0.737 **  \n",
    "** lr = 0.00030255947398111444, reg = 1.1887805824295586e-07, validation accuracy is 0.732 **   \n",
    "** lr = 0.0002938522880460647, reg = 3.1116344006152496e-09, validation accuracy is 0.731 **  \n",
    "<span style=\"color:blue\"> ** lr = 0.0002885154495256621, reg = 2.771973322549355e-09, validation accuracy is 0.75 ** <span style=\"color:black\">   \n",
    "lr = 0.0002719530062001166, reg = 8.181890417359118e-05, validation accuracy is 0.714  \n",
    "lr = 0.00025635190472579454, reg = 26.22154832223876, validation accuracy is 0.087  \n",
    "lr = 0.00016799852379122324, reg = 15.613566194573618, validation accuracy is 0.098  \n",
    "** lr = 0.0001638932273529234, reg = 3.0703157061644324e-05, validation accuracy is 0.73 **  \n",
    "** lr = 0.00016151175929450816, reg = 0.001461378511321383, validation accuracy is 0.73 **  \n",
    "lr = 0.00015862184981477027, reg = 3.311901217036856e-07, validation accuracy is 0.72  \n",
    "lr = 0.00014157475047081133, reg = 3.515875715049107e-05, validation accuracy is 0.723  \n",
    "lr = 0.00011805442164972787, reg = 3.818327291174253e-10, validation accuracy is 0.716  \n",
    "lr = 0.00011532989154129476, reg = 3.889665794272065, validation accuracy is 0.226  \n",
    "lr = 9.609980503912395e-05, reg = 0.005374903040295943, validation accuracy is 0.677  \n",
    "lr = 7.764263308560473e-05, reg = 3.9283309473615766, validation accuracy is 0.203  \n",
    "lr = 7.734499090723071e-05, reg = 2.6875164976126248e-09, validation accuracy is 0.681  \n",
    "lr = 6.914399074312584e-05, reg = 0.030651772897969106, validation accuracy is 0.686  \n",
    "lr = 5.341281559305708e-05, reg = 0.17541836465002894, validation accuracy is 0.632  \n",
    "lr = 5.268044462970665e-05, reg = 0.0948523510014383, validation accuracy is 0.668  \n",
    "lr = 4.971515443042102e-05, reg = 2.6175795871087453e-09, validation accuracy is 0.687  \n",
    "lr = 4.625603296907752e-05, reg = 6.0699709968522045e-09, validation accuracy is 0.666  \n",
    "lr = 4.007498928855568e-05, reg = 1.0462145053481942e-05, validation accuracy is 0.66  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 20\n",
      "t = 100, loss = 1.3332\n",
      "t = 200, loss = 1.1970\n",
      "t = 300, loss = 1.1280\n",
      "t = 400, loss = 0.7356\n",
      "t = 500, loss = 0.7964\n",
      "t = 600, loss = 0.7350\n",
      "t = 700, loss = 0.9378\n",
      "Starting epoch 2 / 20\n",
      "t = 100, loss = 0.5250\n",
      "t = 200, loss = 0.5397\n",
      "t = 300, loss = 0.6298\n",
      "t = 400, loss = 0.5567\n",
      "t = 500, loss = 0.5766\n",
      "t = 600, loss = 0.4170\n",
      "t = 700, loss = 0.6086\n",
      "Starting epoch 3 / 20\n",
      "t = 100, loss = 0.2840\n",
      "t = 200, loss = 0.2342\n",
      "t = 300, loss = 0.2710\n",
      "t = 400, loss = 0.2278\n",
      "t = 500, loss = 0.2419\n",
      "t = 600, loss = 0.0843\n",
      "t = 700, loss = 0.2924\n",
      "Starting epoch 4 / 20\n",
      "t = 100, loss = 0.0524\n",
      "t = 200, loss = 0.0978\n",
      "t = 300, loss = 0.1434\n",
      "t = 400, loss = 0.1321\n",
      "t = 500, loss = 0.0973\n",
      "t = 600, loss = 0.0378\n",
      "t = 700, loss = 0.0232\n",
      "Starting epoch 5 / 20\n",
      "t = 100, loss = 0.0234\n",
      "t = 200, loss = 0.0558\n",
      "t = 300, loss = 0.0584\n",
      "t = 400, loss = 0.0387\n",
      "t = 500, loss = 0.0328\n",
      "t = 600, loss = 0.0706\n",
      "t = 700, loss = 0.0811\n",
      "Starting epoch 6 / 20\n",
      "t = 100, loss = 0.0438\n",
      "t = 200, loss = 0.0156\n",
      "t = 300, loss = 0.0464\n",
      "t = 400, loss = 0.0824\n",
      "t = 500, loss = 0.0096\n",
      "t = 600, loss = 0.0154\n",
      "t = 700, loss = 0.0260\n",
      "Starting epoch 7 / 20\n",
      "t = 100, loss = 0.0321\n",
      "t = 200, loss = 0.0867\n",
      "t = 300, loss = 0.0143\n",
      "t = 400, loss = 0.0126\n",
      "t = 500, loss = 0.0138\n",
      "t = 600, loss = 0.0044\n",
      "t = 700, loss = 0.0131\n",
      "Starting epoch 8 / 20\n",
      "t = 100, loss = 0.0453\n",
      "t = 200, loss = 0.0358\n",
      "t = 300, loss = 0.0303\n",
      "t = 400, loss = 0.0271\n",
      "t = 500, loss = 0.0553\n",
      "t = 600, loss = 0.0189\n",
      "t = 700, loss = 0.0161\n",
      "Starting epoch 9 / 20\n",
      "t = 100, loss = 0.0397\n",
      "t = 200, loss = 0.0064\n",
      "t = 300, loss = 0.0297\n",
      "t = 400, loss = 0.1137\n",
      "t = 500, loss = 0.0068\n",
      "t = 600, loss = 0.0290\n",
      "t = 700, loss = 0.0185\n",
      "Starting epoch 10 / 20\n",
      "t = 100, loss = 0.0027\n",
      "t = 200, loss = 0.0315\n",
      "t = 300, loss = 0.0057\n",
      "t = 400, loss = 0.0669\n",
      "t = 500, loss = 0.0156\n",
      "t = 600, loss = 0.0525\n",
      "t = 700, loss = 0.0106\n",
      "Starting epoch 11 / 20\n",
      "t = 100, loss = 0.0258\n",
      "t = 200, loss = 0.0060\n",
      "t = 300, loss = 0.0028\n",
      "t = 400, loss = 0.0011\n",
      "t = 500, loss = 0.0008\n",
      "t = 600, loss = 0.0021\n",
      "t = 700, loss = 0.0010\n",
      "Starting epoch 12 / 20\n",
      "t = 100, loss = 0.0096\n",
      "t = 200, loss = 0.0019\n",
      "t = 300, loss = 0.0011\n",
      "t = 400, loss = 0.0010\n",
      "t = 500, loss = 0.0038\n",
      "t = 600, loss = 0.0010\n",
      "t = 700, loss = 0.0106\n",
      "Starting epoch 13 / 20\n",
      "t = 100, loss = 0.0313\n",
      "t = 200, loss = 0.0040\n",
      "t = 300, loss = 0.0242\n",
      "t = 400, loss = 0.0038\n",
      "t = 500, loss = 0.0640\n",
      "t = 600, loss = 0.0632\n",
      "t = 700, loss = 0.0086\n",
      "Starting epoch 14 / 20\n",
      "t = 100, loss = 0.0126\n",
      "t = 200, loss = 0.0006\n",
      "t = 300, loss = 0.0196\n",
      "t = 400, loss = 0.0017\n",
      "t = 500, loss = 0.0017\n",
      "t = 600, loss = 0.0016\n",
      "t = 700, loss = 0.0007\n",
      "Starting epoch 15 / 20\n",
      "t = 100, loss = 0.0002\n",
      "t = 200, loss = 0.0042\n",
      "t = 300, loss = 0.0019\n",
      "t = 400, loss = 0.0030\n",
      "t = 500, loss = 0.0077\n",
      "t = 600, loss = 0.0022\n",
      "t = 700, loss = 0.0010\n",
      "Starting epoch 16 / 20\n",
      "t = 100, loss = 0.0011\n",
      "t = 200, loss = 0.0228\n",
      "t = 300, loss = 0.0191\n",
      "t = 400, loss = 0.0011\n",
      "t = 500, loss = 0.0045\n",
      "t = 600, loss = 0.0005\n",
      "t = 700, loss = 0.0093\n",
      "Starting epoch 17 / 20\n",
      "t = 100, loss = 0.0001\n",
      "t = 200, loss = 0.0009\n",
      "t = 300, loss = 0.0008\n",
      "t = 400, loss = 0.0165\n",
      "t = 500, loss = 0.0032\n",
      "t = 600, loss = 0.0038\n",
      "t = 700, loss = 0.0015\n",
      "Starting epoch 18 / 20\n",
      "t = 100, loss = 0.0002\n",
      "t = 200, loss = 0.0078\n",
      "t = 300, loss = 0.0015\n",
      "t = 400, loss = 0.0006\n",
      "t = 500, loss = 0.0019\n",
      "t = 600, loss = 0.0025\n",
      "t = 700, loss = 0.0063\n",
      "Starting epoch 19 / 20\n",
      "t = 100, loss = 0.0013\n",
      "t = 200, loss = 0.0003\n",
      "t = 300, loss = 0.0350\n",
      "t = 400, loss = 0.0003\n",
      "t = 500, loss = 0.0045\n",
      "t = 600, loss = 0.1459\n",
      "t = 700, loss = 0.0687\n",
      "Starting epoch 20 / 20\n",
      "t = 100, loss = 0.0056\n",
      "t = 200, loss = 0.0051\n",
      "t = 300, loss = 0.0024\n",
      "t = 400, loss = 0.0600\n",
      "t = 500, loss = 0.0060\n",
      "t = 600, loss = 0.0016\n",
      "t = 700, loss = 0.0050\n",
      "validation accuracy is 0.813. Training time for 10 epoch: 262.42 sec\n"
     ]
    }
   ],
   "source": [
    "model = generator().type(gpu_dtype)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00028, weight_decay=2.8e-09)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=20, verbose=True)\n",
    "val_acc = check_accuracy(model, loader_val)\n",
    "\n",
    "end = time.time()\n",
    "    \n",
    "print('validation accuracy is {0}. Training time for 10 epoch: {1:.2f} sec'.format(val_acc, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00020412000000000002\n"
     ]
    }
   ],
   "source": [
    "print (optimizer.param_groups[0][\"lr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU(inplace)\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (6): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(inplace)\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (10): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (13): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (14): ReLU(inplace)\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (17): Flatten(\n",
      "  )\n",
      "  (18): Linear(in_features=16384, out_features=1024)\n",
      "  (19): ReLU(inplace)\n",
      "  (20): Linear(in_features=1024, out_features=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In descending order of learning rate:\n",
      "lr = 0.009098637986016157, reg = 6.696844600665914e-06, validation accuracy is 0.258  \n",
      "lr = 0.008419751428795624, reg = 0.0035646738516316866, validation accuracy is 0.478  \n",
      "lr = 0.008294070444654194, reg = 3.236490933113967e-10, validation accuracy is 0.476  \n",
      "lr = 0.00822361091242141, reg = 7.4467018607870274, validation accuracy is 0.113  \n",
      "lr = 0.007708653113076822, reg = 0.09250638253620837, validation accuracy is 0.151  \n",
      "lr = 0.006985326861929126, reg = 0.002004101256505656, validation accuracy is 0.522  \n",
      "lr = 0.006126752859952109, reg = 4.4516479043029783e-07, validation accuracy is 0.402  \n",
      "lr = 0.005996111065727766, reg = 4.813600671695348e-06, validation accuracy is 0.428  \n",
      "lr = 0.0059948302614509005, reg = 0.010011618127031887, validation accuracy is 0.566  \n",
      "lr = 0.005509688622390361, reg = 4.910230537193647e-10, validation accuracy is 0.506  \n",
      "lr = 0.0042242132048472296, reg = 0.00192059789186161, validation accuracy is 0.608  \n",
      "lr = 0.003732182285007303, reg = 2.7238935119576925e-05, validation accuracy is 0.563  \n",
      "lr = 0.003373215466596708, reg = 1.0008602410294153e-09, validation accuracy is 0.586  \n",
      "lr = 0.002985900214736691, reg = 0.010453452867674394, validation accuracy is 0.529  \n",
      "lr = 0.002831501424336825, reg = 2.1814028362557628e-05, validation accuracy is 0.594  \n",
      "lr = 0.002556305569075787, reg = 6.201957204054882e-06, validation accuracy is 0.57  \n",
      "lr = 0.0021901124260892647, reg = 0.0003707486641797913, validation accuracy is 0.606  \n",
      "lr = 0.0019448764802993351, reg = 0.0014559406583695056, validation accuracy is 0.64  \n",
      "lr = 0.0018436283136011092, reg = 1.20855073494988e-07, validation accuracy is 0.602  \n",
      "lr = 0.0017469433543108419, reg = 0.005407562156582751, validation accuracy is 0.588  \n",
      "lr = 0.0013869356779387546, reg = 5.94062005313746e-05, validation accuracy is 0.653  \n",
      "lr = 0.0012393288000769702, reg = 5.12602146030666, validation accuracy is 0.113  \n",
      "lr = 0.0008867992873069955, reg = 1.4372398781436804, validation accuracy is 0.199  \n",
      "lr = 0.0006996954263941067, reg = 1.9038337189684477e-06, validation accuracy is 0.708  \n",
      "lr = 0.0006055829256460011, reg = 9.58996938648248e-07, validation accuracy is 0.722  \n",
      "lr = 0.0005443722591657279, reg = 0.00017920546701173702, validation accuracy is 0.719  \n",
      "lr = 0.0005251670566001226, reg = 0.0018050589295523598, validation accuracy is 0.699  \n",
      "lr = 0.00048459438835051166, reg = 0.05983089061009524, validation accuracy is 0.621  \n",
      "lr = 0.0004420536106205546, reg = 2.0186822341150736e-06, validation accuracy is 0.768  \n",
      "lr = 0.0004122334077427315, reg = 6.4451833938235595e-09, validation accuracy is 0.747  \n",
      "lr = 0.0003961550140640271, reg = 0.8105443384587647, validation accuracy is 0.37  \n",
      "lr = 0.00037206712670449505, reg = 0.09927454316034201, validation accuracy is 0.614  \n",
      "lr = 0.000348507497041526, reg = 1.4605422936453535e-05, validation accuracy is 0.725  \n",
      "lr = 0.0003159819304478141, reg = 28.656846959736583, validation accuracy is 0.113  \n",
      "lr = 0.00030976635881782815, reg = 1.9752562992451137e-05, validation accuracy is 0.737  \n",
      "lr = 0.00030255947398111444, reg = 1.1887805824295586e-07, validation accuracy is 0.732  \n",
      "lr = 0.0002938522880460647, reg = 3.1116344006152496e-09, validation accuracy is 0.731  \n",
      "lr = 0.0002885154495256621, reg = 2.771973322549355e-09, validation accuracy is 0.75  \n",
      "lr = 0.0002719530062001166, reg = 8.181890417359118e-05, validation accuracy is 0.714  \n",
      "lr = 0.00025635190472579454, reg = 26.22154832223876, validation accuracy is 0.087  \n",
      "lr = 0.00016799852379122324, reg = 15.613566194573618, validation accuracy is 0.098  \n",
      "lr = 0.0001638932273529234, reg = 3.0703157061644324e-05, validation accuracy is 0.73  \n",
      "lr = 0.00016151175929450816, reg = 0.001461378511321383, validation accuracy is 0.73  \n",
      "lr = 0.00015862184981477027, reg = 3.311901217036856e-07, validation accuracy is 0.72  \n",
      "lr = 0.00014157475047081133, reg = 3.515875715049107e-05, validation accuracy is 0.723  \n",
      "lr = 0.00011805442164972787, reg = 3.818327291174253e-10, validation accuracy is 0.716  \n",
      "lr = 0.00011532989154129476, reg = 3.889665794272065, validation accuracy is 0.226  \n",
      "lr = 9.609980503912395e-05, reg = 0.005374903040295943, validation accuracy is 0.677  \n",
      "lr = 7.764263308560473e-05, reg = 3.9283309473615766, validation accuracy is 0.203  \n",
      "lr = 7.734499090723071e-05, reg = 2.6875164976126248e-09, validation accuracy is 0.681  \n",
      "lr = 6.914399074312584e-05, reg = 0.030651772897969106, validation accuracy is 0.686  \n",
      "lr = 5.341281559305708e-05, reg = 0.17541836465002894, validation accuracy is 0.632  \n",
      "lr = 5.268044462970665e-05, reg = 0.0948523510014383, validation accuracy is 0.668  \n",
      "lr = 4.971515443042102e-05, reg = 2.6175795871087453e-09, validation accuracy is 0.687  \n",
      "lr = 4.625603296907752e-05, reg = 6.0699709968522045e-09, validation accuracy is 0.666  \n",
      "lr = 4.007498928855568e-05, reg = 1.0462145053481942e-05, validation accuracy is 0.66  \n",
      "lr = 3.348878693686202e-05, reg = 3.7300717080778774e-05, validation accuracy is 0.656  \n",
      "lr = 3.2066990160856126e-05, reg = 73.0011473426906, validation accuracy is 0.263  \n",
      "lr = 3.13625482992454e-05, reg = 0.006702166937063668, validation accuracy is 0.67  \n",
      "lr = 2.980838513237049e-05, reg = 3.9724783982491223, validation accuracy is 0.387  \n",
      "lr = 2.8276700188882648e-05, reg = 0.05565412975199819, validation accuracy is 0.618  \n",
      "lr = 2.8013165961810122e-05, reg = 0.6740105236591744, validation accuracy is 0.543  \n",
      "lr = 2.188164811777817e-05, reg = 1.5925851372560153e-05, validation accuracy is 0.639  \n",
      "lr = 1.834628949407268e-05, reg = 4.781387738199418e-09, validation accuracy is 0.63  \n",
      "lr = 1.647117910036382e-05, reg = 1.5768845674707156e-06, validation accuracy is 0.631  \n",
      "lr = 1.4865817289651003e-05, reg = 28.45191209788082, validation accuracy is 0.321  \n",
      "lr = 1.4783779752657483e-05, reg = 55.130951067603085, validation accuracy is 0.195  \n",
      "lr = 1.397889179081114e-05, reg = 0.013529082259143236, validation accuracy is 0.631  \n",
      "lr = 1.0267141502637463e-05, reg = 2.2423114552249097e-05, validation accuracy is 0.624  \n",
      "lr = 1.0112212652872966e-05, reg = 0.020453604351085584, validation accuracy is 0.616  \n",
      "lr = 1.0002048634484103e-05, reg = 1.0670019552932154e-10, validation accuracy is 0.611  \n",
      "lr = 9.957375080232577e-06, reg = 0.0003074218017755357, validation accuracy is 0.615  \n",
      "lr = 9.30062019336857e-06, reg = 0.1593363262333967, validation accuracy is 0.572  \n",
      "lr = 8.454629846380738e-06, reg = 1.7079373718090442e-10, validation accuracy is 0.587  \n",
      "lr = 7.049317699161044e-06, reg = 0.019993230642586797, validation accuracy is 0.59  \n",
      "lr = 6.5440784050296394e-06, reg = 1.460840922329886e-10, validation accuracy is 0.584  \n",
      "lr = 6.498649825474194e-06, reg = 0.10716034029437083, validation accuracy is 0.562  \n",
      "lr = 5.987749489253305e-06, reg = 3.193174800162297e-09, validation accuracy is 0.575  \n",
      "lr = 5.494435066444071e-06, reg = 1.6931594998242051e-09, validation accuracy is 0.571  \n",
      "lr = 5.178320084401512e-06, reg = 3.125014916588725e-07, validation accuracy is 0.579  \n",
      "lr = 4.1131199258244805e-06, reg = 0.009183569193389245, validation accuracy is 0.553  \n",
      "lr = 3.830276933583746e-06, reg = 4.100863399513804e-09, validation accuracy is 0.523  \n",
      "lr = 3.8290175559735334e-06, reg = 2.5761485147151517e-08, validation accuracy is 0.539  \n",
      "lr = 3.312216301167796e-06, reg = 1.3208096729461642, validation accuracy is 0.394  \n",
      "lr = 2.8694436259300402e-06, reg = 30.457268745591442, validation accuracy is 0.171  \n",
      "lr = 2.5404395271978616e-06, reg = 0.00010934657208394575, validation accuracy is 0.532  \n",
      "lr = 2.497192285643466e-06, reg = 3.3166095775739293, validation accuracy is 0.328  \n",
      "lr = 2.3012233654655408e-06, reg = 1.0587801567612161e-09, validation accuracy is 0.519  \n",
      "lr = 2.2995384859025576e-06, reg = 9.676504532814295e-09, validation accuracy is 0.522  \n",
      "lr = 2.2601995271654264e-06, reg = 0.4816039172648769, validation accuracy is 0.43  \n",
      "lr = 2.019140109564537e-06, reg = 0.00023777504385718968, validation accuracy is 0.493  \n",
      "lr = 1.8528189621301718e-06, reg = 4.746231249856485e-09, validation accuracy is 0.482  \n",
      "lr = 1.6534760084963464e-06, reg = 3.3220756649313485e-07, validation accuracy is 0.5  \n",
      "lr = 1.5807948954963685e-06, reg = 4.214524828334788e-07, validation accuracy is 0.485  \n",
      "lr = 1.4115769829339359e-06, reg = 7.626434172108425, validation accuracy is 0.189  \n",
      "lr = 1.3116142483651602e-06, reg = 0.02321093986222916, validation accuracy is 0.479  \n",
      "lr = 1.30366135150047e-06, reg = 24.68131034640062, validation accuracy is 0.117  \n",
      "lr = 1.103067655335038e-06, reg = 1.3969242782012285e-06, validation accuracy is 0.433  \n",
      "lr = 1.0608505969109444e-06, reg = 9.36159934357995e-08, validation accuracy is 0.429  \n",
      "lr = 1.056164027555874e-06, reg = 6.01442570862751e-09, validation accuracy is 0.434  \n"
     ]
    }
   ],
   "source": [
    "sorted_stat = sorted(stat, key=lambda x: x[0], reverse=True)\n",
    "print (\"In descending order of learning rate:\")\n",
    "for lr, reg, val_acc in sorted_stat:\n",
    "    print('lr = {}, reg = {}, validation accuracy is {}  '.format(lr, reg, val_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8082"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = model\n",
    "check_accuracy(best_model, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
