{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE253 PA3 - Design a CNN \n",
    "\n",
    "First a bit of setup!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import timeit\n",
    "import time\n",
    "import platform\n",
    "import random\n",
    "import pickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "\n",
    "We load the CIFAR-10 dataset. This might take a couple minutes the first time you do it, but the files should stay cached after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "NUM_TRAIN_SMALL=1000\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "loader_train_small = DataLoader(cifar10_train, batch_size=64, sampler=ChunkSampler(NUM_TRAIN_SMALL, 0))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True, \n",
    "                           transform=T.ToTensor())\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                          transform=T.ToTensor())\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our image data (and more relevantly, our intermediate feature maps) are initially N x C x H x W, where:\n",
    "\n",
    "* N is the number of datapoints  \n",
    "* C is the number of channels  \n",
    "* H is the height of the intermediate feature map in pixels  \n",
    "* W is the height of the intermediate feature map in pixels  \n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, that needs spatial understanding of where the intermediate features are relative to each other. When we input data into fully connected affine layers, however, we want each datapoint to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data. So, we use a \"Flatten\" operation to collapse the C x H x W values per representation into a single long vector. The Flatten function below first reads in the N, C, H, and W values from a given batch of data, and then returns a \"view\" of that data. \"View\" is analogous to numpy's \"reshape\" method: it reshapes x's dimensions to be N x ??, where ?? is allowed to be anything (in this case, it will be C x H x W, but we don't need to specify that explicitly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor # the CPU datatype\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "# This is a little utility that we'll use to reset the model\n",
    "# if we want to re-initialize all our parameters\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n",
    "        \n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, num_epochs = 1, verbose=False):\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.9)     # decay lr by 0.9 very 5 epochs   \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "            \n",
    "        scheduler.step()    \n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var = Variable(x.type(gpu_dtype))\n",
    "            y_var = Variable(y.type(gpu_dtype).long())\n",
    "\n",
    "            scores = model(x_var)\n",
    "            \n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % print_every == 0 and verbose:\n",
    "                print('t = %d, loss = %.6f' % (t + 1, loss.data[0]))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def train_detailed(model, loss_fn, optimizer, reg, num_epochs = 10, verbose=False):\n",
    "    # Train the model in greater detail - output validation and train accuracy every epoch\n",
    "    \n",
    "    train_history = []   # this will store train accuracy, val accuracy and loss for every epoch\n",
    "    best_val_acc = 0.0  # initialize best_val_acc\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.9)   # decay lr by 0.9 very 5 epochs \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose:\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "            \n",
    "        scheduler.step()    \n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var = Variable(x.type(gpu_dtype))\n",
    "            y_var = Variable(y.type(gpu_dtype).long())\n",
    "\n",
    "            scores = model(x_var)\n",
    "            \n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % print_every == 0 and verbose:\n",
    "                print('t = %d, loss = %.6f' % (t + 1, loss.data[0]))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "       \n",
    "        # We calculate validation and training accuracy at the end of every epoch\n",
    "        val_acc = check_accuracy(model, loader_val) \n",
    "        train_acc = check_accuracy(model, loader_train_small)\n",
    "        print (\"train acc: {} val acc:{}\".format(train_acc,val_acc))\n",
    "        \n",
    "        if val_acc > best_val_acc:  \n",
    "            # save your model \n",
    "            file_name = 'model_reg='+str(reg)+'bestacc.pt'\n",
    "            torch.save(model.state_dict(), file_name)\n",
    "            best_val_acc = val_acc \n",
    "               \n",
    "        train_history.append([train_acc,val_acc, loss.data[0]])\n",
    "        \n",
    "    return best_val_acc, train_history \n",
    "        \n",
    "\n",
    "def check_accuracy(model, loader, verbose=False):\n",
    "    if verbose:\n",
    "        if loader.dataset.train:\n",
    "            print('Checking accuracy on validation set')\n",
    "        else:\n",
    "            print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in loader:\n",
    "        x_var = Variable(x.type(gpu_dtype), volatile=True)\n",
    "\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    if verbose:\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def generator():\n",
    "    \n",
    "    # Model - 4 layer Conv Layers\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(8192,1024),  # 5408=128*16*16 input size\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator():\n",
    "\n",
    "    # Model - 5 layer Conv Layers\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(8192,1024),  # 5408=128*16*16 input size\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model\n",
    "\n",
    "def generator():\n",
    "\n",
    "    Model - 6 layer Conv Layers\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=256),        \n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(16384,1024),  # 5408=128*16*16 input size\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator():\n",
    "\n",
    "    # Model - 5 layer Conv Layers (WIDER)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=256, kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=256),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(16384,1024),  # 5408=128*16*16 input siz\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model\n",
    "\"\"\"\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "    \n",
    "def generator():\n",
    "\n",
    "    # Model - 5 layer Conv Layers (WIDER)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=32),\n",
    "                    nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=64),\n",
    "                    nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half\n",
    "                    nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=128),\n",
    "                    nn.Conv2d(in_channels=128,out_channels=256, kernel_size=3,stride=1,padding=1), # preserve dimension\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(num_features=256),\n",
    "                    nn.MaxPool2d(kernel_size=2,stride=2),  # Downsample by half        \n",
    "                    Flatten(),\n",
    "                    nn.Linear(16384,1024),  # 5408=128*16*16 input siz\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024,10),\n",
    "                    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generator().type(gpu_dtype)\n",
    "\n",
    "x_gpu = torch.randn(64, 3, 32, 32).type(gpu_dtype)\n",
    "x_var_gpu = Variable(x_gpu.type(gpu_dtype)) # Construct a PyTorch Variable out of your input data\n",
    "ans = model(x_var_gpu)        # Feed it through the model! \n",
    "\n",
    "print (ans.shape)\n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(ans.size()), np.array([64, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy is 0.745. Training time for 1 epoch: 13.12 sec\n"
     ]
    }
   ],
   "source": [
    "model = generator().type(gpu_dtype)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00035, weight_decay=1e-10)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=1)\n",
    "val_acc = check_accuracy(model, loader_val)\n",
    "\n",
    "end = time.time()\n",
    "    \n",
    "print('validation accuracy is {0}. Training time for 1 epoch: {1:.2f} sec'.format(val_acc, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 5.882224702688513e-05, reg = 1e-10, validation accuracy is 0.671\n",
      "lr = 3.207152865895378e-05, reg = 1e-10, validation accuracy is 0.649\n",
      "lr = 9.798006024854252e-05, reg = 1e-10, validation accuracy is 0.696\n",
      "lr = 0.0015500672638029886, reg = 1e-10, validation accuracy is 0.7\n",
      "lr = 0.000233322407480608, reg = 1e-10, validation accuracy is 0.741\n",
      "lr = 0.001034725486107847, reg = 1e-10, validation accuracy is 0.732\n",
      "lr = 1.814455515451092e-05, reg = 1e-10, validation accuracy is 0.602\n",
      "lr = 0.0023977281239786394, reg = 1e-10, validation accuracy is 0.679\n",
      "lr = 0.00018592683890558467, reg = 1e-10, validation accuracy is 0.73\n",
      "lr = 0.00015828243833438324, reg = 1e-10, validation accuracy is 0.724\n",
      "lr = 1.703728984147158e-05, reg = 1e-10, validation accuracy is 0.609\n",
      "lr = 0.005171713154479716, reg = 1e-10, validation accuracy is 0.56\n",
      "lr = 0.00022262840711706407, reg = 1e-10, validation accuracy is 0.739\n",
      "lr = 0.0005543540968943043, reg = 1e-10, validation accuracy is 0.737\n",
      "lr = 0.0020646154334316882, reg = 1e-10, validation accuracy is 0.673\n",
      "lr = 0.000631269222563926, reg = 1e-10, validation accuracy is 0.733\n",
      "lr = 3.126458677944705e-05, reg = 1e-10, validation accuracy is 0.613\n",
      "lr = 3.0101779002806457e-05, reg = 1e-10, validation accuracy is 0.642\n",
      "lr = 0.0021052067759118327, reg = 1e-10, validation accuracy is 0.666\n",
      "lr = 0.00010797508629631022, reg = 1e-10, validation accuracy is 0.714\n",
      "Training time for 10 epochs: 176.47 sec\n",
      "In descending order of learning rate:\n",
      "lr = 0.005171713154479716, reg = 1e-10, validation accuracy is 0.56\n",
      "lr = 0.0023977281239786394, reg = 1e-10, validation accuracy is 0.679\n",
      "lr = 0.0021052067759118327, reg = 1e-10, validation accuracy is 0.666\n",
      "lr = 0.0020646154334316882, reg = 1e-10, validation accuracy is 0.673\n",
      "lr = 0.0015500672638029886, reg = 1e-10, validation accuracy is 0.7\n",
      "lr = 0.001034725486107847, reg = 1e-10, validation accuracy is 0.732\n",
      "lr = 0.000631269222563926, reg = 1e-10, validation accuracy is 0.733\n",
      "lr = 0.0005543540968943043, reg = 1e-10, validation accuracy is 0.737\n",
      "lr = 0.000233322407480608, reg = 1e-10, validation accuracy is 0.741\n",
      "lr = 0.00022262840711706407, reg = 1e-10, validation accuracy is 0.739\n",
      "lr = 0.00018592683890558467, reg = 1e-10, validation accuracy is 0.73\n",
      "lr = 0.00015828243833438324, reg = 1e-10, validation accuracy is 0.724\n",
      "lr = 0.00010797508629631022, reg = 1e-10, validation accuracy is 0.714\n",
      "lr = 9.798006024854252e-05, reg = 1e-10, validation accuracy is 0.696\n",
      "lr = 5.882224702688513e-05, reg = 1e-10, validation accuracy is 0.671\n",
      "lr = 3.207152865895378e-05, reg = 1e-10, validation accuracy is 0.649\n",
      "lr = 3.126458677944705e-05, reg = 1e-10, validation accuracy is 0.613\n",
      "lr = 3.0101779002806457e-05, reg = 1e-10, validation accuracy is 0.642\n",
      "lr = 1.814455515451092e-05, reg = 1e-10, validation accuracy is 0.602\n",
      "lr = 1.703728984147158e-05, reg = 1e-10, validation accuracy is 0.609\n"
     ]
    }
   ],
   "source": [
    "stat = []\n",
    "\n",
    "start = time.time()\n",
    "max_count = 20\n",
    "for count in range(max_count):\n",
    "    reg = 1e-10\n",
    "    lr = 10**random.uniform(-5,-2)\n",
    "    \n",
    "    model = generator().type(gpu_dtype)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    train(model, loss_fn, optimizer, num_epochs=1)\n",
    "    val_acc = check_accuracy(model, loader_val)\n",
    "    \n",
    "    print('lr = {}, reg = {}, validation accuracy is {}  '.format(lr, reg, val_acc))\n",
    "    stat.append([lr, reg, val_acc])\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "print('Training time for 10 epochs: {1:.2f} sec'.format(val_acc, end-start))\n",
    "\n",
    "sorted_stat = sorted(stat, key=lambda x: x[0], reverse=True)\n",
    "print (\"In descending order of learning rate:\")\n",
    "for lr, reg, val_acc in sorted_stat:\n",
    "    print('lr = {}, reg = {}, validation accuracy is {}  '.format(lr, reg, val_acc))    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust Learning Rate \n",
    "\n",
    "We turn down regularization (reg=1e-10), and do a coarse learning rate search over several multi-layer CNN with maxpooling.\n",
    "\n",
    "## Increase Depth\n",
    "\n",
    "####  Model 4-Conv Layers, 2 MaxPool Blocks\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (1): ReLU(inplace)\n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (4): ReLU(inplace)\n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (6): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (7): ReLU(inplace)\n",
    "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (10): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (11): ReLU(inplace)\n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (14): Flatten(\n",
    "  )\n",
    "  (15): Linear(in_features=8192, out_features=1024)\n",
    "  (16): ReLU(inplace)\n",
    "  (17): Linear(in_features=1024, out_features=10)\n",
    "\n",
    "* Training time for 1 epoch: 8.68 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "lr = 0.2839542464941698, reg = 1e-10, validation accuracy is 0.083  \n",
    "lr = 0.21651954228087467, reg = 1e-10, validation accuracy is 0.079   \n",
    "lr = 0.18749522641775604, reg = 1e-10, validation accuracy is 0.079   \n",
    "lr = 0.04615531370572979, reg = 1e-10, validation accuracy is 0.087   \n",
    "lr = 0.01949218798321564, reg = 1e-10, validation accuracy is 0.113   \n",
    "** lr = 0.0006625559311464299, reg = 1e-10, validation accuracy is 0.727 **   \n",
    "** r = 0.000144482779361209, reg = 1e-10, validation accuracy is 0.701 **  \n",
    "lr = 8.516588480512839e-05, reg = 1e-10, validation accuracy is 0.664  \n",
    "lr = 1.557003750655694e-05, reg = 1e-10, validation accuracy is 0.593  \n",
    "lr = 1.0379299460698738e-05, reg = 1e-10, validation accuracy is 0.559 \n",
    "\n",
    "####  Model 5-Conv Layers, 2 MaxPool Blocks\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (1): ReLU(inplace)\n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (4): ReLU(inplace)\n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (6): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (7): ReLU(inplace)\n",
    "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (10): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (11): ReLU(inplace)\n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (13): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (14): ReLU(inplace)\n",
    "  (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (17): Flatten(\n",
    "  )\n",
    "  (18): Linear(in_features=8192, out_features=1024)\n",
    "  (19): ReLU(inplace)\n",
    "  (20): Linear(in_features=1024, out_features=10)\n",
    ")\n",
    "\n",
    "* Training time for 1 epoch: 7.57 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "In descending order of learning rate:\n",
    "lr = 0.005171713154479716, reg = 1e-10, validation accuracy is 0.56  \n",
    "lr = 0.0023977281239786394, reg = 1e-10, validation accuracy is 0.679  \n",
    "lr = 0.0021052067759118327, reg = 1e-10, validation accuracy is 0.666  \n",
    "lr = 0.0020646154334316882, reg = 1e-10, validation accuracy is 0.673  \n",
    "lr = 0.0015500672638029886, reg = 1e-10, validation accuracy is 0.7  \n",
    "** lr = 0.001034725486107847, reg = 1e-10, validation accuracy is 0.732 **  \n",
    "** lr = 0.000631269222563926, reg = 1e-10, validation accuracy is 0.733 **  \n",
    "** lr = 0.0005543540968943043, reg = 1e-10, validation accuracy is 0.737 **  \n",
    "** lr = 0.000233322407480608, reg = 1e-10, validation accuracy is 0.741 **  \n",
    "** lr = 0.00022262840711706407, reg = 1e-10, validation accuracy is 0.739 **  \n",
    "** lr = 0.00018592683890558467, reg = 1e-10, validation accuracy is 0.73 **  \n",
    "** lr = 0.00015828243833438324, reg = 1e-10, validation accuracy is 0.724 **  \n",
    "lr = 0.00010797508629631022, reg = 1e-10, validation accuracy is 0.714  \n",
    "lr = 9.798006024854252e-05, reg = 1e-10, validation accuracy is 0.696  \n",
    "lr = 5.882224702688513e-05, reg = 1e-10, validation accuracy is 0.671  \n",
    "lr = 3.207152865895378e-05, reg = 1e-10, validation accuracy is 0.649  \n",
    "lr = 3.126458677944705e-05, reg = 1e-10, validation accuracy is 0.613  \n",
    "lr = 3.0101779002806457e-05, reg = 1e-10, validation accuracy is 0.642  \n",
    "lr = 1.814455515451092e-05, reg = 1e-10, validation accuracy is 0.602  \n",
    "lr = 1.703728984147158e-05, reg = 1e-10, validation accuracy is 0.609  \n",
    "\n",
    "####  Model 6-Conv Layers, 2 MaxPool Blocks\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (1): ReLU(inplace)\n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (4): ReLU(inplace)\n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (6): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (7): ReLU(inplace)\n",
    "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (10): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (11): ReLU(inplace)\n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (13): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (14): ReLU(inplace)\n",
    "  (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (16): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (17): ReLU(inplace)\n",
    "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (19): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (20): Flatten(\n",
    "  )\n",
    "  (21): Linear(in_features=16384, out_features=1024)\n",
    "  (22): ReLU(inplace)\n",
    "  (23): Linear(in_features=1024, out_features=10)\n",
    ")\n",
    "\n",
    "* Training time for 1 epoch: 12.99 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "lr = 0.007809235059540799, reg = 1e-10, validation accuracy is 0.397  \n",
    "lr = 0.005884487793553565, reg = 1e-10, validation accuracy is 0.468  \n",
    "lr = 0.005690937983509037, reg = 1e-10, validation accuracy is 0.486  \n",
    "** lr = 0.0005143479683944543, reg = 1e-10, validation accuracy is 0.708 **  \n",
    "** lr = 0.0004542994337330826, reg = 1e-10, validation accuracy is 0.728 **  \n",
    "** lr = 0.00023305794669548055, reg = 1e-10, validation accuracy is 0.735 **  \n",
    "** lr = 0.00014776247999586726, reg = 1e-10, validation accuracy is 0.703 **  \n",
    "** lr = 5.85992713405686e-05, reg = 1e-10, validation accuracy is 0.668 **   \n",
    "** lr = 2.108502413295989e-05, reg = 1e-10, validation accuracy is 0.629 **  \n",
    "lr = 1.8574849492178006e-05, reg = 1e-10, validation accuracy is 0.612  \n",
    "lr = 1.3270632405294917e-05, reg = 1e-10, validation accuracy is 0.586  \n",
    "lr = 8.865347011292369e-06, reg = 1e-10, validation accuracy is 0.597  \n",
    "lr = 8.470683213744055e-06, reg = 1e-10, validation accuracy is 0.575  \n",
    "\n",
    "\n",
    "## Increase Width\n",
    "\n",
    "####  Model 5-Conv Layers, 2 MaxPool Blocks (WIDER)\n",
    "\n",
    "Sequential(\n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (1): ReLU(inplace)\n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (4): ReLU(inplace)\n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (6): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (7): ReLU(inplace)\n",
    "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (10): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (11): ReLU(inplace)\n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (13): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "  (14): ReLU(inplace)\n",
    "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
    "  (17): Flatten(\n",
    "  )\n",
    "  (18): Linear(in_features=16384, out_features=1024)\n",
    "  (19): ReLU(inplace)\n",
    "  (20): Linear(in_features=1024, out_features=10)\n",
    ")\n",
    "\n",
    "* Training time for 1 epoch: 13.18 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "lr = 0.006511131263854212, reg = 1e-10, validation accuracy is 0.447  \n",
    "lr = 0.005311015630015579, reg = 1e-10, validation accuracy is 0.5  \n",
    "lr = 0.0050095585969268655, reg = 1e-10, validation accuracy is 0.468  \n",
    "lr = 0.0019763392774939607, reg = 1e-10, validation accuracy is 0.607  \n",
    "lr = 0.0016212594827078903, reg = 1e-10, validation accuracy is 0.67  \n",
    "lr = 0.0012378413601148973, reg = 1e-10, validation accuracy is 0.673  \n",
    "** lr = 0.0006205094279250759, reg = 1e-10, validation accuracy is 0.737 **  \n",
    "** lr = 0.0006055617870144327, reg = 1e-10, validation accuracy is 0.726 **  \n",
    "** lr = 0.0002567453541515327, reg = 1e-10, validation accuracy is 0.757 **  \n",
    "** lr = 0.00010598921967978786, reg = 1e-10, validation accuracy is 0.717 **  \n",
    "** lr = 7.918018060365135e-05, reg = 1e-10, validation accuracy is 0.728 **  \n",
    "lr = 5.3923032925417105e-05, reg = 1e-10, validation accuracy is 0.67  \n",
    "lr = 2.5770930840799296e-05, reg = 1e-10, validation accuracy is 0.664  \n",
    "lr = 1.0070525736216065e-05, reg = 1e-10, validation accuracy is 0.598  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 1.834628949407268e-05, reg = 4.781387738199418e-09, validation accuracy is 0.63  \n",
      "lr = 4.007498928855568e-05, reg = 1.0462145053481942e-05, validation accuracy is 0.66  \n",
      "lr = 6.5440784050296394e-06, reg = 1.460840922329886e-10, validation accuracy is 0.584  \n",
      "lr = 2.2601995271654264e-06, reg = 0.4816039172648769, validation accuracy is 0.43  \n",
      "lr = 0.0059948302614509005, reg = 0.010011618127031887, validation accuracy is 0.566  \n",
      "lr = 1.0608505969109444e-06, reg = 9.36159934357995e-08, validation accuracy is 0.429  \n",
      "lr = 0.008419751428795624, reg = 0.0035646738516316866, validation accuracy is 0.478  \n",
      "lr = 0.002831501424336825, reg = 2.1814028362557628e-05, validation accuracy is 0.594  \n",
      "lr = 0.0004420536106205546, reg = 2.0186822341150736e-06, validation accuracy is 0.768  \n",
      "lr = 0.00014157475047081133, reg = 3.515875715049107e-05, validation accuracy is 0.723  \n",
      "lr = 0.0017469433543108419, reg = 0.005407562156582751, validation accuracy is 0.588  \n",
      "lr = 0.0018436283136011092, reg = 1.20855073494988e-07, validation accuracy is 0.602  \n",
      "lr = 1.103067655335038e-06, reg = 1.3969242782012285e-06, validation accuracy is 0.433  \n",
      "lr = 0.00016799852379122324, reg = 15.613566194573618, validation accuracy is 0.098  \n",
      "lr = 3.312216301167796e-06, reg = 1.3208096729461642, validation accuracy is 0.394  \n",
      "lr = 7.049317699161044e-06, reg = 0.019993230642586797, validation accuracy is 0.59  \n",
      "lr = 5.494435066444071e-06, reg = 1.6931594998242051e-09, validation accuracy is 0.571  \n",
      "lr = 0.0006996954263941067, reg = 1.9038337189684477e-06, validation accuracy is 0.708  \n",
      "lr = 0.00037206712670449505, reg = 0.09927454316034201, validation accuracy is 0.614  \n",
      "lr = 5.268044462970665e-05, reg = 0.0948523510014383, validation accuracy is 0.668  \n",
      "lr = 1.0112212652872966e-05, reg = 0.020453604351085584, validation accuracy is 0.616  \n",
      "lr = 0.00011805442164972787, reg = 3.818327291174253e-10, validation accuracy is 0.716  \n",
      "lr = 4.1131199258244805e-06, reg = 0.009183569193389245, validation accuracy is 0.553  \n",
      "lr = 0.0019448764802993351, reg = 0.0014559406583695056, validation accuracy is 0.64  \n",
      "lr = 0.0001638932273529234, reg = 3.0703157061644324e-05, validation accuracy is 0.73  \n",
      "lr = 5.987749489253305e-06, reg = 3.193174800162297e-09, validation accuracy is 0.575  \n",
      "lr = 2.980838513237049e-05, reg = 3.9724783982491223, validation accuracy is 0.387  \n",
      "lr = 6.914399074312584e-05, reg = 0.030651772897969106, validation accuracy is 0.686  \n",
      "lr = 2.8276700188882648e-05, reg = 0.05565412975199819, validation accuracy is 0.618  \n",
      "lr = 0.0005251670566001226, reg = 0.0018050589295523598, validation accuracy is 0.699  \n",
      "lr = 4.625603296907752e-05, reg = 6.0699709968522045e-09, validation accuracy is 0.666  \n",
      "lr = 2.8013165961810122e-05, reg = 0.6740105236591744, validation accuracy is 0.543  \n",
      "lr = 1.4865817289651003e-05, reg = 28.45191209788082, validation accuracy is 0.321  \n",
      "lr = 0.005996111065727766, reg = 4.813600671695348e-06, validation accuracy is 0.428  \n",
      "lr = 0.00016151175929450816, reg = 0.001461378511321383, validation accuracy is 0.73  \n",
      "lr = 0.00011532989154129476, reg = 3.889665794272065, validation accuracy is 0.226  \n",
      "lr = 0.0002938522880460647, reg = 3.1116344006152496e-09, validation accuracy is 0.731  \n",
      "lr = 2.3012233654655408e-06, reg = 1.0587801567612161e-09, validation accuracy is 0.519  \n",
      "lr = 3.2066990160856126e-05, reg = 73.0011473426906, validation accuracy is 0.263  \n",
      "lr = 0.0006055829256460011, reg = 9.58996938648248e-07, validation accuracy is 0.722  \n",
      "lr = 0.002556305569075787, reg = 6.201957204054882e-06, validation accuracy is 0.57  \n",
      "lr = 0.0021901124260892647, reg = 0.0003707486641797913, validation accuracy is 0.606  \n",
      "lr = 1.3116142483651602e-06, reg = 0.02321093986222916, validation accuracy is 0.479  \n",
      "lr = 0.00015862184981477027, reg = 3.311901217036856e-07, validation accuracy is 0.72  \n",
      "lr = 0.002985900214736691, reg = 0.010453452867674394, validation accuracy is 0.529  \n",
      "lr = 2.019140109564537e-06, reg = 0.00023777504385718968, validation accuracy is 0.493  \n",
      "lr = 1.4115769829339359e-06, reg = 7.626434172108425, validation accuracy is 0.189  \n",
      "lr = 1.4783779752657483e-05, reg = 55.130951067603085, validation accuracy is 0.195  \n",
      "lr = 0.0002885154495256621, reg = 2.771973322549355e-09, validation accuracy is 0.75  \n",
      "lr = 0.0008867992873069955, reg = 1.4372398781436804, validation accuracy is 0.199  \n",
      "lr = 5.178320084401512e-06, reg = 3.125014916588725e-07, validation accuracy is 0.579  \n",
      "lr = 1.30366135150047e-06, reg = 24.68131034640062, validation accuracy is 0.117  \n",
      "lr = 3.13625482992454e-05, reg = 0.006702166937063668, validation accuracy is 0.67  \n",
      "lr = 1.0267141502637463e-05, reg = 2.2423114552249097e-05, validation accuracy is 0.624  \n",
      "lr = 0.0013869356779387546, reg = 5.94062005313746e-05, validation accuracy is 0.653  \n",
      "lr = 3.8290175559735334e-06, reg = 2.5761485147151517e-08, validation accuracy is 0.539  \n",
      "lr = 0.0005443722591657279, reg = 0.00017920546701173702, validation accuracy is 0.719  \n",
      "lr = 9.609980503912395e-05, reg = 0.005374903040295943, validation accuracy is 0.677  \n",
      "lr = 0.0003961550140640271, reg = 0.8105443384587647, validation accuracy is 0.37  \n",
      "lr = 1.8528189621301718e-06, reg = 4.746231249856485e-09, validation accuracy is 0.482  \n",
      "lr = 0.00822361091242141, reg = 7.4467018607870274, validation accuracy is 0.113  \n",
      "lr = 0.000348507497041526, reg = 1.4605422936453535e-05, validation accuracy is 0.725  \n",
      "lr = 1.5807948954963685e-06, reg = 4.214524828334788e-07, validation accuracy is 0.485  \n",
      "lr = 0.003373215466596708, reg = 1.0008602410294153e-09, validation accuracy is 0.586  \n",
      "lr = 1.056164027555874e-06, reg = 6.01442570862751e-09, validation accuracy is 0.434  \n",
      "lr = 0.00030976635881782815, reg = 1.9752562992451137e-05, validation accuracy is 0.737  \n",
      "lr = 3.348878693686202e-05, reg = 3.7300717080778774e-05, validation accuracy is 0.656  \n",
      "lr = 0.0003159819304478141, reg = 28.656846959736583, validation accuracy is 0.113  \n",
      "lr = 0.0002719530062001166, reg = 8.181890417359118e-05, validation accuracy is 0.714  \n",
      "lr = 1.647117910036382e-05, reg = 1.5768845674707156e-06, validation accuracy is 0.631  \n",
      "lr = 0.003732182285007303, reg = 2.7238935119576925e-05, validation accuracy is 0.563  \n",
      "lr = 0.005509688622390361, reg = 4.910230537193647e-10, validation accuracy is 0.506  \n",
      "lr = 0.0012393288000769702, reg = 5.12602146030666, validation accuracy is 0.113  \n",
      "lr = 7.764263308560473e-05, reg = 3.9283309473615766, validation accuracy is 0.203  \n",
      "lr = 0.0004122334077427315, reg = 6.4451833938235595e-09, validation accuracy is 0.747  \n",
      "lr = 2.8694436259300402e-06, reg = 30.457268745591442, validation accuracy is 0.171  \n",
      "lr = 2.497192285643466e-06, reg = 3.3166095775739293, validation accuracy is 0.328  \n",
      "lr = 8.454629846380738e-06, reg = 1.7079373718090442e-10, validation accuracy is 0.587  \n",
      "lr = 0.00048459438835051166, reg = 0.05983089061009524, validation accuracy is 0.621  \n",
      "lr = 1.6534760084963464e-06, reg = 3.3220756649313485e-07, validation accuracy is 0.5  \n",
      "lr = 1.0002048634484103e-05, reg = 1.0670019552932154e-10, validation accuracy is 0.611  \n",
      "lr = 0.008294070444654194, reg = 3.236490933113967e-10, validation accuracy is 0.476  \n",
      "lr = 2.188164811777817e-05, reg = 1.5925851372560153e-05, validation accuracy is 0.639  \n",
      "lr = 6.498649825474194e-06, reg = 0.10716034029437083, validation accuracy is 0.562  \n",
      "lr = 0.0042242132048472296, reg = 0.00192059789186161, validation accuracy is 0.608  \n",
      "lr = 0.00030255947398111444, reg = 1.1887805824295586e-07, validation accuracy is 0.732  \n",
      "lr = 7.734499090723071e-05, reg = 2.6875164976126248e-09, validation accuracy is 0.681  \n",
      "lr = 1.397889179081114e-05, reg = 0.013529082259143236, validation accuracy is 0.631  \n",
      "lr = 2.2995384859025576e-06, reg = 9.676504532814295e-09, validation accuracy is 0.522  \n",
      "lr = 4.971515443042102e-05, reg = 2.6175795871087453e-09, validation accuracy is 0.687  \n",
      "lr = 0.00025635190472579454, reg = 26.22154832223876, validation accuracy is 0.087  \n",
      "lr = 2.5404395271978616e-06, reg = 0.00010934657208394575, validation accuracy is 0.532  \n",
      "lr = 3.830276933583746e-06, reg = 4.100863399513804e-09, validation accuracy is 0.523  \n",
      "lr = 0.007708653113076822, reg = 0.09250638253620837, validation accuracy is 0.151  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 5.341281559305708e-05, reg = 0.17541836465002894, validation accuracy is 0.632  \n",
      "lr = 0.009098637986016157, reg = 6.696844600665914e-06, validation accuracy is 0.258  \n",
      "lr = 9.957375080232577e-06, reg = 0.0003074218017755357, validation accuracy is 0.615  \n",
      "lr = 0.006985326861929126, reg = 0.002004101256505656, validation accuracy is 0.522  \n",
      "lr = 9.30062019336857e-06, reg = 0.1593363262333967, validation accuracy is 0.572  \n",
      "lr = 0.006126752859952109, reg = 4.4516479043029783e-07, validation accuracy is 0.402  \n",
      "Training time for 10 epochs: 1316.03 sec\n",
      "In descending order of learning rate:\n",
      "lr = 0.009098637986016157, reg = 6.696844600665914e-06, validation accuracy is 0.258  \n",
      "lr = 0.008419751428795624, reg = 0.0035646738516316866, validation accuracy is 0.478  \n",
      "lr = 0.008294070444654194, reg = 3.236490933113967e-10, validation accuracy is 0.476  \n",
      "lr = 0.00822361091242141, reg = 7.4467018607870274, validation accuracy is 0.113  \n",
      "lr = 0.007708653113076822, reg = 0.09250638253620837, validation accuracy is 0.151  \n",
      "lr = 0.006985326861929126, reg = 0.002004101256505656, validation accuracy is 0.522  \n",
      "lr = 0.006126752859952109, reg = 4.4516479043029783e-07, validation accuracy is 0.402  \n",
      "lr = 0.005996111065727766, reg = 4.813600671695348e-06, validation accuracy is 0.428  \n",
      "lr = 0.0059948302614509005, reg = 0.010011618127031887, validation accuracy is 0.566  \n",
      "lr = 0.005509688622390361, reg = 4.910230537193647e-10, validation accuracy is 0.506  \n",
      "lr = 0.0042242132048472296, reg = 0.00192059789186161, validation accuracy is 0.608  \n",
      "lr = 0.003732182285007303, reg = 2.7238935119576925e-05, validation accuracy is 0.563  \n",
      "lr = 0.003373215466596708, reg = 1.0008602410294153e-09, validation accuracy is 0.586  \n",
      "lr = 0.002985900214736691, reg = 0.010453452867674394, validation accuracy is 0.529  \n",
      "lr = 0.002831501424336825, reg = 2.1814028362557628e-05, validation accuracy is 0.594  \n",
      "lr = 0.002556305569075787, reg = 6.201957204054882e-06, validation accuracy is 0.57  \n",
      "lr = 0.0021901124260892647, reg = 0.0003707486641797913, validation accuracy is 0.606  \n",
      "lr = 0.0019448764802993351, reg = 0.0014559406583695056, validation accuracy is 0.64  \n",
      "lr = 0.0018436283136011092, reg = 1.20855073494988e-07, validation accuracy is 0.602  \n",
      "lr = 0.0017469433543108419, reg = 0.005407562156582751, validation accuracy is 0.588  \n",
      "lr = 0.0013869356779387546, reg = 5.94062005313746e-05, validation accuracy is 0.653  \n",
      "lr = 0.0012393288000769702, reg = 5.12602146030666, validation accuracy is 0.113  \n",
      "lr = 0.0008867992873069955, reg = 1.4372398781436804, validation accuracy is 0.199  \n",
      "lr = 0.0006996954263941067, reg = 1.9038337189684477e-06, validation accuracy is 0.708  \n",
      "lr = 0.0006055829256460011, reg = 9.58996938648248e-07, validation accuracy is 0.722  \n",
      "lr = 0.0005443722591657279, reg = 0.00017920546701173702, validation accuracy is 0.719  \n",
      "lr = 0.0005251670566001226, reg = 0.0018050589295523598, validation accuracy is 0.699  \n",
      "lr = 0.00048459438835051166, reg = 0.05983089061009524, validation accuracy is 0.621  \n",
      "lr = 0.0004420536106205546, reg = 2.0186822341150736e-06, validation accuracy is 0.768  \n",
      "lr = 0.0004122334077427315, reg = 6.4451833938235595e-09, validation accuracy is 0.747  \n",
      "lr = 0.0003961550140640271, reg = 0.8105443384587647, validation accuracy is 0.37  \n",
      "lr = 0.00037206712670449505, reg = 0.09927454316034201, validation accuracy is 0.614  \n",
      "lr = 0.000348507497041526, reg = 1.4605422936453535e-05, validation accuracy is 0.725  \n",
      "lr = 0.0003159819304478141, reg = 28.656846959736583, validation accuracy is 0.113  \n",
      "lr = 0.00030976635881782815, reg = 1.9752562992451137e-05, validation accuracy is 0.737  \n",
      "lr = 0.00030255947398111444, reg = 1.1887805824295586e-07, validation accuracy is 0.732  \n",
      "lr = 0.0002938522880460647, reg = 3.1116344006152496e-09, validation accuracy is 0.731  \n",
      "lr = 0.0002885154495256621, reg = 2.771973322549355e-09, validation accuracy is 0.75  \n",
      "lr = 0.0002719530062001166, reg = 8.181890417359118e-05, validation accuracy is 0.714  \n",
      "lr = 0.00025635190472579454, reg = 26.22154832223876, validation accuracy is 0.087  \n",
      "lr = 0.00016799852379122324, reg = 15.613566194573618, validation accuracy is 0.098  \n",
      "lr = 0.0001638932273529234, reg = 3.0703157061644324e-05, validation accuracy is 0.73  \n",
      "lr = 0.00016151175929450816, reg = 0.001461378511321383, validation accuracy is 0.73  \n",
      "lr = 0.00015862184981477027, reg = 3.311901217036856e-07, validation accuracy is 0.72  \n",
      "lr = 0.00014157475047081133, reg = 3.515875715049107e-05, validation accuracy is 0.723  \n",
      "lr = 0.00011805442164972787, reg = 3.818327291174253e-10, validation accuracy is 0.716  \n",
      "lr = 0.00011532989154129476, reg = 3.889665794272065, validation accuracy is 0.226  \n",
      "lr = 9.609980503912395e-05, reg = 0.005374903040295943, validation accuracy is 0.677  \n",
      "lr = 7.764263308560473e-05, reg = 3.9283309473615766, validation accuracy is 0.203  \n",
      "lr = 7.734499090723071e-05, reg = 2.6875164976126248e-09, validation accuracy is 0.681  \n",
      "lr = 6.914399074312584e-05, reg = 0.030651772897969106, validation accuracy is 0.686  \n",
      "lr = 5.341281559305708e-05, reg = 0.17541836465002894, validation accuracy is 0.632  \n",
      "lr = 5.268044462970665e-05, reg = 0.0948523510014383, validation accuracy is 0.668  \n",
      "lr = 4.971515443042102e-05, reg = 2.6175795871087453e-09, validation accuracy is 0.687  \n",
      "lr = 4.625603296907752e-05, reg = 6.0699709968522045e-09, validation accuracy is 0.666  \n",
      "lr = 4.007498928855568e-05, reg = 1.0462145053481942e-05, validation accuracy is 0.66  \n",
      "lr = 3.348878693686202e-05, reg = 3.7300717080778774e-05, validation accuracy is 0.656  \n",
      "lr = 3.2066990160856126e-05, reg = 73.0011473426906, validation accuracy is 0.263  \n",
      "lr = 3.13625482992454e-05, reg = 0.006702166937063668, validation accuracy is 0.67  \n",
      "lr = 2.980838513237049e-05, reg = 3.9724783982491223, validation accuracy is 0.387  \n",
      "lr = 2.8276700188882648e-05, reg = 0.05565412975199819, validation accuracy is 0.618  \n",
      "lr = 2.8013165961810122e-05, reg = 0.6740105236591744, validation accuracy is 0.543  \n",
      "lr = 2.188164811777817e-05, reg = 1.5925851372560153e-05, validation accuracy is 0.639  \n",
      "lr = 1.834628949407268e-05, reg = 4.781387738199418e-09, validation accuracy is 0.63  \n",
      "lr = 1.647117910036382e-05, reg = 1.5768845674707156e-06, validation accuracy is 0.631  \n",
      "lr = 1.4865817289651003e-05, reg = 28.45191209788082, validation accuracy is 0.321  \n",
      "lr = 1.4783779752657483e-05, reg = 55.130951067603085, validation accuracy is 0.195  \n",
      "lr = 1.397889179081114e-05, reg = 0.013529082259143236, validation accuracy is 0.631  \n",
      "lr = 1.0267141502637463e-05, reg = 2.2423114552249097e-05, validation accuracy is 0.624  \n",
      "lr = 1.0112212652872966e-05, reg = 0.020453604351085584, validation accuracy is 0.616  \n",
      "lr = 1.0002048634484103e-05, reg = 1.0670019552932154e-10, validation accuracy is 0.611  \n",
      "lr = 9.957375080232577e-06, reg = 0.0003074218017755357, validation accuracy is 0.615  \n",
      "lr = 9.30062019336857e-06, reg = 0.1593363262333967, validation accuracy is 0.572  \n",
      "lr = 8.454629846380738e-06, reg = 1.7079373718090442e-10, validation accuracy is 0.587  \n",
      "lr = 7.049317699161044e-06, reg = 0.019993230642586797, validation accuracy is 0.59  \n",
      "lr = 6.5440784050296394e-06, reg = 1.460840922329886e-10, validation accuracy is 0.584  \n",
      "lr = 6.498649825474194e-06, reg = 0.10716034029437083, validation accuracy is 0.562  \n",
      "lr = 5.987749489253305e-06, reg = 3.193174800162297e-09, validation accuracy is 0.575  \n",
      "lr = 5.494435066444071e-06, reg = 1.6931594998242051e-09, validation accuracy is 0.571  \n",
      "lr = 5.178320084401512e-06, reg = 3.125014916588725e-07, validation accuracy is 0.579  \n",
      "lr = 4.1131199258244805e-06, reg = 0.009183569193389245, validation accuracy is 0.553  \n",
      "lr = 3.830276933583746e-06, reg = 4.100863399513804e-09, validation accuracy is 0.523  \n",
      "lr = 3.8290175559735334e-06, reg = 2.5761485147151517e-08, validation accuracy is 0.539  \n",
      "lr = 3.312216301167796e-06, reg = 1.3208096729461642, validation accuracy is 0.394  \n",
      "lr = 2.8694436259300402e-06, reg = 30.457268745591442, validation accuracy is 0.171  \n",
      "lr = 2.5404395271978616e-06, reg = 0.00010934657208394575, validation accuracy is 0.532  \n",
      "lr = 2.497192285643466e-06, reg = 3.3166095775739293, validation accuracy is 0.328  \n",
      "lr = 2.3012233654655408e-06, reg = 1.0587801567612161e-09, validation accuracy is 0.519  \n",
      "lr = 2.2995384859025576e-06, reg = 9.676504532814295e-09, validation accuracy is 0.522  \n",
      "lr = 2.2601995271654264e-06, reg = 0.4816039172648769, validation accuracy is 0.43  \n",
      "lr = 2.019140109564537e-06, reg = 0.00023777504385718968, validation accuracy is 0.493  \n",
      "lr = 1.8528189621301718e-06, reg = 4.746231249856485e-09, validation accuracy is 0.482  \n",
      "lr = 1.6534760084963464e-06, reg = 3.3220756649313485e-07, validation accuracy is 0.5  \n",
      "lr = 1.5807948954963685e-06, reg = 4.214524828334788e-07, validation accuracy is 0.485  \n",
      "lr = 1.4115769829339359e-06, reg = 7.626434172108425, validation accuracy is 0.189  \n",
      "lr = 1.3116142483651602e-06, reg = 0.02321093986222916, validation accuracy is 0.479  \n",
      "lr = 1.30366135150047e-06, reg = 24.68131034640062, validation accuracy is 0.117  \n",
      "lr = 1.103067655335038e-06, reg = 1.3969242782012285e-06, validation accuracy is 0.433  \n",
      "lr = 1.0608505969109444e-06, reg = 9.36159934357995e-08, validation accuracy is 0.429  \n",
      "lr = 1.056164027555874e-06, reg = 6.01442570862751e-09, validation accuracy is 0.434  \n"
     ]
    }
   ],
   "source": [
    "stat = []\n",
    "\n",
    "start = time.time()\n",
    "max_count = 100\n",
    "for count in range(max_count):\n",
    "    reg = 10**random.uniform(-10,2)\n",
    "    lr = 10**random.uniform(-6,-2)\n",
    "    \n",
    "    model = generator().type(gpu_dtype)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "    train(model, loss_fn, optimizer, num_epochs=1)\n",
    "    val_acc = check_accuracy(model, loader_val)\n",
    "    \n",
    "    print('lr = {}, reg = {}, validation accuracy is {}  '.format(lr, reg, val_acc))\n",
    "    stat.append([lr, reg, val_acc])\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "print('Training time for 10 epochs: {1:.2f} sec'.format(val_acc, end-start))\n",
    "\n",
    "sorted_stat = sorted(stat, key=lambda x: x[0], reverse=True)\n",
    "print (\"In descending order of learning rate:\")\n",
    "for lr, reg, val_acc in sorted_stat:\n",
    "    print('lr = {}, reg = {}, validation accuracy is {}  '.format(lr, reg, val_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune Learning Rate + Regularization\n",
    "\n",
    "####  Model 5-Conv Layers, 2 MaxPool Blocks (WIDER)\n",
    "\n",
    "Sequential(  \n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (1): ReLU(inplace)  \n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (4): ReLU(inplace)  \n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (6): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (7): ReLU(inplace)  \n",
    "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))  \n",
    "  (10): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (11): ReLU(inplace)  \n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (13): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (14): ReLU(inplace)  \n",
    "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))  \n",
    "  (17): Flatten()  \n",
    "  (18): Linear(in_features=16384, out_features=1024)  \n",
    "  (19): ReLU(inplace)  \n",
    "  (20): Linear(in_features=1024, out_features=10)  \n",
    ")  \n",
    "\n",
    "* Training time for 1 epoch: 13.18 sec\n",
    "\n",
    "* In descending order of learning rate:\n",
    "lr = 0.0019448764802993351, reg = 0.0014559406583695056, validation accuracy is 0.64  \n",
    "lr = 0.0018436283136011092, reg = 1.20855073494988e-07, validation accuracy is 0.602  \n",
    "lr = 0.0017469433543108419, reg = 0.005407562156582751, validation accuracy is 0.588  \n",
    "lr = 0.0013869356779387546, reg = 5.94062005313746e-05, validation accuracy is 0.653  \n",
    "lr = 0.0012393288000769702, reg = 5.12602146030666, validation accuracy is 0.113  \n",
    "lr = 0.0008867992873069955, reg = 1.4372398781436804, validation accuracy is 0.199  \n",
    "lr = 0.0006996954263941067, reg = 1.9038337189684477e-06, validation accuracy is 0.708  \n",
    "** lr = 0.0006055829256460011, reg = 9.58996938648248e-07, validation accuracy is 0.722 **  \n",
    "** lr = 0.0005443722591657279, reg = 0.00017920546701173702, validation accuracy is 0.719 **  \n",
    "lr = 0.0005251670566001226, reg = 0.0018050589295523598, validation accuracy is 0.699  \n",
    "lr = 0.00048459438835051166, reg = 0.05983089061009524, validation accuracy is 0.621  \n",
    "lr = 0.0004420536106205546, reg = 2.0186822341150736e-06, validation accuracy is 0.768  \n",
    "** lr = 0.0004122334077427315, reg = 6.4451833938235595e-09, validation accuracy is 0.747 **  \n",
    "lr = 0.0003961550140640271, reg = 0.8105443384587647, validation accuracy is 0.37  \n",
    "lr = 0.00037206712670449505, reg = 0.09927454316034201, validation accuracy is 0.614  \n",
    "** lr = 0.000348507497041526, reg = 1.4605422936453535e-05, validation accuracy is 0.725 **  \n",
    "lr = 0.0003159819304478141, reg = 28.656846959736583, validation accuracy is 0.113  \n",
    "** lr = 0.00030976635881782815, reg = 1.9752562992451137e-05, validation accuracy is 0.737 **  \n",
    "** lr = 0.00030255947398111444, reg = 1.1887805824295586e-07, validation accuracy is 0.732 **   \n",
    "** lr = 0.0002938522880460647, reg = 3.1116344006152496e-09, validation accuracy is 0.731 **  \n",
    "<span style=\"color:blue\"> ** lr = 0.0002885154495256621, reg = 2.771973322549355e-09, validation accuracy is 0.75 ** <span style=\"color:black\">   \n",
    "lr = 0.0002719530062001166, reg = 8.181890417359118e-05, validation accuracy is 0.714  \n",
    "lr = 0.00025635190472579454, reg = 26.22154832223876, validation accuracy is 0.087  \n",
    "lr = 0.00016799852379122324, reg = 15.613566194573618, validation accuracy is 0.098  \n",
    "** lr = 0.0001638932273529234, reg = 3.0703157061644324e-05, validation accuracy is 0.73 **  \n",
    "** lr = 0.00016151175929450816, reg = 0.001461378511321383, validation accuracy is 0.73 **  \n",
    "lr = 0.00015862184981477027, reg = 3.311901217036856e-07, validation accuracy is 0.72  \n",
    "lr = 0.00014157475047081133, reg = 3.515875715049107e-05, validation accuracy is 0.723  \n",
    "lr = 0.00011805442164972787, reg = 3.818327291174253e-10, validation accuracy is 0.716  \n",
    "lr = 0.00011532989154129476, reg = 3.889665794272065, validation accuracy is 0.226  \n",
    "lr = 9.609980503912395e-05, reg = 0.005374903040295943, validation accuracy is 0.677  \n",
    "lr = 7.764263308560473e-05, reg = 3.9283309473615766, validation accuracy is 0.203  \n",
    "lr = 7.734499090723071e-05, reg = 2.6875164976126248e-09, validation accuracy is 0.681  \n",
    "lr = 6.914399074312584e-05, reg = 0.030651772897969106, validation accuracy is 0.686  \n",
    "lr = 5.341281559305708e-05, reg = 0.17541836465002894, validation accuracy is 0.632  \n",
    "lr = 5.268044462970665e-05, reg = 0.0948523510014383, validation accuracy is 0.668  \n",
    "lr = 4.971515443042102e-05, reg = 2.6175795871087453e-09, validation accuracy is 0.687  \n",
    "lr = 4.625603296907752e-05, reg = 6.0699709968522045e-09, validation accuracy is 0.666  \n",
    "lr = 4.007498928855568e-05, reg = 1.0462145053481942e-05, validation accuracy is 0.66  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 10\n",
      "t = 100, loss = 1.302131\n",
      "t = 200, loss = 1.055626\n",
      "t = 300, loss = 1.135448\n",
      "t = 400, loss = 0.731551\n",
      "t = 500, loss = 0.757980\n",
      "t = 600, loss = 0.837833\n",
      "t = 700, loss = 0.871886\n",
      "train acc: 0.745 val acc:0.737\n",
      "Starting epoch 2 / 10\n",
      "t = 100, loss = 0.571929\n",
      "t = 200, loss = 0.565344\n",
      "t = 300, loss = 0.603255\n",
      "t = 400, loss = 0.480906\n",
      "t = 500, loss = 0.474143\n",
      "t = 600, loss = 0.505449\n",
      "t = 700, loss = 0.457483\n",
      "train acc: 0.838 val acc:0.784\n",
      "Starting epoch 3 / 10\n",
      "t = 100, loss = 0.282405\n",
      "t = 200, loss = 0.280204\n",
      "t = 300, loss = 0.284276\n",
      "t = 400, loss = 0.195764\n",
      "t = 500, loss = 0.146566\n",
      "t = 600, loss = 0.201729\n",
      "t = 700, loss = 0.198754\n",
      "train acc: 0.932 val acc:0.809\n",
      "Starting epoch 4 / 10\n",
      "t = 100, loss = 0.085924\n",
      "t = 200, loss = 0.050464\n",
      "t = 300, loss = 0.051892\n",
      "t = 400, loss = 0.066274\n",
      "t = 500, loss = 0.034314\n",
      "t = 600, loss = 0.056482\n",
      "t = 700, loss = 0.135147\n",
      "train acc: 0.957 val acc:0.809\n",
      "Starting epoch 5 / 10\n",
      "t = 100, loss = 0.031658\n",
      "t = 200, loss = 0.046154\n",
      "t = 300, loss = 0.080537\n",
      "t = 400, loss = 0.030479\n",
      "t = 500, loss = 0.038312\n",
      "t = 600, loss = 0.063997\n",
      "t = 700, loss = 0.044613\n",
      "train acc: 0.97 val acc:0.817\n",
      "Starting epoch 6 / 10\n",
      "t = 100, loss = 0.018360\n",
      "t = 200, loss = 0.031161\n",
      "t = 300, loss = 0.051273\n",
      "t = 400, loss = 0.033788\n",
      "t = 500, loss = 0.049175\n",
      "t = 600, loss = 0.029687\n",
      "t = 700, loss = 0.016906\n",
      "train acc: 0.985 val acc:0.817\n",
      "Starting epoch 7 / 10\n",
      "t = 100, loss = 0.040979\n",
      "t = 200, loss = 0.083458\n",
      "t = 300, loss = 0.074767\n",
      "t = 400, loss = 0.007458\n",
      "t = 500, loss = 0.026587\n",
      "t = 600, loss = 0.004191\n",
      "t = 700, loss = 0.045807\n",
      "train acc: 0.987 val acc:0.811\n",
      "Starting epoch 8 / 10\n",
      "t = 100, loss = 0.008241\n",
      "t = 200, loss = 0.006694\n",
      "t = 300, loss = 0.007278\n",
      "t = 400, loss = 0.013704\n",
      "t = 500, loss = 0.002008\n",
      "t = 600, loss = 0.022659\n",
      "t = 700, loss = 0.006514\n",
      "train acc: 0.983 val acc:0.809\n",
      "Starting epoch 9 / 10\n",
      "t = 100, loss = 0.001847\n",
      "t = 200, loss = 0.012863\n",
      "t = 300, loss = 0.015312\n",
      "t = 400, loss = 0.035060\n",
      "t = 500, loss = 0.001414\n",
      "t = 600, loss = 0.045084\n",
      "t = 700, loss = 0.059503\n",
      "train acc: 0.985 val acc:0.817\n",
      "Starting epoch 10 / 10\n",
      "t = 100, loss = 0.070639\n",
      "t = 200, loss = 0.008766\n",
      "t = 300, loss = 0.029400\n",
      "t = 400, loss = 0.038903\n",
      "t = 500, loss = 0.017340\n",
      "t = 600, loss = 0.010464\n",
      "t = 700, loss = 0.005563\n",
      "train acc: 0.994 val acc:0.823\n",
      "Regularization = 5e-10.\n",
      "Best validation accuracy is 0.823. Training time for 10 epochs: 134.86 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f012ab74e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 10\n",
      "t = 100, loss = 1.204594\n",
      "t = 200, loss = 1.167658\n",
      "t = 300, loss = 1.234994\n",
      "t = 400, loss = 0.752770\n",
      "t = 500, loss = 0.753093\n",
      "t = 600, loss = 0.855827\n",
      "t = 700, loss = 0.852142\n",
      "train acc: 0.742 val acc:0.738\n",
      "Starting epoch 2 / 10\n",
      "t = 100, loss = 0.574701\n",
      "t = 200, loss = 0.641135\n",
      "t = 300, loss = 0.580295\n",
      "t = 400, loss = 0.517988\n",
      "t = 500, loss = 0.515799\n",
      "t = 600, loss = 0.519595\n",
      "t = 700, loss = 0.512896\n",
      "train acc: 0.843 val acc:0.787\n",
      "Starting epoch 3 / 10\n",
      "t = 100, loss = 0.294029\n",
      "t = 200, loss = 0.248863\n",
      "t = 300, loss = 0.254878\n",
      "t = 400, loss = 0.226526\n",
      "t = 500, loss = 0.304504\n",
      "t = 600, loss = 0.118253\n",
      "t = 700, loss = 0.267026\n",
      "train acc: 0.911 val acc:0.791\n",
      "Starting epoch 4 / 10\n",
      "t = 100, loss = 0.111232\n",
      "t = 200, loss = 0.070384\n",
      "t = 300, loss = 0.069479\n",
      "t = 400, loss = 0.152719\n",
      "t = 500, loss = 0.030864\n",
      "t = 600, loss = 0.048662\n",
      "t = 700, loss = 0.112237\n",
      "train acc: 0.959 val acc:0.787\n",
      "Starting epoch 5 / 10\n",
      "t = 100, loss = 0.077441\n",
      "t = 200, loss = 0.053373\n",
      "t = 300, loss = 0.101819\n",
      "t = 400, loss = 0.009790\n",
      "t = 500, loss = 0.074463\n",
      "t = 600, loss = 0.068044\n",
      "t = 700, loss = 0.006935\n",
      "train acc: 0.978 val acc:0.806\n",
      "Starting epoch 6 / 10\n",
      "t = 100, loss = 0.007363\n",
      "t = 200, loss = 0.017009\n",
      "t = 300, loss = 0.022138\n",
      "t = 400, loss = 0.036829\n",
      "t = 500, loss = 0.032919\n",
      "t = 600, loss = 0.025139\n",
      "t = 700, loss = 0.029714\n",
      "train acc: 0.99 val acc:0.812\n",
      "Starting epoch 7 / 10\n",
      "t = 100, loss = 0.011733\n",
      "t = 200, loss = 0.006231\n",
      "t = 300, loss = 0.008421\n",
      "t = 400, loss = 0.003801\n",
      "t = 500, loss = 0.028650\n",
      "t = 600, loss = 0.020988\n",
      "t = 700, loss = 0.007285\n",
      "train acc: 0.995 val acc:0.808\n",
      "Starting epoch 8 / 10\n",
      "t = 100, loss = 0.021259\n",
      "t = 200, loss = 0.023453\n",
      "t = 300, loss = 0.017830\n",
      "t = 400, loss = 0.052083\n",
      "t = 500, loss = 0.025876\n",
      "t = 600, loss = 0.005725\n",
      "t = 700, loss = 0.036865\n",
      "train acc: 0.987 val acc:0.813\n",
      "Starting epoch 9 / 10\n",
      "t = 100, loss = 0.005475\n",
      "t = 200, loss = 0.053802\n",
      "t = 300, loss = 0.090042\n",
      "t = 400, loss = 0.008898\n",
      "t = 500, loss = 0.001442\n",
      "t = 600, loss = 0.028059\n",
      "t = 700, loss = 0.007464\n",
      "train acc: 0.985 val acc:0.81\n",
      "Starting epoch 10 / 10\n",
      "t = 100, loss = 0.071641\n",
      "t = 200, loss = 0.022141\n",
      "t = 300, loss = 0.002806\n",
      "t = 400, loss = 0.017956\n",
      "t = 500, loss = 0.007107\n",
      "t = 600, loss = 0.011495\n",
      "t = 700, loss = 0.021375\n",
      "train acc: 0.994 val acc:0.802\n",
      "Regularization = 1e-09.\n",
      "Best validation accuracy is 0.813. Training time for 10 epochs: 133.40 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f012ab74f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 10\n",
      "t = 100, loss = 1.281325\n",
      "t = 200, loss = 1.232170\n",
      "t = 300, loss = 1.154043\n",
      "t = 400, loss = 0.736414\n",
      "t = 500, loss = 0.763951\n",
      "t = 600, loss = 0.833129\n",
      "t = 700, loss = 0.993367\n",
      "train acc: 0.732 val acc:0.722\n",
      "Starting epoch 2 / 10\n",
      "t = 100, loss = 0.494532\n",
      "t = 200, loss = 0.550428\n",
      "t = 300, loss = 0.662729\n",
      "t = 400, loss = 0.490333\n",
      "t = 500, loss = 0.505286\n",
      "t = 600, loss = 0.556825\n",
      "t = 700, loss = 0.506207\n",
      "train acc: 0.85 val acc:0.796\n",
      "Starting epoch 3 / 10\n",
      "t = 100, loss = 0.250247\n",
      "t = 200, loss = 0.302054\n",
      "t = 300, loss = 0.298213\n",
      "t = 400, loss = 0.234516\n",
      "t = 500, loss = 0.186163\n",
      "t = 600, loss = 0.178183\n",
      "t = 700, loss = 0.299353\n",
      "train acc: 0.929 val acc:0.807\n",
      "Starting epoch 4 / 10\n",
      "t = 100, loss = 0.095263\n",
      "t = 200, loss = 0.093226\n",
      "t = 300, loss = 0.136688\n",
      "t = 400, loss = 0.107297\n",
      "t = 500, loss = 0.044004\n",
      "t = 600, loss = 0.084330\n",
      "t = 700, loss = 0.106846\n",
      "train acc: 0.96 val acc:0.816\n",
      "Starting epoch 5 / 10\n",
      "t = 100, loss = 0.031257\n",
      "t = 200, loss = 0.044711\n",
      "t = 300, loss = 0.062493\n",
      "t = 400, loss = 0.036691\n",
      "t = 500, loss = 0.019030\n",
      "t = 600, loss = 0.011076\n",
      "t = 700, loss = 0.049310\n",
      "train acc: 0.968 val acc:0.797\n",
      "Starting epoch 6 / 10\n",
      "t = 100, loss = 0.047759\n",
      "t = 200, loss = 0.022719\n",
      "t = 300, loss = 0.048355\n",
      "t = 400, loss = 0.086664\n",
      "t = 500, loss = 0.027600\n",
      "t = 600, loss = 0.051034\n",
      "t = 700, loss = 0.045695\n",
      "train acc: 0.984 val acc:0.826\n",
      "Starting epoch 7 / 10\n",
      "t = 100, loss = 0.046502\n",
      "t = 200, loss = 0.016530\n",
      "t = 300, loss = 0.023703\n",
      "t = 400, loss = 0.012368\n",
      "t = 500, loss = 0.009961\n",
      "t = 600, loss = 0.015819\n",
      "t = 700, loss = 0.035472\n",
      "train acc: 0.99 val acc:0.823\n",
      "Starting epoch 8 / 10\n",
      "t = 100, loss = 0.037532\n",
      "t = 200, loss = 0.009388\n",
      "t = 300, loss = 0.109006\n",
      "t = 400, loss = 0.045650\n",
      "t = 500, loss = 0.032971\n",
      "t = 600, loss = 0.003757\n",
      "t = 700, loss = 0.043592\n",
      "train acc: 0.985 val acc:0.814\n",
      "Starting epoch 9 / 10\n",
      "t = 100, loss = 0.020584\n",
      "t = 200, loss = 0.051644\n",
      "t = 300, loss = 0.011737\n",
      "t = 400, loss = 0.008964\n",
      "t = 500, loss = 0.036318\n",
      "t = 600, loss = 0.022351\n",
      "t = 700, loss = 0.002924\n",
      "train acc: 0.989 val acc:0.813\n",
      "Starting epoch 10 / 10\n",
      "t = 100, loss = 0.077316\n",
      "t = 200, loss = 0.025068\n",
      "t = 300, loss = 0.041337\n",
      "t = 400, loss = 0.030921\n",
      "t = 500, loss = 0.055095\n",
      "t = 600, loss = 0.033976\n",
      "t = 700, loss = 0.010706\n",
      "train acc: 0.995 val acc:0.822\n",
      "Regularization = 2.8e-09.\n",
      "Best validation accuracy is 0.826. Training time for 10 epochs: 135.21 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f012aa3a588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 10\n",
      "t = 100, loss = 1.217142\n",
      "t = 200, loss = 1.130621\n",
      "t = 300, loss = 1.088014\n",
      "t = 400, loss = 0.723230\n",
      "t = 500, loss = 0.748084\n",
      "t = 600, loss = 0.790512\n",
      "t = 700, loss = 0.896013\n",
      "train acc: 0.73 val acc:0.72\n",
      "Starting epoch 2 / 10\n",
      "t = 100, loss = 0.503795\n",
      "t = 200, loss = 0.652479\n",
      "t = 300, loss = 0.523681\n",
      "t = 400, loss = 0.529529\n",
      "t = 500, loss = 0.489117\n",
      "t = 600, loss = 0.466351\n",
      "t = 700, loss = 0.569352\n",
      "train acc: 0.847 val acc:0.802\n",
      "Starting epoch 3 / 10\n",
      "t = 100, loss = 0.232159\n",
      "t = 200, loss = 0.320501\n",
      "t = 300, loss = 0.255292\n",
      "t = 400, loss = 0.239438\n",
      "t = 500, loss = 0.192504\n",
      "t = 600, loss = 0.219094\n",
      "t = 700, loss = 0.191595\n",
      "train acc: 0.932 val acc:0.805\n",
      "Starting epoch 4 / 10\n",
      "t = 100, loss = 0.047301\n",
      "t = 200, loss = 0.097832\n",
      "t = 300, loss = 0.070838\n",
      "t = 400, loss = 0.069228\n",
      "t = 500, loss = 0.067619\n",
      "t = 600, loss = 0.054574\n",
      "t = 700, loss = 0.098718\n",
      "train acc: 0.954 val acc:0.814\n",
      "Starting epoch 5 / 10\n",
      "t = 100, loss = 0.065685\n",
      "t = 200, loss = 0.030767\n",
      "t = 300, loss = 0.024663\n",
      "t = 400, loss = 0.101559\n",
      "t = 500, loss = 0.100475\n",
      "t = 600, loss = 0.069455\n",
      "t = 700, loss = 0.085422\n",
      "train acc: 0.972 val acc:0.808\n",
      "Starting epoch 6 / 10\n",
      "t = 100, loss = 0.029081\n",
      "t = 200, loss = 0.020404\n",
      "t = 300, loss = 0.018029\n",
      "t = 400, loss = 0.014032\n",
      "t = 500, loss = 0.010126\n",
      "t = 600, loss = 0.067939\n",
      "t = 700, loss = 0.009599\n",
      "train acc: 0.99 val acc:0.834\n",
      "Starting epoch 7 / 10\n",
      "t = 100, loss = 0.046990\n",
      "t = 200, loss = 0.030915\n",
      "t = 300, loss = 0.039377\n",
      "t = 400, loss = 0.007937\n",
      "t = 500, loss = 0.034372\n",
      "t = 600, loss = 0.010189\n",
      "t = 700, loss = 0.093821\n",
      "train acc: 0.982 val acc:0.828\n",
      "Starting epoch 8 / 10\n",
      "t = 100, loss = 0.003674\n",
      "t = 200, loss = 0.005985\n",
      "t = 300, loss = 0.037611\n",
      "t = 400, loss = 0.006327\n",
      "t = 500, loss = 0.003122\n",
      "t = 600, loss = 0.005337\n",
      "t = 700, loss = 0.007115\n",
      "train acc: 0.984 val acc:0.833\n",
      "Starting epoch 9 / 10\n",
      "t = 100, loss = 0.008729\n",
      "t = 200, loss = 0.013049\n",
      "t = 300, loss = 0.030619\n",
      "t = 400, loss = 0.090503\n",
      "t = 500, loss = 0.011064\n",
      "t = 600, loss = 0.009705\n",
      "t = 700, loss = 0.002204\n",
      "train acc: 0.989 val acc:0.822\n",
      "Starting epoch 10 / 10\n",
      "t = 100, loss = 0.093605\n",
      "t = 200, loss = 0.002377\n",
      "t = 300, loss = 0.021898\n",
      "t = 400, loss = 0.094166\n",
      "t = 500, loss = 0.003835\n",
      "t = 600, loss = 0.018389\n",
      "t = 700, loss = 0.015186\n",
      "train acc: 0.982 val acc:0.837\n",
      "Regularization = 1e-08.\n",
      "Best validation accuracy is 0.837. Training time for 10 epochs: 134.97 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f012acfd240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 10\n",
      "t = 100, loss = 1.184618\n",
      "t = 200, loss = 1.262933\n",
      "t = 300, loss = 1.170771\n",
      "t = 400, loss = 0.793889\n",
      "t = 500, loss = 0.808136\n",
      "t = 600, loss = 0.788380\n",
      "t = 700, loss = 0.898860\n",
      "train acc: 0.743 val acc:0.752\n",
      "Starting epoch 2 / 10\n",
      "t = 100, loss = 0.518630\n",
      "t = 200, loss = 0.538422\n",
      "t = 300, loss = 0.567899\n",
      "t = 400, loss = 0.613235\n",
      "t = 500, loss = 0.529969\n",
      "t = 600, loss = 0.456264\n",
      "t = 700, loss = 0.452459\n",
      "train acc: 0.855 val acc:0.794\n",
      "Starting epoch 3 / 10\n",
      "t = 100, loss = 0.297039\n",
      "t = 200, loss = 0.219840\n",
      "t = 300, loss = 0.388979\n",
      "t = 400, loss = 0.227920\n",
      "t = 500, loss = 0.185224\n",
      "t = 600, loss = 0.148253\n",
      "t = 700, loss = 0.149141\n",
      "train acc: 0.932 val acc:0.805\n",
      "Starting epoch 4 / 10\n",
      "t = 100, loss = 0.137202\n",
      "t = 200, loss = 0.053538\n",
      "t = 300, loss = 0.058050\n",
      "t = 400, loss = 0.070715\n",
      "t = 500, loss = 0.061297\n",
      "t = 600, loss = 0.050381\n",
      "t = 700, loss = 0.043803\n",
      "train acc: 0.957 val acc:0.796\n",
      "Starting epoch 5 / 10\n",
      "t = 100, loss = 0.073683\n",
      "t = 200, loss = 0.033405\n",
      "t = 300, loss = 0.034239\n",
      "t = 400, loss = 0.060121\n",
      "t = 500, loss = 0.029745\n",
      "t = 600, loss = 0.031524\n",
      "t = 700, loss = 0.015062\n",
      "train acc: 0.966 val acc:0.815\n",
      "Starting epoch 6 / 10\n",
      "t = 100, loss = 0.033513\n",
      "t = 200, loss = 0.076985\n",
      "t = 300, loss = 0.049736\n",
      "t = 400, loss = 0.021129\n",
      "t = 500, loss = 0.010861\n",
      "t = 600, loss = 0.062479\n",
      "t = 700, loss = 0.022656\n",
      "train acc: 0.988 val acc:0.825\n",
      "Starting epoch 7 / 10\n",
      "t = 100, loss = 0.017938\n",
      "t = 200, loss = 0.056307\n",
      "t = 300, loss = 0.047239\n",
      "t = 400, loss = 0.015210\n",
      "t = 500, loss = 0.012285\n",
      "t = 600, loss = 0.002307\n",
      "t = 700, loss = 0.016594\n",
      "train acc: 0.984 val acc:0.824\n",
      "Starting epoch 8 / 10\n",
      "t = 100, loss = 0.040604\n",
      "t = 200, loss = 0.003140\n",
      "t = 300, loss = 0.004329\n",
      "t = 400, loss = 0.011547\n",
      "t = 500, loss = 0.019788\n",
      "t = 600, loss = 0.034735\n",
      "t = 700, loss = 0.033496\n",
      "train acc: 0.985 val acc:0.828\n",
      "Starting epoch 9 / 10\n",
      "t = 100, loss = 0.004175\n",
      "t = 200, loss = 0.004806\n",
      "t = 300, loss = 0.032916\n",
      "t = 400, loss = 0.026560\n",
      "t = 500, loss = 0.028409\n",
      "t = 600, loss = 0.011643\n",
      "t = 700, loss = 0.035054\n",
      "train acc: 0.987 val acc:0.827\n",
      "Starting epoch 10 / 10\n",
      "t = 100, loss = 0.021290\n",
      "t = 200, loss = 0.006670\n",
      "t = 300, loss = 0.027800\n",
      "t = 400, loss = 0.079812\n",
      "t = 500, loss = 0.001579\n",
      "t = 600, loss = 0.040583\n",
      "t = 700, loss = 0.002337\n",
      "train acc: 0.985 val acc:0.817\n",
      "Regularization = 2e-08.\n",
      "Best validation accuracy is 0.828. Training time for 10 epochs: 134.70 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f012aa43a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "reg_list = [5e-10, 1e-09,2.8e-09, 1e-08, 2e-8]\n",
    "\n",
    "for reg in reg_list:\n",
    "    \n",
    "    best_val_acc=0.0\n",
    "    model = generator().type(gpu_dtype)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00028, weight_decay=reg)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    best_val_acc, training_history = train_detailed(model, loss_fn, optimizer, reg, num_epochs=epochs, verbose=True)\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    print('Regularization = {}.'.format(reg))    \n",
    "    print('Best validation accuracy is {0}. Training time for {1} epochs: {2:.2f} sec'.format(best_val_acc, \n",
    "                                                                                              epochs, end-start))\n",
    "    history = np.array(training_history)\n",
    "\n",
    "    # Plot out the accuracies\n",
    "    plt.title('CNN Train and Validation Accuracies')\n",
    "    plt.axis((0,len(history),0,1.0))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot(history[:,0], '-ro', label=\"train acc\")\n",
    "    plt.plot(history[:,1], '-bo', label=\"val acc\")\n",
    "    plt.legend(loc='best', ncol=4)\n",
    " \n",
    "    plt.gcf().set_size_inches(15, 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f012047cb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = np.array(training_history)\n",
    "\n",
    "# Plot out the accuracies\n",
    "plt.title('CNN Train and Validation Accuracies')\n",
    "plt.axis((0,len(history),0,1.0))\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(history[:,0], '-ro', label=\"train acc\")\n",
    "plt.plot(history[:,1], '-bo', label=\"val acc\")\n",
    "plt.legend(loc='best', ncol=4)\n",
    " \n",
    "plt.gcf().set_size_inches(15, 5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Model 5-Conv Layers, 2 MaxPool Blocks (WIDER)\n",
    "\n",
    "Sequential(  \n",
    "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (1): ReLU(inplace)  \n",
    "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (4): ReLU(inplace)  \n",
    "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (6): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (7): ReLU(inplace)  \n",
    "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))  \n",
    "  (10): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (11): ReLU(inplace)  \n",
    "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (13): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))  \n",
    "  (14): ReLU(inplace)  \n",
    "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)  \n",
    "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))  \n",
    "  (17): Flatten()  \n",
    "  (18): Linear(in_features=16384, out_features=1024)  \n",
    "  (19): ReLU(inplace)  \n",
    "  (20): Linear(in_features=1024, out_features=10)  \n",
    ")  \n",
    "\n",
    "* Training time for 100 epochs: 1297.74 sec\n",
    "* The best validation accuracy is 0.834.\n",
    "* Learning rate annealed to 3.78238480948438e-05\n",
    "\n",
    "We finetune regularization from 5e-10 to 2e-8, and train for 10 epochs to arrive at following test accuracies:\n",
    "\n",
    "** Model model_reg=5e-10bestacc.pt has test accuracy of 0.8073 **  \n",
    "Model model_reg=1e-09bestacc.pt has test accuracy of 0.7992  \n",
    "** Model model_reg=2.8e-09bestacc.pt has test accuracy of 0.8088 **  \n",
    "Model model_reg=1e-08bestacc.pt has test accuracy of 0.8001  \n",
    "** Model model_reg=2e-08bestacc.pt has test accuracy of 0.8075 ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000252\n"
     ]
    }
   ],
   "source": [
    "print (optimizer.param_groups[0][\"lr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model_reg=5e-10bestacc.pt has test accuracy of 0.8073\n",
      "Model model_reg=1e-09bestacc.pt has test accuracy of 0.7992\n",
      "Model model_reg=2.8e-09bestacc.pt has test accuracy of 0.8088\n",
      "Model model_reg=1e-08bestacc.pt has test accuracy of 0.8001\n",
      "Model model_reg=2e-08bestacc.pt has test accuracy of 0.8075\n"
     ]
    }
   ],
   "source": [
    "files = ['model_reg=5e-10bestacc.pt',\n",
    "         'model_reg=1e-09bestacc.pt',\n",
    "         'model_reg=2.8e-09bestacc.pt',\n",
    "         'model_reg=1e-08bestacc.pt',\n",
    "         'model_reg=2e-08bestacc.pt']\n",
    "\n",
    "for file_name in files:\n",
    "    best_model = generator().type(gpu_dtype)\n",
    "    best_model.load_state_dict(torch.load(file_name))\n",
    "\n",
    "    acc = check_accuracy(best_model, loader_test)\n",
    "    print (\"Model {} has test accuracy of {}\".format(file_name, acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d (3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU(inplace)\n",
      "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (6): Conv2d (64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(inplace)\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (10): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (13): Conv2d (128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (14): ReLU(inplace)\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (17): Flatten(\n",
      "  )\n",
      "  (18): Linear(in_features=16384, out_features=1024)\n",
      "  (19): ReLU(inplace)\n",
      "  (20): Linear(in_features=1024, out_features=10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Training Sessions\n",
    "\n",
    "We will conduct a 100 epoch training on the 3 hyperparameter configurations\n",
    "* lr = 0.00028, reg = 5e-10\n",
    "* lr = 0.00028, reg = 2.8e-9\n",
    "* lr = 0.00028, reg = 2e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 100\n",
      "t = 100, loss = 1.221746\n",
      "t = 200, loss = 1.232969\n",
      "t = 300, loss = 1.156492\n",
      "t = 400, loss = 0.687013\n",
      "t = 500, loss = 0.766338\n",
      "t = 600, loss = 0.907028\n",
      "t = 700, loss = 0.920032\n",
      "train acc: 0.737 val acc:0.721\n",
      "Starting epoch 2 / 100\n",
      "t = 100, loss = 0.559160\n",
      "t = 200, loss = 0.595174\n",
      "t = 300, loss = 0.611812\n",
      "t = 400, loss = 0.544299\n",
      "t = 500, loss = 0.502519\n",
      "t = 600, loss = 0.545971\n",
      "t = 700, loss = 0.498729\n",
      "train acc: 0.837 val acc:0.767\n",
      "Starting epoch 3 / 100\n",
      "t = 100, loss = 0.278900\n",
      "t = 200, loss = 0.267661\n",
      "t = 300, loss = 0.259971\n",
      "t = 400, loss = 0.303049\n",
      "t = 500, loss = 0.142560\n",
      "t = 600, loss = 0.213759\n",
      "t = 700, loss = 0.163022\n",
      "train acc: 0.936 val acc:0.809\n",
      "Starting epoch 4 / 100\n",
      "t = 100, loss = 0.136784\n",
      "t = 200, loss = 0.060272\n",
      "t = 300, loss = 0.104338\n",
      "t = 400, loss = 0.038985\n",
      "t = 500, loss = 0.094907\n",
      "t = 600, loss = 0.043067\n",
      "t = 700, loss = 0.134379\n",
      "train acc: 0.948 val acc:0.793\n",
      "Starting epoch 5 / 100\n",
      "t = 100, loss = 0.089937\n",
      "t = 200, loss = 0.052112\n",
      "t = 300, loss = 0.031034\n",
      "t = 400, loss = 0.092148\n",
      "t = 500, loss = 0.088115\n",
      "t = 600, loss = 0.025736\n",
      "t = 700, loss = 0.050367\n",
      "train acc: 0.977 val acc:0.808\n",
      "Starting epoch 6 / 100\n",
      "t = 100, loss = 0.024398\n",
      "t = 200, loss = 0.011697\n",
      "t = 300, loss = 0.073337\n",
      "t = 400, loss = 0.046033\n",
      "t = 500, loss = 0.006916\n",
      "t = 600, loss = 0.043640\n",
      "t = 700, loss = 0.038987\n",
      "train acc: 0.988 val acc:0.817\n",
      "Starting epoch 7 / 100\n",
      "t = 100, loss = 0.016188\n",
      "t = 200, loss = 0.043106\n",
      "t = 300, loss = 0.015996\n",
      "t = 400, loss = 0.059195\n",
      "t = 500, loss = 0.006738\n",
      "t = 600, loss = 0.008602\n",
      "t = 700, loss = 0.004442\n",
      "train acc: 0.993 val acc:0.822\n",
      "Starting epoch 8 / 100\n",
      "t = 100, loss = 0.057378\n",
      "t = 200, loss = 0.003742\n",
      "t = 300, loss = 0.019875\n",
      "t = 400, loss = 0.007995\n",
      "t = 500, loss = 0.025858\n",
      "t = 600, loss = 0.071219\n",
      "t = 700, loss = 0.050521\n",
      "train acc: 0.994 val acc:0.806\n",
      "Starting epoch 9 / 100\n",
      "t = 100, loss = 0.026747\n",
      "t = 200, loss = 0.007682\n",
      "t = 300, loss = 0.003970\n",
      "t = 400, loss = 0.060436\n",
      "t = 500, loss = 0.009013\n",
      "t = 600, loss = 0.164405\n",
      "t = 700, loss = 0.009283\n",
      "train acc: 0.991 val acc:0.813\n",
      "Starting epoch 10 / 100\n",
      "t = 100, loss = 0.013099\n",
      "t = 200, loss = 0.002979\n",
      "t = 300, loss = 0.023797\n",
      "t = 400, loss = 0.024024\n",
      "t = 500, loss = 0.001478\n",
      "t = 600, loss = 0.005844\n",
      "t = 700, loss = 0.001734\n",
      "train acc: 0.997 val acc:0.809\n",
      "Starting epoch 11 / 100\n",
      "t = 100, loss = 0.073703\n",
      "t = 200, loss = 0.098501\n",
      "t = 300, loss = 0.012502\n",
      "t = 400, loss = 0.003890\n",
      "t = 500, loss = 0.018679\n",
      "t = 600, loss = 0.001181\n",
      "t = 700, loss = 0.010261\n",
      "train acc: 0.99 val acc:0.812\n",
      "Starting epoch 12 / 100\n",
      "t = 100, loss = 0.000871\n",
      "t = 200, loss = 0.007750\n",
      "t = 300, loss = 0.008741\n",
      "t = 400, loss = 0.006179\n",
      "t = 500, loss = 0.012348\n",
      "t = 600, loss = 0.001958\n",
      "t = 700, loss = 0.002121\n",
      "train acc: 0.999 val acc:0.827\n",
      "Starting epoch 13 / 100\n",
      "t = 100, loss = 0.003884\n",
      "t = 200, loss = 0.005654\n",
      "t = 300, loss = 0.015705\n",
      "t = 400, loss = 0.003988\n",
      "t = 500, loss = 0.001861\n",
      "t = 600, loss = 0.003105\n",
      "t = 700, loss = 0.010113\n",
      "train acc: 0.988 val acc:0.808\n",
      "Starting epoch 14 / 100\n",
      "t = 100, loss = 0.013291\n",
      "t = 200, loss = 0.017793\n",
      "t = 300, loss = 0.053406\n",
      "t = 400, loss = 0.001894\n",
      "t = 500, loss = 0.006083\n",
      "t = 600, loss = 0.025608\n",
      "t = 700, loss = 0.001475\n",
      "train acc: 0.992 val acc:0.813\n",
      "Starting epoch 15 / 100\n",
      "t = 100, loss = 0.006103\n",
      "t = 200, loss = 0.000092\n",
      "t = 300, loss = 0.001208\n",
      "t = 400, loss = 0.028018\n",
      "t = 500, loss = 0.004433\n",
      "t = 600, loss = 0.006067\n",
      "t = 700, loss = 0.000628\n",
      "train acc: 0.996 val acc:0.799\n",
      "Starting epoch 16 / 100\n",
      "t = 100, loss = 0.010560\n",
      "t = 200, loss = 0.004342\n",
      "t = 300, loss = 0.001380\n",
      "t = 400, loss = 0.019335\n",
      "t = 500, loss = 0.003566\n",
      "t = 600, loss = 0.005414\n",
      "t = 700, loss = 0.000913\n",
      "train acc: 0.997 val acc:0.816\n",
      "Starting epoch 17 / 100\n",
      "t = 100, loss = 0.000674\n",
      "t = 200, loss = 0.000337\n",
      "t = 300, loss = 0.007947\n",
      "t = 400, loss = 0.001369\n",
      "t = 500, loss = 0.001578\n",
      "t = 600, loss = 0.000494\n",
      "t = 700, loss = 0.000283\n",
      "train acc: 0.999 val acc:0.819\n",
      "Starting epoch 18 / 100\n",
      "t = 100, loss = 0.029549\n",
      "t = 200, loss = 0.000243\n",
      "t = 300, loss = 0.000813\n",
      "t = 400, loss = 0.000614\n",
      "t = 500, loss = 0.004852\n",
      "t = 600, loss = 0.008512\n",
      "t = 700, loss = 0.004002\n",
      "train acc: 0.997 val acc:0.82\n",
      "Starting epoch 19 / 100\n",
      "t = 100, loss = 0.000427\n",
      "t = 200, loss = 0.001119\n",
      "t = 300, loss = 0.003370\n",
      "t = 400, loss = 0.000582\n",
      "t = 500, loss = 0.000626\n",
      "t = 600, loss = 0.000808\n",
      "t = 700, loss = 0.009534\n",
      "train acc: 0.992 val acc:0.822\n",
      "Starting epoch 20 / 100\n",
      "t = 100, loss = 0.000384\n",
      "t = 200, loss = 0.030847\n",
      "t = 300, loss = 0.037217\n",
      "t = 400, loss = 0.003471\n",
      "t = 500, loss = 0.008647\n",
      "t = 600, loss = 0.003603\n",
      "t = 700, loss = 0.015117\n",
      "train acc: 0.998 val acc:0.813\n",
      "Starting epoch 21 / 100\n",
      "t = 100, loss = 0.000237\n",
      "t = 200, loss = 0.001048\n",
      "t = 300, loss = 0.004313\n",
      "t = 400, loss = 0.001084\n",
      "t = 500, loss = 0.000273\n",
      "t = 600, loss = 0.002358\n",
      "t = 700, loss = 0.007886\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 22 / 100\n",
      "t = 100, loss = 0.000018\n",
      "t = 200, loss = 0.000556\n",
      "t = 300, loss = 0.000582\n",
      "t = 400, loss = 0.000097\n",
      "t = 500, loss = 0.000055\n",
      "t = 600, loss = 0.002871\n",
      "t = 700, loss = 0.000029\n",
      "train acc: 0.999 val acc:0.824\n",
      "Starting epoch 23 / 100\n",
      "t = 100, loss = 0.016502\n",
      "t = 200, loss = 0.000156\n",
      "t = 300, loss = 0.000998\n",
      "t = 400, loss = 0.000115\n",
      "t = 500, loss = 0.000197\n",
      "t = 600, loss = 0.000742\n",
      "t = 700, loss = 0.000080\n",
      "train acc: 1.0 val acc:0.839\n",
      "Starting epoch 24 / 100\n",
      "t = 100, loss = 0.000040\n",
      "t = 200, loss = 0.000115\n",
      "t = 300, loss = 0.004834\n",
      "t = 400, loss = 0.000055\n",
      "t = 500, loss = 0.000042\n",
      "t = 600, loss = 0.000065\n",
      "t = 700, loss = 0.000093\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 25 / 100\n",
      "t = 100, loss = 0.000142\n",
      "t = 200, loss = 0.000943\n",
      "t = 300, loss = 0.009156\n",
      "t = 400, loss = 0.007357\n",
      "t = 500, loss = 0.003287\n",
      "t = 600, loss = 0.034505\n",
      "t = 700, loss = 0.000309\n",
      "train acc: 0.992 val acc:0.843\n",
      "Starting epoch 26 / 100\n",
      "t = 100, loss = 0.003224\n",
      "t = 200, loss = 0.008823\n",
      "t = 300, loss = 0.005649\n",
      "t = 400, loss = 0.000064\n",
      "t = 500, loss = 0.000055\n",
      "t = 600, loss = 0.001416\n",
      "t = 700, loss = 0.000531\n",
      "train acc: 1.0 val acc:0.837\n",
      "Starting epoch 27 / 100\n",
      "t = 100, loss = 0.000016\n",
      "t = 200, loss = 0.004131\n",
      "t = 300, loss = 0.033576\n",
      "t = 400, loss = 0.000198\n",
      "t = 500, loss = 0.000009\n",
      "t = 600, loss = 0.000053\n",
      "t = 700, loss = 0.000567\n",
      "train acc: 1.0 val acc:0.842\n",
      "Starting epoch 28 / 100\n",
      "t = 100, loss = 0.000013\n",
      "t = 200, loss = 0.000211\n",
      "t = 300, loss = 0.000039\n",
      "t = 400, loss = 0.000038\n",
      "t = 500, loss = 0.000005\n",
      "t = 600, loss = 0.000032\n",
      "t = 700, loss = 0.000048\n",
      "train acc: 1.0 val acc:0.842\n",
      "Starting epoch 29 / 100\n",
      "t = 100, loss = 0.000015\n",
      "t = 200, loss = 0.000076\n",
      "t = 300, loss = 0.000024\n",
      "t = 400, loss = 0.000031\n",
      "t = 500, loss = 0.000004\n",
      "t = 600, loss = 0.000022\n",
      "t = 700, loss = 0.000036\n",
      "train acc: 1.0 val acc:0.841\n",
      "Starting epoch 30 / 100\n",
      "t = 100, loss = 0.000010\n",
      "t = 200, loss = 0.000052\n",
      "t = 300, loss = 0.000016\n",
      "t = 400, loss = 0.000025\n",
      "t = 500, loss = 0.000004\n",
      "t = 600, loss = 0.000015\n",
      "t = 700, loss = 0.000027\n",
      "train acc: 1.0 val acc:0.843\n",
      "Starting epoch 31 / 100\n",
      "t = 100, loss = 0.000008\n",
      "t = 200, loss = 0.000037\n",
      "t = 300, loss = 0.000011\n",
      "t = 400, loss = 0.000019\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000011\n",
      "t = 700, loss = 0.000020\n",
      "train acc: 1.0 val acc:0.844\n",
      "Starting epoch 32 / 100\n",
      "t = 100, loss = 0.000006\n",
      "t = 200, loss = 0.000027\n",
      "t = 300, loss = 0.000008\n",
      "t = 400, loss = 0.000015\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000008\n",
      "t = 700, loss = 0.000015\n",
      "train acc: 1.0 val acc:0.848\n",
      "Starting epoch 33 / 100\n",
      "t = 100, loss = 0.000004\n",
      "t = 200, loss = 0.000020\n",
      "t = 300, loss = 0.000005\n",
      "t = 400, loss = 0.000011\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000006\n",
      "t = 700, loss = 0.000011\n",
      "train acc: 1.0 val acc:0.848\n",
      "Starting epoch 34 / 100\n",
      "t = 100, loss = 0.000004\n",
      "t = 200, loss = 0.000014\n",
      "t = 300, loss = 0.000004\n",
      "t = 400, loss = 0.000008\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000005\n",
      "t = 700, loss = 0.000009\n",
      "train acc: 1.0 val acc:0.85\n",
      "Starting epoch 35 / 100\n",
      "t = 100, loss = 0.000003\n",
      "t = 200, loss = 0.000011\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000006\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000006\n",
      "train acc: 1.0 val acc:0.848\n",
      "Starting epoch 36 / 100\n",
      "t = 100, loss = 0.000003\n",
      "t = 200, loss = 0.000008\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000005\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 1.0 val acc:0.849\n",
      "Starting epoch 37 / 100\n",
      "t = 100, loss = 0.000004\n",
      "t = 200, loss = 0.000007\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000004\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000004\n",
      "train acc: 1.0 val acc:0.848\n",
      "Starting epoch 38 / 100\n",
      "t = 100, loss = 0.000003\n",
      "t = 200, loss = 0.000006\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000003\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.845\n",
      "Starting epoch 39 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000004\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.845\n",
      "Starting epoch 40 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000003\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.845\n",
      "Starting epoch 41 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.85\n",
      "Starting epoch 42 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.846\n",
      "Starting epoch 43 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.844\n",
      "Starting epoch 44 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.838\n",
      "Starting epoch 45 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.837\n",
      "Starting epoch 46 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000006\n",
      "t = 600, loss = 0.021451\n",
      "t = 700, loss = 0.001836\n",
      "train acc: 0.991 val acc:0.817\n",
      "Starting epoch 47 / 100\n",
      "t = 100, loss = 0.006409\n",
      "t = 200, loss = 0.001015\n",
      "t = 300, loss = 0.000189\n",
      "t = 400, loss = 0.003196\n",
      "t = 500, loss = 0.002297\n",
      "t = 600, loss = 0.001612\n",
      "t = 700, loss = 0.000163\n",
      "train acc: 1.0 val acc:0.847\n",
      "Starting epoch 48 / 100\n",
      "t = 100, loss = 0.000015\n",
      "t = 200, loss = 0.000265\n",
      "t = 300, loss = 0.000006\n",
      "t = 400, loss = 0.000008\n",
      "t = 500, loss = 0.000120\n",
      "t = 600, loss = 0.000141\n",
      "t = 700, loss = 0.000202\n",
      "train acc: 1.0 val acc:0.85\n",
      "Starting epoch 49 / 100\n",
      "t = 100, loss = 0.000076\n",
      "t = 200, loss = 0.000020\n",
      "t = 300, loss = 0.000007\n",
      "t = 400, loss = 0.000007\n",
      "t = 500, loss = 0.000043\n",
      "t = 600, loss = 0.000005\n",
      "t = 700, loss = 0.000054\n",
      "train acc: 1.0 val acc:0.847\n",
      "Starting epoch 50 / 100\n",
      "t = 100, loss = 0.000031\n",
      "t = 200, loss = 0.000017\n",
      "t = 300, loss = 0.000005\n",
      "t = 400, loss = 0.000006\n",
      "t = 500, loss = 0.000024\n",
      "t = 600, loss = 0.000004\n",
      "t = 700, loss = 0.000038\n",
      "train acc: 1.0 val acc:0.845\n",
      "Starting epoch 51 / 100\n",
      "t = 100, loss = 0.000019\n",
      "t = 200, loss = 0.000014\n",
      "t = 300, loss = 0.000004\n",
      "t = 400, loss = 0.000005\n",
      "t = 500, loss = 0.000015\n",
      "t = 600, loss = 0.000004\n",
      "t = 700, loss = 0.000028\n",
      "train acc: 1.0 val acc:0.846\n",
      "Starting epoch 52 / 100\n",
      "t = 100, loss = 0.000013\n",
      "t = 200, loss = 0.000011\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000004\n",
      "t = 500, loss = 0.000010\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000020\n",
      "train acc: 1.0 val acc:0.846\n",
      "Starting epoch 53 / 100\n",
      "t = 100, loss = 0.000009\n",
      "t = 200, loss = 0.000009\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000004\n",
      "t = 500, loss = 0.000006\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000015\n",
      "train acc: 1.0 val acc:0.846\n",
      "Starting epoch 54 / 100\n",
      "t = 100, loss = 0.000006\n",
      "t = 200, loss = 0.000007\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000003\n",
      "t = 500, loss = 0.000004\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000011\n",
      "train acc: 1.0 val acc:0.847\n",
      "Starting epoch 55 / 100\n",
      "t = 100, loss = 0.000004\n",
      "t = 200, loss = 0.000005\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000007\n",
      "train acc: 1.0 val acc:0.848\n",
      "Starting epoch 56 / 100\n",
      "t = 100, loss = 0.000003\n",
      "t = 200, loss = 0.000004\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.846\n",
      "Starting epoch 57 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000003\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000004\n",
      "train acc: 1.0 val acc:0.847\n",
      "Starting epoch 58 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.847\n",
      "Starting epoch 59 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.847\n",
      "Starting epoch 60 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.848\n",
      "Starting epoch 61 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.85\n",
      "Starting epoch 62 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.851\n",
      "Starting epoch 63 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.848\n",
      "Starting epoch 64 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.847\n",
      "Starting epoch 65 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.846\n",
      "Starting epoch 66 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.844\n",
      "Starting epoch 67 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.845\n",
      "Starting epoch 68 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.839\n",
      "Starting epoch 69 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.837\n",
      "Starting epoch 70 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.838\n",
      "Starting epoch 71 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.838\n",
      "Starting epoch 72 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000261\n",
      "t = 700, loss = 0.002399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.999 val acc:0.824\n",
      "Starting epoch 73 / 100\n",
      "t = 100, loss = 0.000220\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000359\n",
      "t = 400, loss = 0.000006\n",
      "t = 500, loss = 0.000056\n",
      "t = 600, loss = 0.000006\n",
      "t = 700, loss = 0.000008\n",
      "train acc: 1.0 val acc:0.833\n",
      "Starting epoch 74 / 100\n",
      "t = 100, loss = 0.000110\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000075\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000021\n",
      "t = 600, loss = 0.000011\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 75 / 100\n",
      "t = 100, loss = 0.000013\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000013\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000014\n",
      "t = 600, loss = 0.000009\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.834\n",
      "Starting epoch 76 / 100\n",
      "t = 100, loss = 0.000011\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000007\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000011\n",
      "t = 600, loss = 0.000007\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.834\n",
      "Starting epoch 77 / 100\n",
      "t = 100, loss = 0.000009\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000005\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000009\n",
      "t = 600, loss = 0.000006\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.834\n",
      "Starting epoch 78 / 100\n",
      "t = 100, loss = 0.000006\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000004\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000006\n",
      "t = 600, loss = 0.000004\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.836\n",
      "Starting epoch 79 / 100\n",
      "t = 100, loss = 0.000005\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000005\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.836\n",
      "Starting epoch 80 / 100\n",
      "t = 100, loss = 0.000004\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.837\n",
      "Starting epoch 81 / 100\n",
      "t = 100, loss = 0.000003\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.837\n",
      "Starting epoch 82 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.837\n",
      "Starting epoch 83 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.838\n",
      "Starting epoch 84 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.836\n",
      "Starting epoch 85 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.838\n",
      "Starting epoch 86 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.839\n",
      "Starting epoch 87 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.839\n",
      "Starting epoch 88 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.841\n",
      "Starting epoch 89 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.842\n",
      "Starting epoch 90 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.842\n",
      "Starting epoch 91 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.84\n",
      "Starting epoch 92 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.843\n",
      "Starting epoch 93 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.838\n",
      "Starting epoch 94 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 95 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.834\n",
      "Starting epoch 96 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 97 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 98 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.836\n",
      "Starting epoch 99 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.823\n",
      "Starting epoch 100 / 100\n",
      "t = 100, loss = 0.000013\n",
      "t = 200, loss = 0.000005\n",
      "t = 300, loss = 0.000119\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000005\n",
      "t = 600, loss = 0.000007\n",
      "t = 700, loss = 0.000004\n",
      "train acc: 1.0 val acc:0.835\n",
      "Regularization = 5e-10.\n",
      "Best validation accuracy is 0.851. Training time for 100 epochs: 1322.42 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f012aa437b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 100\n",
      "t = 100, loss = 1.394800\n",
      "t = 200, loss = 1.321122\n",
      "t = 300, loss = 1.057709\n",
      "t = 400, loss = 0.744611\n",
      "t = 500, loss = 0.764446\n",
      "t = 600, loss = 0.802720\n",
      "t = 700, loss = 0.813232\n",
      "train acc: 0.758 val acc:0.747\n",
      "Starting epoch 2 / 100\n",
      "t = 100, loss = 0.470598\n",
      "t = 200, loss = 0.610582\n",
      "t = 300, loss = 0.622051\n",
      "t = 400, loss = 0.581646\n",
      "t = 500, loss = 0.532627\n",
      "t = 600, loss = 0.452293\n",
      "t = 700, loss = 0.379008\n",
      "train acc: 0.86 val acc:0.782\n",
      "Starting epoch 3 / 100\n",
      "t = 100, loss = 0.265759\n",
      "t = 200, loss = 0.245966\n",
      "t = 300, loss = 0.279608\n",
      "t = 400, loss = 0.198800\n",
      "t = 500, loss = 0.272004\n",
      "t = 600, loss = 0.134135\n",
      "t = 700, loss = 0.220469\n",
      "train acc: 0.916 val acc:0.808\n",
      "Starting epoch 4 / 100\n",
      "t = 100, loss = 0.121478\n",
      "t = 200, loss = 0.074243\n",
      "t = 300, loss = 0.048356\n",
      "t = 400, loss = 0.097674\n",
      "t = 500, loss = 0.041731\n",
      "t = 600, loss = 0.025852\n",
      "t = 700, loss = 0.085082\n",
      "train acc: 0.949 val acc:0.804\n",
      "Starting epoch 5 / 100\n",
      "t = 100, loss = 0.026948\n",
      "t = 200, loss = 0.032965\n",
      "t = 300, loss = 0.066560\n",
      "t = 400, loss = 0.035372\n",
      "t = 500, loss = 0.071461\n",
      "t = 600, loss = 0.048975\n",
      "t = 700, loss = 0.039095\n",
      "train acc: 0.97 val acc:0.819\n",
      "Starting epoch 6 / 100\n",
      "t = 100, loss = 0.076677\n",
      "t = 200, loss = 0.040172\n",
      "t = 300, loss = 0.018157\n",
      "t = 400, loss = 0.057755\n",
      "t = 500, loss = 0.043193\n",
      "t = 600, loss = 0.053515\n",
      "t = 700, loss = 0.019978\n",
      "train acc: 0.995 val acc:0.837\n",
      "Starting epoch 7 / 100\n",
      "t = 100, loss = 0.013262\n",
      "t = 200, loss = 0.013520\n",
      "t = 300, loss = 0.008949\n",
      "t = 400, loss = 0.005896\n",
      "t = 500, loss = 0.010450\n",
      "t = 600, loss = 0.002044\n",
      "t = 700, loss = 0.037953\n",
      "train acc: 0.987 val acc:0.809\n",
      "Starting epoch 8 / 100\n",
      "t = 100, loss = 0.011234\n",
      "t = 200, loss = 0.008332\n",
      "t = 300, loss = 0.023843\n",
      "t = 400, loss = 0.010148\n",
      "t = 500, loss = 0.020313\n",
      "t = 600, loss = 0.013384\n",
      "t = 700, loss = 0.033559\n",
      "train acc: 0.992 val acc:0.823\n",
      "Starting epoch 9 / 100\n",
      "t = 100, loss = 0.025056\n",
      "t = 200, loss = 0.028034\n",
      "t = 300, loss = 0.083647\n",
      "t = 400, loss = 0.007940\n",
      "t = 500, loss = 0.011653\n",
      "t = 600, loss = 0.004185\n",
      "t = 700, loss = 0.003137\n",
      "train acc: 0.992 val acc:0.818\n",
      "Starting epoch 10 / 100\n",
      "t = 100, loss = 0.011003\n",
      "t = 200, loss = 0.010073\n",
      "t = 300, loss = 0.025535\n",
      "t = 400, loss = 0.016327\n",
      "t = 500, loss = 0.048571\n",
      "t = 600, loss = 0.057122\n",
      "t = 700, loss = 0.002917\n",
      "train acc: 0.992 val acc:0.799\n",
      "Starting epoch 11 / 100\n",
      "t = 100, loss = 0.007045\n",
      "t = 200, loss = 0.036360\n",
      "t = 300, loss = 0.046343\n",
      "t = 400, loss = 0.003388\n",
      "t = 500, loss = 0.001028\n",
      "t = 600, loss = 0.001962\n",
      "t = 700, loss = 0.033353\n",
      "train acc: 0.994 val acc:0.818\n",
      "Starting epoch 12 / 100\n",
      "t = 100, loss = 0.006785\n",
      "t = 200, loss = 0.004773\n",
      "t = 300, loss = 0.009154\n",
      "t = 400, loss = 0.002396\n",
      "t = 500, loss = 0.002442\n",
      "t = 600, loss = 0.010894\n",
      "t = 700, loss = 0.075091\n",
      "train acc: 0.996 val acc:0.816\n",
      "Starting epoch 13 / 100\n",
      "t = 100, loss = 0.027539\n",
      "t = 200, loss = 0.001608\n",
      "t = 300, loss = 0.003329\n",
      "t = 400, loss = 0.010332\n",
      "t = 500, loss = 0.020351\n",
      "t = 600, loss = 0.040090\n",
      "t = 700, loss = 0.001191\n",
      "train acc: 0.992 val acc:0.812\n",
      "Starting epoch 14 / 100\n",
      "t = 100, loss = 0.001717\n",
      "t = 200, loss = 0.000862\n",
      "t = 300, loss = 0.007758\n",
      "t = 400, loss = 0.002429\n",
      "t = 500, loss = 0.009394\n",
      "t = 600, loss = 0.007943\n",
      "t = 700, loss = 0.016545\n",
      "train acc: 0.993 val acc:0.81\n",
      "Starting epoch 15 / 100\n",
      "t = 100, loss = 0.000416\n",
      "t = 200, loss = 0.002861\n",
      "t = 300, loss = 0.027364\n",
      "t = 400, loss = 0.003594\n",
      "t = 500, loss = 0.000779\n",
      "t = 600, loss = 0.144100\n",
      "t = 700, loss = 0.004071\n",
      "train acc: 0.994 val acc:0.819\n",
      "Starting epoch 16 / 100\n",
      "t = 100, loss = 0.001341\n",
      "t = 200, loss = 0.000360\n",
      "t = 300, loss = 0.001286\n",
      "t = 400, loss = 0.038333\n",
      "t = 500, loss = 0.000926\n",
      "t = 600, loss = 0.001256\n",
      "t = 700, loss = 0.000590\n",
      "train acc: 1.0 val acc:0.841\n",
      "Starting epoch 17 / 100\n",
      "t = 100, loss = 0.000826\n",
      "t = 200, loss = 0.000242\n",
      "t = 300, loss = 0.000579\n",
      "t = 400, loss = 0.000275\n",
      "t = 500, loss = 0.000217\n",
      "t = 600, loss = 0.000216\n",
      "t = 700, loss = 0.000449\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 18 / 100\n",
      "t = 100, loss = 0.000570\n",
      "t = 200, loss = 0.030323\n",
      "t = 300, loss = 0.002164\n",
      "t = 400, loss = 0.007913\n",
      "t = 500, loss = 0.008954\n",
      "t = 600, loss = 0.013909\n",
      "t = 700, loss = 0.000751\n",
      "train acc: 0.992 val acc:0.799\n",
      "Starting epoch 19 / 100\n",
      "t = 100, loss = 0.014669\n",
      "t = 200, loss = 0.011389\n",
      "t = 300, loss = 0.006701\n",
      "t = 400, loss = 0.002345\n",
      "t = 500, loss = 0.000543\n",
      "t = 600, loss = 0.008839\n",
      "t = 700, loss = 0.002804\n",
      "train acc: 0.999 val acc:0.817\n",
      "Starting epoch 20 / 100\n",
      "t = 100, loss = 0.032620\n",
      "t = 200, loss = 0.000205\n",
      "t = 300, loss = 0.000421\n",
      "t = 400, loss = 0.001016\n",
      "t = 500, loss = 0.014935\n",
      "t = 600, loss = 0.000261\n",
      "t = 700, loss = 0.000675\n",
      "train acc: 0.999 val acc:0.828\n",
      "Starting epoch 21 / 100\n",
      "t = 100, loss = 0.000532\n",
      "t = 200, loss = 0.003878\n",
      "t = 300, loss = 0.000679\n",
      "t = 400, loss = 0.000559\n",
      "t = 500, loss = 0.000454\n",
      "t = 600, loss = 0.000152\n",
      "t = 700, loss = 0.001414\n",
      "train acc: 0.999 val acc:0.827\n",
      "Starting epoch 22 / 100\n",
      "t = 100, loss = 0.000659\n",
      "t = 200, loss = 0.000227\n",
      "t = 300, loss = 0.000128\n",
      "t = 400, loss = 0.000222\n",
      "t = 500, loss = 0.000021\n",
      "t = 600, loss = 0.000049\n",
      "t = 700, loss = 0.000133\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 23 / 100\n",
      "t = 100, loss = 0.000063\n",
      "t = 200, loss = 0.000054\n",
      "t = 300, loss = 0.000024\n",
      "t = 400, loss = 0.000015\n",
      "t = 500, loss = 0.000010\n",
      "t = 600, loss = 0.000371\n",
      "t = 700, loss = 0.000668\n",
      "train acc: 0.998 val acc:0.808\n",
      "Starting epoch 24 / 100\n",
      "t = 100, loss = 0.000501\n",
      "t = 200, loss = 0.042009\n",
      "t = 300, loss = 0.026572\n",
      "t = 400, loss = 0.008855\n",
      "t = 500, loss = 0.000163\n",
      "t = 600, loss = 0.005410\n",
      "t = 700, loss = 0.016883\n",
      "train acc: 0.996 val acc:0.813\n",
      "Starting epoch 25 / 100\n",
      "t = 100, loss = 0.043166\n",
      "t = 200, loss = 0.047631\n",
      "t = 300, loss = 0.003897\n",
      "t = 400, loss = 0.000936\n",
      "t = 500, loss = 0.000401\n",
      "t = 600, loss = 0.005066\n",
      "t = 700, loss = 0.000208\n",
      "train acc: 0.999 val acc:0.817\n",
      "Starting epoch 26 / 100\n",
      "t = 100, loss = 0.000415\n",
      "t = 200, loss = 0.000330\n",
      "t = 300, loss = 0.000125\n",
      "t = 400, loss = 0.000608\n",
      "t = 500, loss = 0.000308\n",
      "t = 600, loss = 0.000077\n",
      "t = 700, loss = 0.000070\n",
      "train acc: 1.0 val acc:0.824\n",
      "Starting epoch 27 / 100\n",
      "t = 100, loss = 0.000033\n",
      "t = 200, loss = 0.000203\n",
      "t = 300, loss = 0.000062\n",
      "t = 400, loss = 0.000071\n",
      "t = 500, loss = 0.000019\n",
      "t = 600, loss = 0.000018\n",
      "t = 700, loss = 0.000011\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 28 / 100\n",
      "t = 100, loss = 0.000021\n",
      "t = 200, loss = 0.000018\n",
      "t = 300, loss = 0.000021\n",
      "t = 400, loss = 0.000040\n",
      "t = 500, loss = 0.000010\n",
      "t = 600, loss = 0.000015\n",
      "t = 700, loss = 0.000009\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 29 / 100\n",
      "t = 100, loss = 0.000018\n",
      "t = 200, loss = 0.000014\n",
      "t = 300, loss = 0.000014\n",
      "t = 400, loss = 0.000025\n",
      "t = 500, loss = 0.000007\n",
      "t = 600, loss = 0.000013\n",
      "t = 700, loss = 0.000008\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 30 / 100\n",
      "t = 100, loss = 0.000015\n",
      "t = 200, loss = 0.000011\n",
      "t = 300, loss = 0.000009\n",
      "t = 400, loss = 0.000017\n",
      "t = 500, loss = 0.000006\n",
      "t = 600, loss = 0.000011\n",
      "t = 700, loss = 0.000007\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 31 / 100\n",
      "t = 100, loss = 0.000013\n",
      "t = 200, loss = 0.000009\n",
      "t = 300, loss = 0.000006\n",
      "t = 400, loss = 0.000012\n",
      "t = 500, loss = 0.000005\n",
      "t = 600, loss = 0.000009\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 32 / 100\n",
      "t = 100, loss = 0.000010\n",
      "t = 200, loss = 0.000007\n",
      "t = 300, loss = 0.000005\n",
      "t = 400, loss = 0.000009\n",
      "t = 500, loss = 0.000004\n",
      "t = 600, loss = 0.000008\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 33 / 100\n",
      "t = 100, loss = 0.000008\n",
      "t = 200, loss = 0.000006\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000007\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000006\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 34 / 100\n",
      "t = 100, loss = 0.000007\n",
      "t = 200, loss = 0.000005\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000006\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000006\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.825\n",
      "Starting epoch 35 / 100\n",
      "t = 100, loss = 0.000004\n",
      "t = 200, loss = 0.000004\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000004\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000004\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.825\n",
      "Starting epoch 36 / 100\n",
      "t = 100, loss = 0.000003\n",
      "t = 200, loss = 0.000003\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000003\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 1.0 val acc:0.824\n",
      "Starting epoch 37 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000003\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.831\n",
      "Starting epoch 38 / 100\n",
      "t = 100, loss = 0.000028\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 39 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 40 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 41 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 42 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 43 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.825\n",
      "Starting epoch 44 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 45 / 100\n",
      "t = 100, loss = 0.052378\n",
      "t = 200, loss = 0.103056\n",
      "t = 300, loss = 0.026758\n",
      "t = 400, loss = 0.000353\n",
      "t = 500, loss = 0.001479\n",
      "t = 600, loss = 0.000028\n",
      "t = 700, loss = 0.000287\n",
      "train acc: 0.996 val acc:0.814\n",
      "Starting epoch 46 / 100\n",
      "t = 100, loss = 0.001367\n",
      "t = 200, loss = 0.000013\n",
      "t = 300, loss = 0.000413\n",
      "t = 400, loss = 0.000269\n",
      "t = 500, loss = 0.001048\n",
      "t = 600, loss = 0.000018\n",
      "t = 700, loss = 0.000381\n",
      "train acc: 0.999 val acc:0.813\n",
      "Starting epoch 47 / 100\n",
      "t = 100, loss = 0.000005\n",
      "t = 200, loss = 0.000014\n",
      "t = 300, loss = 0.000033\n",
      "t = 400, loss = 0.000011\n",
      "t = 500, loss = 0.000020\n",
      "t = 600, loss = 0.000009\n",
      "t = 700, loss = 0.000023\n",
      "train acc: 1.0 val acc:0.816\n",
      "Starting epoch 48 / 100\n",
      "t = 100, loss = 0.000003\n",
      "t = 200, loss = 0.000006\n",
      "t = 300, loss = 0.000017\n",
      "t = 400, loss = 0.000013\n",
      "t = 500, loss = 0.000013\n",
      "t = 600, loss = 0.000008\n",
      "t = 700, loss = 0.000018\n",
      "train acc: 1.0 val acc:0.816\n",
      "Starting epoch 49 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000006\n",
      "t = 300, loss = 0.000012\n",
      "t = 400, loss = 0.000012\n",
      "t = 500, loss = 0.000010\n",
      "t = 600, loss = 0.000007\n",
      "t = 700, loss = 0.000015\n",
      "train acc: 1.0 val acc:0.818\n",
      "Starting epoch 50 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000005\n",
      "t = 300, loss = 0.000009\n",
      "t = 400, loss = 0.000010\n",
      "t = 500, loss = 0.000008\n",
      "t = 600, loss = 0.000006\n",
      "t = 700, loss = 0.000013\n",
      "train acc: 1.0 val acc:0.82\n",
      "Starting epoch 51 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000004\n",
      "t = 300, loss = 0.000007\n",
      "t = 400, loss = 0.000008\n",
      "t = 500, loss = 0.000006\n",
      "t = 600, loss = 0.000005\n",
      "t = 700, loss = 0.000011\n",
      "train acc: 1.0 val acc:0.82\n",
      "Starting epoch 52 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000003\n",
      "t = 300, loss = 0.000006\n",
      "t = 400, loss = 0.000007\n",
      "t = 500, loss = 0.000005\n",
      "t = 600, loss = 0.000004\n",
      "t = 700, loss = 0.000009\n",
      "train acc: 1.0 val acc:0.82\n",
      "Starting epoch 53 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000003\n",
      "t = 300, loss = 0.000004\n",
      "t = 400, loss = 0.000006\n",
      "t = 500, loss = 0.000004\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000007\n",
      "train acc: 1.0 val acc:0.821\n",
      "Starting epoch 54 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000004\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000006\n",
      "train acc: 1.0 val acc:0.823\n",
      "Starting epoch 55 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000003\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.824\n",
      "Starting epoch 56 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.825\n",
      "Starting epoch 57 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.824\n",
      "Starting epoch 58 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 59 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 60 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 61 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 62 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 63 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 64 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 65 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 66 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.002292\n",
      "t = 300, loss = 0.000142\n",
      "t = 400, loss = 0.009115\n",
      "t = 500, loss = 0.000200\n",
      "t = 600, loss = 0.000044\n",
      "t = 700, loss = 0.000757\n",
      "train acc: 0.997 val acc:0.821\n",
      "Starting epoch 67 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000099\n",
      "t = 300, loss = 0.000041\n",
      "t = 400, loss = 0.000076\n",
      "t = 500, loss = 0.000007\n",
      "t = 600, loss = 0.000044\n",
      "t = 700, loss = 0.000009\n",
      "train acc: 1.0 val acc:0.818\n",
      "Starting epoch 68 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000007\n",
      "t = 400, loss = 0.000029\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000028\n",
      "t = 700, loss = 0.000008\n",
      "train acc: 1.0 val acc:0.824\n",
      "Starting epoch 69 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000007\n",
      "t = 400, loss = 0.000019\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000020\n",
      "t = 700, loss = 0.000007\n",
      "train acc: 1.0 val acc:0.825\n",
      "Starting epoch 70 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000006\n",
      "t = 400, loss = 0.000014\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000015\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 71 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000005\n",
      "t = 400, loss = 0.000011\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000011\n",
      "t = 700, loss = 0.000004\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 72 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000005\n",
      "t = 400, loss = 0.000008\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000008\n",
      "t = 700, loss = 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 73 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000004\n",
      "t = 400, loss = 0.000006\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000006\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 74 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000005\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000004\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 75 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000004\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 76 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000003\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 77 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 78 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.83\n",
      "Starting epoch 79 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 80 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 81 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 82 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 83 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.825\n",
      "Starting epoch 84 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 85 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 86 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 87 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 88 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 89 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.83\n",
      "Starting epoch 90 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.832\n",
      "Starting epoch 91 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000102\n",
      "t = 500, loss = 0.062475\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000011\n",
      "train acc: 0.999 val acc:0.824\n",
      "Starting epoch 92 / 100\n",
      "t = 100, loss = 0.000064\n",
      "t = 200, loss = 0.000814\n",
      "t = 300, loss = 0.000008\n",
      "t = 400, loss = 0.000004\n",
      "t = 500, loss = 0.000022\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000012\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 93 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000007\n",
      "t = 400, loss = 0.000011\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 94 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000005\n",
      "t = 400, loss = 0.000010\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 95 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000004\n",
      "t = 400, loss = 0.000006\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 96 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000005\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.827\n",
      "Starting epoch 97 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000003\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 98 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 99 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.83\n",
      "Starting epoch 100 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.83\n",
      "Regularization = 2.8e-09.\n",
      "Best validation accuracy is 0.841. Training time for 100 epochs: 1318.58 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0120632b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 100\n",
      "t = 100, loss = 1.290993\n",
      "t = 200, loss = 1.221534\n",
      "t = 300, loss = 1.068935\n",
      "t = 400, loss = 0.773494\n",
      "t = 500, loss = 0.704042\n",
      "t = 600, loss = 0.783597\n",
      "t = 700, loss = 0.881417\n",
      "train acc: 0.736 val acc:0.742\n",
      "Starting epoch 2 / 100\n",
      "t = 100, loss = 0.457470\n",
      "t = 200, loss = 0.618027\n",
      "t = 300, loss = 0.552327\n",
      "t = 400, loss = 0.602205\n",
      "t = 500, loss = 0.433866\n",
      "t = 600, loss = 0.536849\n",
      "t = 700, loss = 0.476422\n",
      "train acc: 0.837 val acc:0.777\n",
      "Starting epoch 3 / 100\n",
      "t = 100, loss = 0.229124\n",
      "t = 200, loss = 0.335027\n",
      "t = 300, loss = 0.263380\n",
      "t = 400, loss = 0.191730\n",
      "t = 500, loss = 0.162350\n",
      "t = 600, loss = 0.156550\n",
      "t = 700, loss = 0.179353\n",
      "train acc: 0.92 val acc:0.803\n",
      "Starting epoch 4 / 100\n",
      "t = 100, loss = 0.113208\n",
      "t = 200, loss = 0.057148\n",
      "t = 300, loss = 0.118768\n",
      "t = 400, loss = 0.099951\n",
      "t = 500, loss = 0.066889\n",
      "t = 600, loss = 0.021885\n",
      "t = 700, loss = 0.099862\n",
      "train acc: 0.949 val acc:0.819\n",
      "Starting epoch 5 / 100\n",
      "t = 100, loss = 0.073192\n",
      "t = 200, loss = 0.052816\n",
      "t = 300, loss = 0.084264\n",
      "t = 400, loss = 0.037569\n",
      "t = 500, loss = 0.063455\n",
      "t = 600, loss = 0.058357\n",
      "t = 700, loss = 0.013284\n",
      "train acc: 0.983 val acc:0.822\n",
      "Starting epoch 6 / 100\n",
      "t = 100, loss = 0.066570\n",
      "t = 200, loss = 0.050208\n",
      "t = 300, loss = 0.073935\n",
      "t = 400, loss = 0.044845\n",
      "t = 500, loss = 0.009139\n",
      "t = 600, loss = 0.048467\n",
      "t = 700, loss = 0.092504\n",
      "train acc: 0.985 val acc:0.82\n",
      "Starting epoch 7 / 100\n",
      "t = 100, loss = 0.012703\n",
      "t = 200, loss = 0.014573\n",
      "t = 300, loss = 0.006226\n",
      "t = 400, loss = 0.015328\n",
      "t = 500, loss = 0.001379\n",
      "t = 600, loss = 0.023558\n",
      "t = 700, loss = 0.009017\n",
      "train acc: 0.988 val acc:0.823\n",
      "Starting epoch 8 / 100\n",
      "t = 100, loss = 0.003484\n",
      "t = 200, loss = 0.037810\n",
      "t = 300, loss = 0.021824\n",
      "t = 400, loss = 0.001723\n",
      "t = 500, loss = 0.002194\n",
      "t = 600, loss = 0.028266\n",
      "t = 700, loss = 0.088070\n",
      "train acc: 0.984 val acc:0.818\n",
      "Starting epoch 9 / 100\n",
      "t = 100, loss = 0.167571\n",
      "t = 200, loss = 0.015166\n",
      "t = 300, loss = 0.004910\n",
      "t = 400, loss = 0.003897\n",
      "t = 500, loss = 0.004324\n",
      "t = 600, loss = 0.021842\n",
      "t = 700, loss = 0.008995\n",
      "train acc: 0.978 val acc:0.803\n",
      "Starting epoch 10 / 100\n",
      "t = 100, loss = 0.030682\n",
      "t = 200, loss = 0.026732\n",
      "t = 300, loss = 0.007721\n",
      "t = 400, loss = 0.006665\n",
      "t = 500, loss = 0.067885\n",
      "t = 600, loss = 0.005688\n",
      "t = 700, loss = 0.011992\n",
      "train acc: 0.997 val acc:0.837\n",
      "Starting epoch 11 / 100\n",
      "t = 100, loss = 0.002247\n",
      "t = 200, loss = 0.004022\n",
      "t = 300, loss = 0.072065\n",
      "t = 400, loss = 0.001472\n",
      "t = 500, loss = 0.038255\n",
      "t = 600, loss = 0.003310\n",
      "t = 700, loss = 0.034066\n",
      "train acc: 0.998 val acc:0.833\n",
      "Starting epoch 12 / 100\n",
      "t = 100, loss = 0.000135\n",
      "t = 200, loss = 0.000231\n",
      "t = 300, loss = 0.033532\n",
      "t = 400, loss = 0.002425\n",
      "t = 500, loss = 0.000444\n",
      "t = 600, loss = 0.000509\n",
      "t = 700, loss = 0.000206\n",
      "train acc: 0.994 val acc:0.825\n",
      "Starting epoch 13 / 100\n",
      "t = 100, loss = 0.001390\n",
      "t = 200, loss = 0.002818\n",
      "t = 300, loss = 0.002583\n",
      "t = 400, loss = 0.164566\n",
      "t = 500, loss = 0.008576\n",
      "t = 600, loss = 0.007319\n",
      "t = 700, loss = 0.011253\n",
      "train acc: 0.992 val acc:0.812\n",
      "Starting epoch 14 / 100\n",
      "t = 100, loss = 0.050291\n",
      "t = 200, loss = 0.103943\n",
      "t = 300, loss = 0.043201\n",
      "t = 400, loss = 0.048706\n",
      "t = 500, loss = 0.021372\n",
      "t = 600, loss = 0.001206\n",
      "t = 700, loss = 0.001977\n",
      "train acc: 0.991 val acc:0.818\n",
      "Starting epoch 15 / 100\n",
      "t = 100, loss = 0.011110\n",
      "t = 200, loss = 0.004705\n",
      "t = 300, loss = 0.011524\n",
      "t = 400, loss = 0.002632\n",
      "t = 500, loss = 0.011461\n",
      "t = 600, loss = 0.003056\n",
      "t = 700, loss = 0.006190\n",
      "train acc: 0.995 val acc:0.835\n",
      "Starting epoch 16 / 100\n",
      "t = 100, loss = 0.000214\n",
      "t = 200, loss = 0.004129\n",
      "t = 300, loss = 0.001115\n",
      "t = 400, loss = 0.001978\n",
      "t = 500, loss = 0.001946\n",
      "t = 600, loss = 0.000690\n",
      "t = 700, loss = 0.007966\n",
      "train acc: 0.998 val acc:0.826\n",
      "Starting epoch 17 / 100\n",
      "t = 100, loss = 0.002058\n",
      "t = 200, loss = 0.027758\n",
      "t = 300, loss = 0.004900\n",
      "t = 400, loss = 0.016081\n",
      "t = 500, loss = 0.000449\n",
      "t = 600, loss = 0.006895\n",
      "t = 700, loss = 0.042513\n",
      "train acc: 0.997 val acc:0.832\n",
      "Starting epoch 18 / 100\n",
      "t = 100, loss = 0.013359\n",
      "t = 200, loss = 0.000365\n",
      "t = 300, loss = 0.098756\n",
      "t = 400, loss = 0.021250\n",
      "t = 500, loss = 0.000360\n",
      "t = 600, loss = 0.005222\n",
      "t = 700, loss = 0.002495\n",
      "train acc: 0.998 val acc:0.827\n",
      "Starting epoch 19 / 100\n",
      "t = 100, loss = 0.037013\n",
      "t = 200, loss = 0.001549\n",
      "t = 300, loss = 0.005112\n",
      "t = 400, loss = 0.006624\n",
      "t = 500, loss = 0.000027\n",
      "t = 600, loss = 0.006865\n",
      "t = 700, loss = 0.005284\n",
      "train acc: 0.999 val acc:0.83\n",
      "Starting epoch 20 / 100\n",
      "t = 100, loss = 0.000385\n",
      "t = 200, loss = 0.001816\n",
      "t = 300, loss = 0.000849\n",
      "t = 400, loss = 0.000183\n",
      "t = 500, loss = 0.000249\n",
      "t = 600, loss = 0.000342\n",
      "t = 700, loss = 0.021713\n",
      "train acc: 1.0 val acc:0.834\n",
      "Starting epoch 21 / 100\n",
      "t = 100, loss = 0.000542\n",
      "t = 200, loss = 0.001434\n",
      "t = 300, loss = 0.000212\n",
      "t = 400, loss = 0.031366\n",
      "t = 500, loss = 0.000700\n",
      "t = 600, loss = 0.000284\n",
      "t = 700, loss = 0.000233\n",
      "train acc: 0.997 val acc:0.827\n",
      "Starting epoch 22 / 100\n",
      "t = 100, loss = 0.000631\n",
      "t = 200, loss = 0.001024\n",
      "t = 300, loss = 0.024979\n",
      "t = 400, loss = 0.000181\n",
      "t = 500, loss = 0.000783\n",
      "t = 600, loss = 0.003228\n",
      "t = 700, loss = 0.000126\n",
      "train acc: 0.998 val acc:0.817\n",
      "Starting epoch 23 / 100\n",
      "t = 100, loss = 0.001142\n",
      "t = 200, loss = 0.002984\n",
      "t = 300, loss = 0.009541\n",
      "t = 400, loss = 0.017125\n",
      "t = 500, loss = 0.024606\n",
      "t = 600, loss = 0.000939\n",
      "t = 700, loss = 0.001928\n",
      "train acc: 0.998 val acc:0.803\n",
      "Starting epoch 24 / 100\n",
      "t = 100, loss = 0.006693\n",
      "t = 200, loss = 0.004540\n",
      "t = 300, loss = 0.001612\n",
      "t = 400, loss = 0.000454\n",
      "t = 500, loss = 0.000612\n",
      "t = 600, loss = 0.006568\n",
      "t = 700, loss = 0.000067\n",
      "train acc: 0.999 val acc:0.818\n",
      "Starting epoch 25 / 100\n",
      "t = 100, loss = 0.000345\n",
      "t = 200, loss = 0.002884\n",
      "t = 300, loss = 0.000284\n",
      "t = 400, loss = 0.004767\n",
      "t = 500, loss = 0.000193\n",
      "t = 600, loss = 0.004594\n",
      "t = 700, loss = 0.000266\n",
      "train acc: 0.999 val acc:0.825\n",
      "Starting epoch 26 / 100\n",
      "t = 100, loss = 0.000024\n",
      "t = 200, loss = 0.000187\n",
      "t = 300, loss = 0.000057\n",
      "t = 400, loss = 0.000084\n",
      "t = 500, loss = 0.000057\n",
      "t = 600, loss = 0.000076\n",
      "t = 700, loss = 0.000010\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 27 / 100\n",
      "t = 100, loss = 0.000015\n",
      "t = 200, loss = 0.000289\n",
      "t = 300, loss = 0.000029\n",
      "t = 400, loss = 0.000018\n",
      "t = 500, loss = 0.000017\n",
      "t = 600, loss = 0.000057\n",
      "t = 700, loss = 0.000004\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 28 / 100\n",
      "t = 100, loss = 0.000016\n",
      "t = 200, loss = 0.000016\n",
      "t = 300, loss = 0.000016\n",
      "t = 400, loss = 0.000014\n",
      "t = 500, loss = 0.000014\n",
      "t = 600, loss = 0.000017\n",
      "t = 700, loss = 0.000004\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 29 / 100\n",
      "t = 100, loss = 0.000012\n",
      "t = 200, loss = 0.000012\n",
      "t = 300, loss = 0.000014\n",
      "t = 400, loss = 0.000011\n",
      "t = 500, loss = 0.000011\n",
      "t = 600, loss = 0.000010\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.832\n",
      "Starting epoch 30 / 100\n",
      "t = 100, loss = 0.000010\n",
      "t = 200, loss = 0.000010\n",
      "t = 300, loss = 0.000012\n",
      "t = 400, loss = 0.000008\n",
      "t = 500, loss = 0.000009\n",
      "t = 600, loss = 0.000006\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.831\n",
      "Starting epoch 31 / 100\n",
      "t = 100, loss = 0.000007\n",
      "t = 200, loss = 0.000007\n",
      "t = 300, loss = 0.000010\n",
      "t = 400, loss = 0.000006\n",
      "t = 500, loss = 0.000008\n",
      "t = 600, loss = 0.000004\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.832\n",
      "Starting epoch 32 / 100\n",
      "t = 100, loss = 0.000006\n",
      "t = 200, loss = 0.000006\n",
      "t = 300, loss = 0.000010\n",
      "t = 400, loss = 0.000004\n",
      "t = 500, loss = 0.000006\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.831\n",
      "Starting epoch 33 / 100\n",
      "t = 100, loss = 0.000007\n",
      "t = 200, loss = 0.000004\n",
      "t = 300, loss = 0.000008\n",
      "t = 400, loss = 0.000003\n",
      "t = 500, loss = 0.000006\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.832\n",
      "Starting epoch 34 / 100\n",
      "t = 100, loss = 0.000007\n",
      "t = 200, loss = 0.000003\n",
      "t = 300, loss = 0.000005\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.832\n",
      "Starting epoch 35 / 100\n",
      "t = 100, loss = 0.000011\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.831\n",
      "Starting epoch 36 / 100\n",
      "t = 100, loss = 0.000004\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 37 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.834\n",
      "Starting epoch 38 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.836\n",
      "Starting epoch 39 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.842\n",
      "Starting epoch 40 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.847\n",
      "Starting epoch 41 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.845\n",
      "Starting epoch 42 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.842\n",
      "Starting epoch 43 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.837\n",
      "Starting epoch 44 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.839\n",
      "Starting epoch 45 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.834\n",
      "Starting epoch 46 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.051676\n",
      "t = 600, loss = 0.002564\n",
      "t = 700, loss = 0.001135\n",
      "train acc: 0.993 val acc:0.823\n",
      "Starting epoch 47 / 100\n",
      "t = 100, loss = 0.007063\n",
      "t = 200, loss = 0.000049\n",
      "t = 300, loss = 0.012353\n",
      "t = 400, loss = 0.001742\n",
      "t = 500, loss = 0.000046\n",
      "t = 600, loss = 0.000050\n",
      "t = 700, loss = 0.000827\n",
      "train acc: 0.999 val acc:0.834\n",
      "Starting epoch 48 / 100\n",
      "t = 100, loss = 0.000843\n",
      "t = 200, loss = 0.000035\n",
      "t = 300, loss = 0.000017\n",
      "t = 400, loss = 0.000088\n",
      "t = 500, loss = 0.000051\n",
      "t = 600, loss = 0.000022\n",
      "t = 700, loss = 0.000521\n",
      "train acc: 1.0 val acc:0.829\n",
      "Starting epoch 49 / 100\n",
      "t = 100, loss = 0.000023\n",
      "t = 200, loss = 0.000073\n",
      "t = 300, loss = 0.000026\n",
      "t = 400, loss = 0.000053\n",
      "t = 500, loss = 0.000048\n",
      "t = 600, loss = 0.000016\n",
      "t = 700, loss = 0.000007\n",
      "train acc: 1.0 val acc:0.831\n",
      "Starting epoch 50 / 100\n",
      "t = 100, loss = 0.000013\n",
      "t = 200, loss = 0.000035\n",
      "t = 300, loss = 0.000015\n",
      "t = 400, loss = 0.000034\n",
      "t = 500, loss = 0.000019\n",
      "t = 600, loss = 0.000013\n",
      "t = 700, loss = 0.000006\n",
      "train acc: 1.0 val acc:0.831\n",
      "Starting epoch 51 / 100\n",
      "t = 100, loss = 0.000010\n",
      "t = 200, loss = 0.000028\n",
      "t = 300, loss = 0.000011\n",
      "t = 400, loss = 0.000025\n",
      "t = 500, loss = 0.000012\n",
      "t = 600, loss = 0.000011\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.831\n",
      "Starting epoch 52 / 100\n",
      "t = 100, loss = 0.000007\n",
      "t = 200, loss = 0.000023\n",
      "t = 300, loss = 0.000009\n",
      "t = 400, loss = 0.000019\n",
      "t = 500, loss = 0.000009\n",
      "t = 600, loss = 0.000009\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.831\n",
      "Starting epoch 53 / 100\n",
      "t = 100, loss = 0.000006\n",
      "t = 200, loss = 0.000018\n",
      "t = 300, loss = 0.000007\n",
      "t = 400, loss = 0.000014\n",
      "t = 500, loss = 0.000006\n",
      "t = 600, loss = 0.000007\n",
      "t = 700, loss = 0.000004\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 54 / 100\n",
      "t = 100, loss = 0.000004\n",
      "t = 200, loss = 0.000014\n",
      "t = 300, loss = 0.000005\n",
      "t = 400, loss = 0.000011\n",
      "t = 500, loss = 0.000005\n",
      "t = 600, loss = 0.000005\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 55 / 100\n",
      "t = 100, loss = 0.000003\n",
      "t = 200, loss = 0.000010\n",
      "t = 300, loss = 0.000004\n",
      "t = 400, loss = 0.000008\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000004\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 56 / 100\n",
      "t = 100, loss = 0.000003\n",
      "t = 200, loss = 0.000008\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000006\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 57 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000006\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000004\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.832\n",
      "Starting epoch 58 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000004\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000003\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.833\n",
      "Starting epoch 59 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000003\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.836\n",
      "Starting epoch 60 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 61 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.836\n",
      "Starting epoch 62 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 63 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.837\n",
      "Starting epoch 64 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.838\n",
      "Starting epoch 65 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.833\n",
      "Starting epoch 66 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.835\n",
      "Starting epoch 67 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.834\n",
      "Starting epoch 68 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.83\n",
      "Starting epoch 69 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.83\n",
      "Starting epoch 70 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.83\n",
      "Starting epoch 71 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.826\n",
      "Starting epoch 72 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 1.0 val acc:0.825\n",
      "Starting epoch 73 / 100\n",
      "t = 100, loss = 0.029905\n",
      "t = 200, loss = 0.007839\n",
      "t = 300, loss = 0.000252\n",
      "t = 400, loss = 0.000007\n",
      "t = 500, loss = 0.047173\n",
      "t = 600, loss = 0.009190\n",
      "t = 700, loss = 0.000019\n",
      "train acc: 0.998 val acc:0.817\n",
      "Starting epoch 74 / 100\n",
      "t = 100, loss = 0.000009\n",
      "t = 200, loss = 0.000130\n",
      "t = 300, loss = 0.001378\n",
      "t = 400, loss = 0.000060\n",
      "t = 500, loss = 0.000138\n",
      "t = 600, loss = 0.000038\n",
      "t = 700, loss = 0.000296\n",
      "train acc: 1.0 val acc:0.819\n",
      "Starting epoch 75 / 100\n",
      "t = 100, loss = 0.000002\n",
      "t = 200, loss = 0.000069\n",
      "t = 300, loss = 0.000019\n",
      "t = 400, loss = 0.000003\n",
      "t = 500, loss = 0.000128\n",
      "t = 600, loss = 0.000010\n",
      "t = 700, loss = 0.000007\n",
      "train acc: 1.0 val acc:0.817\n",
      "Starting epoch 76 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000036\n",
      "t = 300, loss = 0.000018\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000043\n",
      "t = 600, loss = 0.000009\n",
      "t = 700, loss = 0.000007\n",
      "train acc: 1.0 val acc:0.818\n",
      "Starting epoch 77 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000027\n",
      "t = 300, loss = 0.000015\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000030\n",
      "t = 600, loss = 0.000008\n",
      "t = 700, loss = 0.000006\n",
      "train acc: 1.0 val acc:0.817\n",
      "Starting epoch 78 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000020\n",
      "t = 300, loss = 0.000013\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000021\n",
      "t = 600, loss = 0.000007\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.817\n",
      "Starting epoch 79 / 100\n",
      "t = 100, loss = 0.000001\n",
      "t = 200, loss = 0.000015\n",
      "t = 300, loss = 0.000010\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000015\n",
      "t = 600, loss = 0.000005\n",
      "t = 700, loss = 0.000005\n",
      "train acc: 1.0 val acc:0.817\n",
      "Starting epoch 80 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000011\n",
      "t = 300, loss = 0.000008\n",
      "t = 400, loss = 0.000002\n",
      "t = 500, loss = 0.000010\n",
      "t = 600, loss = 0.000004\n",
      "t = 700, loss = 0.000004\n",
      "train acc: 1.0 val acc:0.818\n",
      "Starting epoch 81 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000008\n",
      "t = 300, loss = 0.000006\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000007\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000003\n",
      "train acc: 1.0 val acc:0.821\n",
      "Starting epoch 82 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000006\n",
      "t = 300, loss = 0.000004\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000006\n",
      "t = 600, loss = 0.000003\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.82\n",
      "Starting epoch 83 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000004\n",
      "t = 300, loss = 0.000003\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000004\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000002\n",
      "train acc: 1.0 val acc:0.821\n",
      "Starting epoch 84 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000003\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000003\n",
      "t = 600, loss = 0.000002\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.822\n",
      "Starting epoch 85 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000002\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.823\n",
      "Starting epoch 86 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000002\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000002\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.825\n",
      "Starting epoch 87 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000001\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000001\n",
      "train acc: 1.0 val acc:0.823\n",
      "Starting epoch 88 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000001\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.825\n",
      "Starting epoch 89 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000001\n",
      "t = 300, loss = 0.000001\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.822\n",
      "Starting epoch 90 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000001\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.823\n",
      "Starting epoch 91 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.822\n",
      "Starting epoch 92 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.823\n",
      "Starting epoch 93 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.822\n",
      "Starting epoch 94 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.82\n",
      "Starting epoch 95 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.818\n",
      "Starting epoch 96 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.822\n",
      "Starting epoch 97 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.822\n",
      "Starting epoch 98 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.823\n",
      "Starting epoch 99 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.828\n",
      "Starting epoch 100 / 100\n",
      "t = 100, loss = 0.000000\n",
      "t = 200, loss = 0.000000\n",
      "t = 300, loss = 0.000000\n",
      "t = 400, loss = 0.000000\n",
      "t = 500, loss = 0.000000\n",
      "t = 600, loss = 0.000000\n",
      "t = 700, loss = 0.000000\n",
      "train acc: 1.0 val acc:0.831\n",
      "Regularization = 2e-08.\n",
      "Best validation accuracy is 0.847. Training time for 100 epochs: 1319.40 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f012acbe198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "reg_list = [5e-10,2.8e-09, 2e-8]\n",
    "\n",
    "for reg in reg_list:\n",
    "    \n",
    "    best_val_acc=0.0\n",
    "    model = generator().type(gpu_dtype)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00028, weight_decay=reg)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    best_val_acc, training_history = train_detailed(model, loss_fn, optimizer, reg, num_epochs=epochs, verbose=True)\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    print('Regularization = {}.'.format(reg))    \n",
    "    print('Best validation accuracy is {0}. Training time for {1} epochs: {2:.2f} sec'.format(best_val_acc, \n",
    "                                                                                              epochs, end-start))\n",
    "    history = np.array(training_history)\n",
    "\n",
    "    # Plot out the accuracies\n",
    "    plt.title('CNN Train and Validation Accuracies')\n",
    "    plt.axis((0,len(history),0,1.0))\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot(history[:,0], '-ro', label=\"train acc\")\n",
    "    plt.plot(history[:,1], '-bo', label=\"val acc\")\n",
    "    plt.legend(loc='best', ncol=4)\n",
    " \n",
    "    plt.gcf().set_size_inches(15, 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model model_reg=5e-10bestacc.pt has test accuracy of 0.8212\n",
      "Model model_reg=2.8e-09bestacc.pt has test accuracy of 0.8134\n",
      "Model model_reg=2e-08bestacc.pt has test accuracy of 0.8274\n"
     ]
    }
   ],
   "source": [
    "files = ['model_reg=5e-10bestacc.pt',\n",
    "         'model_reg=2.8e-09bestacc.pt',\n",
    "         'model_reg=2e-08bestacc.pt']\n",
    "\n",
    "for file_name in files:\n",
    "    best_model = generator().type(gpu_dtype)\n",
    "    best_model.load_state_dict(torch.load(file_name))\n",
    "\n",
    "    acc = check_accuracy(best_model, loader_test)\n",
    "    print (\"Model {} has test accuracy of {}\".format(file_name, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"795pt\" height=\"864pt\"\n",
       " viewBox=\"0.00 0.00 795.23 864.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.625181 0.625181) rotate(0) translate(4 1378)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-1378 1268,-1378 1268,4 -4,4\"/>\n",
       "<!-- 140336117947024 -->\n",
       "<g id=\"node1\" class=\"node\"><title>140336117947024</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1152.5,-21 1048.5,-21 1048.5,-0 1152.5,-0 1152.5,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"1100.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140336117948256 -->\n",
       "<g id=\"node2\" class=\"node\"><title>140336117948256</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1025.5,-78 923.5,-78 923.5,-57 1025.5,-57 1025.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"974.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140336117948256&#45;&gt;140336117947024 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>140336117948256&#45;&gt;140336117947024</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M996.448,-56.9197C1016.56,-48.1406 1046.56,-35.0457 1069.19,-25.1689\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1070.62,-28.3634 1078.38,-21.155 1067.82,-21.9479 1070.62,-28.3634\"/>\n",
       "</g>\n",
       "<!-- 140336117948144 -->\n",
       "<g id=\"node3\" class=\"node\"><title>140336117948144</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1001.5,-148 947.5,-148 947.5,-114 1001.5,-114 1001.5,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"974.5\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\">20.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"974.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (10)</text>\n",
       "</g>\n",
       "<!-- 140336117948144&#45;&gt;140336117948256 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>140336117948144&#45;&gt;140336117948256</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M974.5,-113.842C974.5,-106.012 974.5,-96.5396 974.5,-88.2816\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"978,-88.0419 974.5,-78.0419 971,-88.0419 978,-88.0419\"/>\n",
       "</g>\n",
       "<!-- 140336117946968 -->\n",
       "<g id=\"node4\" class=\"node\"><title>140336117946968</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1157,-78 1044,-78 1044,-57 1157,-57 1157,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"1100.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward</text>\n",
       "</g>\n",
       "<!-- 140336117946968&#45;&gt;140336117947024 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>140336117946968&#45;&gt;140336117947024</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1100.5,-56.9197C1100.5,-49.9083 1100.5,-40.1442 1100.5,-31.4652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1104,-31.3408 1100.5,-21.3408 1097,-31.3409 1104,-31.3408\"/>\n",
       "</g>\n",
       "<!-- 140336117946688 -->\n",
       "<g id=\"node5\" class=\"node\"><title>140336117946688</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1152.5,-141.5 1048.5,-141.5 1048.5,-120.5 1152.5,-120.5 1152.5,-141.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1100.5\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\">AddmmBackward</text>\n",
       "</g>\n",
       "<!-- 140336117946688&#45;&gt;140336117946968 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>140336117946688&#45;&gt;140336117946968</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1100.5,-120.391C1100.5,-111.866 1100.5,-99.1392 1100.5,-88.4235\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1104,-88.2448 1100.5,-78.2449 1097,-88.2449 1104,-88.2448\"/>\n",
       "</g>\n",
       "<!-- 140336117946520 -->\n",
       "<g id=\"node6\" class=\"node\"><title>140336117946520</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1036.5,-205 934.5,-205 934.5,-184 1036.5,-184 1036.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"985.5\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">ExpandBackward</text>\n",
       "</g>\n",
       "<!-- 140336117946520&#45;&gt;140336117946688 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>140336117946520&#45;&gt;140336117946688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1003.47,-183.891C1022.29,-173.826 1052.06,-157.906 1073.66,-146.351\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1075.49,-149.344 1082.66,-141.542 1072.19,-143.171 1075.49,-149.344\"/>\n",
       "</g>\n",
       "<!-- 140336117946800 -->\n",
       "<g id=\"node7\" class=\"node\"><title>140336117946800</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1012.5,-275 958.5,-275 958.5,-241 1012.5,-241 1012.5,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"985.5\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\">18.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"985.5\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 140336117946800&#45;&gt;140336117946520 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>140336117946800&#45;&gt;140336117946520</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M985.5,-240.842C985.5,-233.012 985.5,-223.54 985.5,-215.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"989,-215.042 985.5,-205.042 982,-215.042 989,-215.042\"/>\n",
       "</g>\n",
       "<!-- 140336117948032 -->\n",
       "<g id=\"node8\" class=\"node\"><title>140336117948032</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1146.5,-205 1054.5,-205 1054.5,-184 1146.5,-184 1146.5,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"1100.5\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 140336117948032&#45;&gt;140336117946688 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>140336117948032&#45;&gt;140336117946688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1100.5,-183.891C1100.5,-175.366 1100.5,-162.639 1100.5,-151.923\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1104,-151.745 1100.5,-141.745 1097,-151.745 1104,-151.745\"/>\n",
       "</g>\n",
       "<!-- 140336117947920 -->\n",
       "<g id=\"node9\" class=\"node\"><title>140336117947920</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1158.5,-268.5 1034.5,-268.5 1034.5,-247.5 1158.5,-247.5 1158.5,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1096.5\" y=\"-254.9\" font-family=\"Times,serif\" font-size=\"12.00\">MaxPool2DBackward</text>\n",
       "</g>\n",
       "<!-- 140336117947920&#45;&gt;140336117948032 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>140336117947920&#45;&gt;140336117948032</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1097.12,-247.391C1097.68,-238.866 1098.51,-226.139 1099.2,-215.423\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1102.71,-215.451 1099.87,-205.245 1095.72,-214.997 1102.71,-215.451\"/>\n",
       "</g>\n",
       "<!-- 140336117947864 -->\n",
       "<g id=\"node10\" class=\"node\"><title>140336117947864</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1157,-332 1036,-332 1036,-311 1157,-311 1157,-332\"/>\n",
       "<text text-anchor=\"middle\" x=\"1096.5\" y=\"-318.4\" font-family=\"Times,serif\" font-size=\"12.00\">BatchNormBackward</text>\n",
       "</g>\n",
       "<!-- 140336117947864&#45;&gt;140336117947920 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>140336117947864&#45;&gt;140336117947920</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1096.5,-310.891C1096.5,-302.366 1096.5,-289.639 1096.5,-278.923\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1100,-278.745 1096.5,-268.745 1093,-278.745 1100,-278.745\"/>\n",
       "</g>\n",
       "<!-- 140336117947808 -->\n",
       "<g id=\"node11\" class=\"node\"><title>140336117947808</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1046,-395.5 933,-395.5 933,-374.5 1046,-374.5 1046,-395.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"989.5\" y=\"-381.9\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward</text>\n",
       "</g>\n",
       "<!-- 140336117947808&#45;&gt;140336117947864 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>140336117947808&#45;&gt;140336117947864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1006.22,-374.391C1023.57,-364.416 1050.93,-348.691 1070.99,-337.163\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1072.97,-340.06 1079.9,-332.042 1069.48,-333.991 1072.97,-340.06\"/>\n",
       "</g>\n",
       "<!-- 140336117973400 -->\n",
       "<g id=\"node12\" class=\"node\"><title>140336117973400</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1043,-459 936,-459 936,-438 1043,-438 1043,-459\"/>\n",
       "<text text-anchor=\"middle\" x=\"989.5\" y=\"-445.4\" font-family=\"Times,serif\" font-size=\"12.00\">ConvNdBackward</text>\n",
       "</g>\n",
       "<!-- 140336117973400&#45;&gt;140336117947808 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>140336117973400&#45;&gt;140336117947808</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M989.5,-437.891C989.5,-429.366 989.5,-416.639 989.5,-405.923\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"993,-405.745 989.5,-395.745 986,-405.745 993,-405.745\"/>\n",
       "</g>\n",
       "<!-- 140336117973288 -->\n",
       "<g id=\"node13\" class=\"node\"><title>140336117973288</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"925,-522.5 804,-522.5 804,-501.5 925,-501.5 925,-522.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"864.5\" y=\"-508.9\" font-family=\"Times,serif\" font-size=\"12.00\">BatchNormBackward</text>\n",
       "</g>\n",
       "<!-- 140336117973288&#45;&gt;140336117973400 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>140336117973288&#45;&gt;140336117973400</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M884.031,-501.391C904.671,-491.236 937.428,-475.12 960.96,-463.542\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"962.678,-466.597 970.106,-459.042 959.588,-460.316 962.678,-466.597\"/>\n",
       "</g>\n",
       "<!-- 140336117973064 -->\n",
       "<g id=\"node14\" class=\"node\"><title>140336117973064</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"814,-592.5 701,-592.5 701,-571.5 814,-571.5 814,-592.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"757.5\" y=\"-578.9\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward</text>\n",
       "</g>\n",
       "<!-- 140336117973064&#45;&gt;140336117973288 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>140336117973064&#45;&gt;140336117973288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M772.83,-571.257C790.65,-559.933 820.257,-541.117 840.989,-527.942\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"842.98,-530.823 849.543,-522.505 839.226,-524.915 842.98,-530.823\"/>\n",
       "</g>\n",
       "<!-- 140336185208224 -->\n",
       "<g id=\"node15\" class=\"node\"><title>140336185208224</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"811,-656 704,-656 704,-635 811,-635 811,-656\"/>\n",
       "<text text-anchor=\"middle\" x=\"757.5\" y=\"-642.4\" font-family=\"Times,serif\" font-size=\"12.00\">ConvNdBackward</text>\n",
       "</g>\n",
       "<!-- 140336185208224&#45;&gt;140336117973064 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>140336185208224&#45;&gt;140336117973064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M757.5,-634.891C757.5,-626.366 757.5,-613.639 757.5,-602.923\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"761,-602.745 757.5,-592.745 754,-602.745 761,-602.745\"/>\n",
       "</g>\n",
       "<!-- 140336185206152 -->\n",
       "<g id=\"node16\" class=\"node\"><title>140336185206152</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"693.5,-719.5 569.5,-719.5 569.5,-698.5 693.5,-698.5 693.5,-719.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"631.5\" y=\"-705.9\" font-family=\"Times,serif\" font-size=\"12.00\">MaxPool2DBackward</text>\n",
       "</g>\n",
       "<!-- 140336185206152&#45;&gt;140336185208224 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>140336185206152&#45;&gt;140336185208224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M651.188,-698.391C671.992,-688.236 705.011,-672.12 728.732,-660.542\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"730.499,-663.574 737.951,-656.042 727.429,-657.283 730.499,-663.574\"/>\n",
       "</g>\n",
       "<!-- 140336185205984 -->\n",
       "<g id=\"node17\" class=\"node\"><title>140336185205984</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"692,-783 571,-783 571,-762 692,-762 692,-783\"/>\n",
       "<text text-anchor=\"middle\" x=\"631.5\" y=\"-769.4\" font-family=\"Times,serif\" font-size=\"12.00\">BatchNormBackward</text>\n",
       "</g>\n",
       "<!-- 140336185205984&#45;&gt;140336185206152 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>140336185205984&#45;&gt;140336185206152</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M631.5,-761.891C631.5,-753.366 631.5,-740.639 631.5,-729.923\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"635,-729.745 631.5,-719.745 628,-729.745 635,-729.745\"/>\n",
       "</g>\n",
       "<!-- 140336185207944 -->\n",
       "<g id=\"node18\" class=\"node\"><title>140336185207944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"584,-846.5 471,-846.5 471,-825.5 584,-825.5 584,-846.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.5\" y=\"-832.9\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward</text>\n",
       "</g>\n",
       "<!-- 140336185207944&#45;&gt;140336185205984 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>140336185207944&#45;&gt;140336185205984</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M543.75,-825.391C560.617,-815.416 587.21,-799.691 606.703,-788.163\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"608.538,-791.145 615.364,-783.042 604.975,-785.119 608.538,-791.145\"/>\n",
       "</g>\n",
       "<!-- 140336185207664 -->\n",
       "<g id=\"node19\" class=\"node\"><title>140336185207664</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"581,-910 474,-910 474,-889 581,-889 581,-910\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.5\" y=\"-896.4\" font-family=\"Times,serif\" font-size=\"12.00\">ConvNdBackward</text>\n",
       "</g>\n",
       "<!-- 140336185207664&#45;&gt;140336185207944 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>140336185207664&#45;&gt;140336185207944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M527.5,-888.891C527.5,-880.366 527.5,-867.639 527.5,-856.923\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"531,-856.745 527.5,-846.745 524,-856.745 531,-856.745\"/>\n",
       "</g>\n",
       "<!-- 140336185205536 -->\n",
       "<g id=\"node20\" class=\"node\"><title>140336185205536</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"466,-973.5 345,-973.5 345,-952.5 466,-952.5 466,-973.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"405.5\" y=\"-959.9\" font-family=\"Times,serif\" font-size=\"12.00\">BatchNormBackward</text>\n",
       "</g>\n",
       "<!-- 140336185205536&#45;&gt;140336185207664 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>140336185205536&#45;&gt;140336185207664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M424.562,-952.391C444.617,-942.281 476.393,-926.263 499.338,-914.696\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"501.217,-917.669 508.571,-910.042 498.066,-911.418 501.217,-917.669\"/>\n",
       "</g>\n",
       "<!-- 140336185194704 -->\n",
       "<g id=\"node21\" class=\"node\"><title>140336185194704</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"358,-1043.5 245,-1043.5 245,-1022.5 358,-1022.5 358,-1043.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"301.5\" y=\"-1029.9\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward</text>\n",
       "</g>\n",
       "<!-- 140336185194704&#45;&gt;140336185205536 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>140336185194704&#45;&gt;140336185205536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M316.401,-1022.26C333.643,-1010.98 362.24,-992.286 382.377,-979.119\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"384.508,-981.907 390.962,-973.505 380.677,-976.049 384.508,-981.907\"/>\n",
       "</g>\n",
       "<!-- 140336185193584 -->\n",
       "<g id=\"node22\" class=\"node\"><title>140336185193584</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"355,-1107 248,-1107 248,-1086 355,-1086 355,-1107\"/>\n",
       "<text text-anchor=\"middle\" x=\"301.5\" y=\"-1093.4\" font-family=\"Times,serif\" font-size=\"12.00\">ConvNdBackward</text>\n",
       "</g>\n",
       "<!-- 140336185193584&#45;&gt;140336185194704 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>140336185193584&#45;&gt;140336185194704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.5,-1085.89C301.5,-1077.37 301.5,-1064.64 301.5,-1053.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"305,-1053.74 301.5,-1043.74 298,-1053.74 305,-1053.74\"/>\n",
       "</g>\n",
       "<!-- 140336185193360 -->\n",
       "<g id=\"node23\" class=\"node\"><title>140336185193360</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"243,-1170.5 122,-1170.5 122,-1149.5 243,-1149.5 243,-1170.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.5\" y=\"-1156.9\" font-family=\"Times,serif\" font-size=\"12.00\">BatchNormBackward</text>\n",
       "</g>\n",
       "<!-- 140336185193360&#45;&gt;140336185193584 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>140336185193360&#45;&gt;140336185193584</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M201.094,-1149.39C220.655,-1139.28 251.65,-1123.26 274.031,-1111.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"275.76,-1114.74 283.037,-1107.04 272.546,-1108.52 275.76,-1114.74\"/>\n",
       "</g>\n",
       "<!-- 140336185193304 -->\n",
       "<g id=\"node24\" class=\"node\"><title>140336185193304</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"135,-1240.5 22,-1240.5 22,-1219.5 135,-1219.5 135,-1240.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"78.5\" y=\"-1226.9\" font-family=\"Times,serif\" font-size=\"12.00\">ThresholdBackward</text>\n",
       "</g>\n",
       "<!-- 140336185193304&#45;&gt;140336185193360 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>140336185193304&#45;&gt;140336185193360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.4007,-1219.26C110.643,-1207.98 139.24,-1189.29 159.377,-1176.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"161.508,-1178.91 167.962,-1170.51 157.677,-1173.05 161.508,-1178.91\"/>\n",
       "</g>\n",
       "<!-- 140336185192912 -->\n",
       "<g id=\"node25\" class=\"node\"><title>140336185192912</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-1304 25,-1304 25,-1283 132,-1283 132,-1304\"/>\n",
       "<text text-anchor=\"middle\" x=\"78.5\" y=\"-1290.4\" font-family=\"Times,serif\" font-size=\"12.00\">ConvNdBackward</text>\n",
       "</g>\n",
       "<!-- 140336185192912&#45;&gt;140336185193304 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>140336185192912&#45;&gt;140336185193304</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M78.5,-1282.89C78.5,-1274.37 78.5,-1261.64 78.5,-1250.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.0001,-1250.74 78.5,-1240.74 75.0001,-1250.74 82.0001,-1250.74\"/>\n",
       "</g>\n",
       "<!-- 140336185194256 -->\n",
       "<g id=\"node26\" class=\"node\"><title>140336185194256</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"75,-1374 7.10543e-15,-1374 7.10543e-15,-1340 75,-1340 75,-1374\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.5\" y=\"-1360.4\" font-family=\"Times,serif\" font-size=\"12.00\">0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"37.5\" y=\"-1347.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (32, 3, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140336185194256&#45;&gt;140336185192912 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>140336185194256&#45;&gt;140336185192912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M48.2723,-1339.84C53.8478,-1331.48 60.6732,-1321.24 66.4265,-1312.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"69.5039,-1314.3 72.1387,-1304.04 63.6795,-1310.42 69.5039,-1314.3\"/>\n",
       "</g>\n",
       "<!-- 140336185194368 -->\n",
       "<g id=\"node27\" class=\"node\"><title>140336185194368</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"147.5,-1374 93.5,-1374 93.5,-1340 147.5,-1340 147.5,-1374\"/>\n",
       "<text text-anchor=\"middle\" x=\"120.5\" y=\"-1360.4\" font-family=\"Times,serif\" font-size=\"12.00\">0.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"120.5\" y=\"-1347.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (32)</text>\n",
       "</g>\n",
       "<!-- 140336185194368&#45;&gt;140336185192912 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>140336185194368&#45;&gt;140336185192912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109.465,-1339.84C103.693,-1331.39 96.6127,-1321.02 90.6803,-1312.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.5464,-1310.33 85.0164,-1304.04 87.7658,-1314.27 93.5464,-1310.33\"/>\n",
       "</g>\n",
       "<!-- 140336185192968 -->\n",
       "<g id=\"node28\" class=\"node\"><title>140336185192968</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"211.5,-1247 153.5,-1247 153.5,-1213 211.5,-1213 211.5,-1247\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.5\" y=\"-1233.4\" font-family=\"Times,serif\" font-size=\"12.00\">2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"182.5\" y=\"-1220.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (32)</text>\n",
       "</g>\n",
       "<!-- 140336185192968&#45;&gt;140336185193360 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>140336185192968&#45;&gt;140336185193360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.5,-1212.88C182.5,-1203.31 182.5,-1191.09 182.5,-1180.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186,-1180.89 182.5,-1170.89 179,-1180.89 186,-1180.89\"/>\n",
       "</g>\n",
       "<!-- 140336185193080 -->\n",
       "<g id=\"node29\" class=\"node\"><title>140336185193080</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"283.5,-1247 229.5,-1247 229.5,-1213 283.5,-1213 283.5,-1247\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.5\" y=\"-1233.4\" font-family=\"Times,serif\" font-size=\"12.00\">2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"256.5\" y=\"-1220.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (32)</text>\n",
       "</g>\n",
       "<!-- 140336185193080&#45;&gt;140336185193360 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>140336185193080&#45;&gt;140336185193360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.963,-1212.88C227.434,-1202.29 212.38,-1188.46 200.716,-1177.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.999,-1175.08 193.268,-1170.89 198.263,-1180.24 202.999,-1175.08\"/>\n",
       "</g>\n",
       "<!-- 140336185193920 -->\n",
       "<g id=\"node30\" class=\"node\"><title>140336185193920</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"342,-1177 261,-1177 261,-1143 342,-1143 342,-1177\"/>\n",
       "<text text-anchor=\"middle\" x=\"301.5\" y=\"-1163.4\" font-family=\"Times,serif\" font-size=\"12.00\">3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"301.5\" y=\"-1150.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64, 32, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140336185193920&#45;&gt;140336185193584 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>140336185193920&#45;&gt;140336185193584</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.5,-1142.84C301.5,-1135.01 301.5,-1125.54 301.5,-1117.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"305,-1117.04 301.5,-1107.04 298,-1117.04 305,-1117.04\"/>\n",
       "</g>\n",
       "<!-- 140336185192520 -->\n",
       "<g id=\"node31\" class=\"node\"><title>140336185192520</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"414.5,-1177 360.5,-1177 360.5,-1143 414.5,-1143 414.5,-1177\"/>\n",
       "<text text-anchor=\"middle\" x=\"387.5\" y=\"-1163.4\" font-family=\"Times,serif\" font-size=\"12.00\">3.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"387.5\" y=\"-1150.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140336185192520&#45;&gt;140336185193584 -->\n",
       "<g id=\"edge30\" class=\"edge\"><title>140336185192520&#45;&gt;140336185193584</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M364.905,-1142.84C351.965,-1133.59 335.817,-1122.04 323.056,-1112.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"325.013,-1110.01 314.843,-1107.04 320.941,-1115.71 325.013,-1110.01\"/>\n",
       "</g>\n",
       "<!-- 140336185194760 -->\n",
       "<g id=\"node32\" class=\"node\"><title>140336185194760</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"434.5,-1050 376.5,-1050 376.5,-1016 434.5,-1016 434.5,-1050\"/>\n",
       "<text text-anchor=\"middle\" x=\"405.5\" y=\"-1036.4\" font-family=\"Times,serif\" font-size=\"12.00\">5.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"405.5\" y=\"-1023.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140336185194760&#45;&gt;140336185205536 -->\n",
       "<g id=\"edge31\" class=\"edge\"><title>140336185194760&#45;&gt;140336185205536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M405.5,-1015.88C405.5,-1006.31 405.5,-994.088 405.5,-983.912\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"409,-983.895 405.5,-973.895 402,-983.895 409,-983.895\"/>\n",
       "</g>\n",
       "<!-- 140336185193528 -->\n",
       "<g id=\"node33\" class=\"node\"><title>140336185193528</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"506.5,-1050 452.5,-1050 452.5,-1016 506.5,-1016 506.5,-1050\"/>\n",
       "<text text-anchor=\"middle\" x=\"479.5\" y=\"-1036.4\" font-family=\"Times,serif\" font-size=\"12.00\">5.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"479.5\" y=\"-1023.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140336185193528&#45;&gt;140336185205536 -->\n",
       "<g id=\"edge32\" class=\"edge\"><title>140336185193528&#45;&gt;140336185205536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M461.963,-1015.88C450.434,-1005.29 435.38,-991.458 423.716,-980.739\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"425.999,-978.084 416.268,-973.895 421.263,-983.238 425.999,-978.084\"/>\n",
       "</g>\n",
       "<!-- 140336185207496 -->\n",
       "<g id=\"node34\" class=\"node\"><title>140336185207496</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"571,-980 484,-980 484,-946 571,-946 571,-980\"/>\n",
       "<text text-anchor=\"middle\" x=\"527.5\" y=\"-966.4\" font-family=\"Times,serif\" font-size=\"12.00\">6.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"527.5\" y=\"-953.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128, 64, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140336185207496&#45;&gt;140336185207664 -->\n",
       "<g id=\"edge33\" class=\"edge\"><title>140336185207496&#45;&gt;140336185207664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M527.5,-945.842C527.5,-938.012 527.5,-928.54 527.5,-920.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"531,-920.042 527.5,-910.042 524,-920.042 531,-920.042\"/>\n",
       "</g>\n",
       "<!-- 140336185208784 -->\n",
       "<g id=\"node35\" class=\"node\"><title>140336185208784</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"643.5,-980 589.5,-980 589.5,-946 643.5,-946 643.5,-980\"/>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-966.4\" font-family=\"Times,serif\" font-size=\"12.00\">6.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"616.5\" y=\"-953.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140336185208784&#45;&gt;140336185207664 -->\n",
       "<g id=\"edge34\" class=\"edge\"><title>140336185208784&#45;&gt;140336185207664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M593.116,-945.842C579.726,-936.589 563.014,-925.041 549.808,-915.915\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"551.525,-912.847 541.309,-910.042 547.546,-918.606 551.525,-912.847\"/>\n",
       "</g>\n",
       "<!-- 140336185205816 -->\n",
       "<g id=\"node36\" class=\"node\"><title>140336185205816</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"660.5,-853 602.5,-853 602.5,-819 660.5,-819 660.5,-853\"/>\n",
       "<text text-anchor=\"middle\" x=\"631.5\" y=\"-839.4\" font-family=\"Times,serif\" font-size=\"12.00\">8.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"631.5\" y=\"-826.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140336185205816&#45;&gt;140336185205984 -->\n",
       "<g id=\"edge35\" class=\"edge\"><title>140336185205816&#45;&gt;140336185205984</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M631.5,-818.842C631.5,-811.012 631.5,-801.54 631.5,-793.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"635,-793.042 631.5,-783.042 628,-793.042 635,-793.042\"/>\n",
       "</g>\n",
       "<!-- 140336185207832 -->\n",
       "<g id=\"node37\" class=\"node\"><title>140336185207832</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"732.5,-853 678.5,-853 678.5,-819 732.5,-819 732.5,-853\"/>\n",
       "<text text-anchor=\"middle\" x=\"705.5\" y=\"-839.4\" font-family=\"Times,serif\" font-size=\"12.00\">8.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"705.5\" y=\"-826.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140336185207832&#45;&gt;140336185205984 -->\n",
       "<g id=\"edge36\" class=\"edge\"><title>140336185207832&#45;&gt;140336185205984</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M686.057,-818.842C675.138,-809.766 661.562,-798.484 650.685,-789.444\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"652.909,-786.742 642.981,-783.042 648.435,-792.125 652.909,-786.742\"/>\n",
       "</g>\n",
       "<!-- 140336185206096 -->\n",
       "<g id=\"node38\" class=\"node\"><title>140336185206096</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"804,-726 711,-726 711,-692 804,-692 804,-726\"/>\n",
       "<text text-anchor=\"middle\" x=\"757.5\" y=\"-712.4\" font-family=\"Times,serif\" font-size=\"12.00\">10.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"757.5\" y=\"-699.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128, 128, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140336185206096&#45;&gt;140336185208224 -->\n",
       "<g id=\"edge37\" class=\"edge\"><title>140336185206096&#45;&gt;140336185208224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M757.5,-691.842C757.5,-684.012 757.5,-674.54 757.5,-666.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"761,-666.042 757.5,-656.042 754,-666.042 761,-666.042\"/>\n",
       "</g>\n",
       "<!-- 140336185206040 -->\n",
       "<g id=\"node39\" class=\"node\"><title>140336185206040</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"876.5,-726 822.5,-726 822.5,-692 876.5,-692 876.5,-726\"/>\n",
       "<text text-anchor=\"middle\" x=\"849.5\" y=\"-712.4\" font-family=\"Times,serif\" font-size=\"12.00\">10.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"849.5\" y=\"-699.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140336185206040&#45;&gt;140336185208224 -->\n",
       "<g id=\"edge38\" class=\"edge\"><title>140336185206040&#45;&gt;140336185208224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M825.328,-691.842C811.353,-682.5 793.879,-670.818 780.167,-661.652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"782.033,-658.69 771.774,-656.042 778.143,-664.509 782.033,-658.69\"/>\n",
       "</g>\n",
       "<!-- 140336117973680 -->\n",
       "<g id=\"node40\" class=\"node\"><title>140336117973680</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"896.5,-599 832.5,-599 832.5,-565 896.5,-565 896.5,-599\"/>\n",
       "<text text-anchor=\"middle\" x=\"864.5\" y=\"-585.4\" font-family=\"Times,serif\" font-size=\"12.00\">12.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"864.5\" y=\"-572.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140336117973680&#45;&gt;140336117973288 -->\n",
       "<g id=\"edge39\" class=\"edge\"><title>140336117973680&#45;&gt;140336117973288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M864.5,-564.885C864.5,-555.309 864.5,-543.088 864.5,-532.912\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"868,-532.895 864.5,-522.895 861,-532.895 868,-532.895\"/>\n",
       "</g>\n",
       "<!-- 140336185208280 -->\n",
       "<g id=\"node41\" class=\"node\"><title>140336185208280</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"968.5,-599 914.5,-599 914.5,-565 968.5,-565 968.5,-599\"/>\n",
       "<text text-anchor=\"middle\" x=\"941.5\" y=\"-585.4\" font-family=\"Times,serif\" font-size=\"12.00\">12.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"941.5\" y=\"-572.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (128)</text>\n",
       "</g>\n",
       "<!-- 140336185208280&#45;&gt;140336117973288 -->\n",
       "<g id=\"edge40\" class=\"edge\"><title>140336185208280&#45;&gt;140336117973288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M923.252,-564.885C911.256,-554.291 895.592,-540.458 883.455,-529.739\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"885.517,-526.891 875.704,-522.895 880.883,-532.138 885.517,-526.891\"/>\n",
       "</g>\n",
       "<!-- 140336117973232 -->\n",
       "<g id=\"node42\" class=\"node\"><title>140336117973232</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1036,-529 943,-529 943,-495 1036,-495 1036,-529\"/>\n",
       "<text text-anchor=\"middle\" x=\"989.5\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\">13.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"989.5\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (256, 128, 3, 3)</text>\n",
       "</g>\n",
       "<!-- 140336117973232&#45;&gt;140336117973400 -->\n",
       "<g id=\"edge41\" class=\"edge\"><title>140336117973232&#45;&gt;140336117973400</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M989.5,-494.842C989.5,-487.012 989.5,-477.54 989.5,-469.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"993,-469.042 989.5,-459.042 986,-469.042 993,-469.042\"/>\n",
       "</g>\n",
       "<!-- 140336117973176 -->\n",
       "<g id=\"node43\" class=\"node\"><title>140336117973176</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1108.5,-529 1054.5,-529 1054.5,-495 1108.5,-495 1108.5,-529\"/>\n",
       "<text text-anchor=\"middle\" x=\"1081.5\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\">13.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"1081.5\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (256)</text>\n",
       "</g>\n",
       "<!-- 140336117973176&#45;&gt;140336117973400 -->\n",
       "<g id=\"edge42\" class=\"edge\"><title>140336117973176&#45;&gt;140336117973400</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1057.33,-494.842C1043.35,-485.5 1025.88,-473.818 1012.17,-464.652\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1014.03,-461.69 1003.77,-459.042 1010.14,-467.509 1014.03,-461.69\"/>\n",
       "</g>\n",
       "<!-- 140336117973568 -->\n",
       "<g id=\"node44\" class=\"node\"><title>140336117973568</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1128.5,-402 1064.5,-402 1064.5,-368 1128.5,-368 1128.5,-402\"/>\n",
       "<text text-anchor=\"middle\" x=\"1096.5\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\">15.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"1096.5\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (256)</text>\n",
       "</g>\n",
       "<!-- 140336117973568&#45;&gt;140336117947864 -->\n",
       "<g id=\"edge43\" class=\"edge\"><title>140336117973568&#45;&gt;140336117947864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1096.5,-367.842C1096.5,-360.012 1096.5,-350.54 1096.5,-342.282\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1100,-342.042 1096.5,-332.042 1093,-342.042 1100,-342.042\"/>\n",
       "</g>\n",
       "<!-- 140336117973512 -->\n",
       "<g id=\"node45\" class=\"node\"><title>140336117973512</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1200.5,-402 1146.5,-402 1146.5,-368 1200.5,-368 1200.5,-402\"/>\n",
       "<text text-anchor=\"middle\" x=\"1173.5\" y=\"-388.4\" font-family=\"Times,serif\" font-size=\"12.00\">15.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"1173.5\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (256)</text>\n",
       "</g>\n",
       "<!-- 140336117973512&#45;&gt;140336117947864 -->\n",
       "<g id=\"edge44\" class=\"edge\"><title>140336117973512&#45;&gt;140336117947864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1153.27,-367.842C1141.91,-358.766 1127.78,-347.484 1116.46,-338.444\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1118.44,-335.548 1108.45,-332.042 1114.08,-341.017 1118.44,-335.548\"/>\n",
       "</g>\n",
       "<!-- 140336117946856 -->\n",
       "<g id=\"node46\" class=\"node\"><title>140336117946856</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1245,-205 1172,-205 1172,-184 1245,-184 1245,-205\"/>\n",
       "<text text-anchor=\"middle\" x=\"1208.5\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140336117946856&#45;&gt;140336117946688 -->\n",
       "<g id=\"edge45\" class=\"edge\"><title>140336117946856&#45;&gt;140336117946688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1191.62,-183.891C1174.03,-173.871 1146.24,-158.048 1125.98,-146.507\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1127.68,-143.449 1117.26,-141.542 1124.21,-149.532 1127.68,-143.449\"/>\n",
       "</g>\n",
       "<!-- 140336117946744 -->\n",
       "<g id=\"node47\" class=\"node\"><title>140336117946744</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1264,-275 1177,-275 1177,-241 1264,-241 1264,-275\"/>\n",
       "<text text-anchor=\"middle\" x=\"1220.5\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\">18.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"1220.5\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (1024, 16384)</text>\n",
       "</g>\n",
       "<!-- 140336117946744&#45;&gt;140336117946856 -->\n",
       "<g id=\"edge46\" class=\"edge\"><title>140336117946744&#45;&gt;140336117946856</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1217.35,-240.842C1215.8,-232.923 1213.93,-223.324 1212.3,-215.001\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1215.71,-214.186 1210.36,-205.042 1208.84,-215.527 1215.71,-214.186\"/>\n",
       "</g>\n",
       "<!-- 140336117948200 -->\n",
       "<g id=\"node48\" class=\"node\"><title>140336117948200</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"1248,-78 1175,-78 1175,-57 1248,-57 1248,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"1211.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 140336117948200&#45;&gt;140336117947024 -->\n",
       "<g id=\"edge47\" class=\"edge\"><title>140336117948200&#45;&gt;140336117947024</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1192.17,-56.9197C1174.76,-48.2973 1148.96,-35.512 1129.16,-25.7011\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1130.5,-22.4588 1119.99,-21.155 1127.39,-28.731 1130.5,-22.4588\"/>\n",
       "</g>\n",
       "<!-- 140336117948088 -->\n",
       "<g id=\"node49\" class=\"node\"><title>140336117948088</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"1246,-148 1177,-148 1177,-114 1246,-114 1246,-148\"/>\n",
       "<text text-anchor=\"middle\" x=\"1211.5\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\">20.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"1211.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\"> (10, 1024)</text>\n",
       "</g>\n",
       "<!-- 140336117948088&#45;&gt;140336117948200 -->\n",
       "<g id=\"edge48\" class=\"edge\"><title>140336117948088&#45;&gt;140336117948200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1211.5,-113.842C1211.5,-106.012 1211.5,-96.5396 1211.5,-88.2816\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1215,-88.0419 1211.5,-78.0419 1208,-88.0419 1215,-88.0419\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa28c759f98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "model = generator()\n",
    "\n",
    "x = torch.randn(64, 3, 32, 32)\n",
    "x_var = Variable(x) # Construct a PyTorch Variable out of your input data\n",
    "y = model(x_var)        # Feed it through the model! \n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(y.size()), np.array([64, 10]))\n",
    "\n",
    "make_dot(y, params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
